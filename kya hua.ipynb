{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84fcdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f915e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f555667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a81c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a27f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['review'] = df['review'].apply(lambda x: re.sub(\"<.*?>\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bb9ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production.   The filming t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production.   The filming t...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb707643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df['sentiment'] = df['sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4156cee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production.   The filming t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production.   The filming t...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c42d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.  The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.  It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.  I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "data=df.to_numpy()\n",
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20044cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Johan\\miniconda3\\envs\\torchsong\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2028,  1997,  1996,  2060, 15814,  2038,  3855,  2008,  2044,\n",
      "          3666,  2074,  1015, 11472,  2792,  2017,  1005,  2222,  2022, 13322,\n",
      "          1012,  2027,  2024,  2157,  1010,  2004,  2023,  2003,  3599,  2054,\n",
      "          3047,  2007,  2033,  1012,  1996,  2034,  2518,  2008,  4930,  2033,\n",
      "          2055, 11472,  2001,  2049, 24083,  1998,  4895, 10258,  2378,  8450,\n",
      "          5019,  1997,  4808,  1010,  2029,  2275,  1999,  2157,  2013,  1996,\n",
      "          2773,  2175,  1012,  3404,  2033,  1010,  2023,  2003,  2025,  1037,\n",
      "          2265,  2005,  1996,  8143, 18627,  2030,  5199,  3593,  1012,  2023,\n",
      "          2265,  8005,  2053, 17957,  2007, 12362,  2000,  5850,  1010,  3348,\n",
      "          2030,  4808,  1012,  2049,  2003, 13076,  1010,  1999,  1996,  4438,\n",
      "          2224,  1997,  1996,  2773,  1012,  2009,  2003,  2170, 11472,  2004,\n",
      "          2008,  2003,  1996,  8367,  2445,  2000,  1996, 17411,  4555,  3036,\n",
      "          2110,  7279,  4221, 12380,  2854,  1012,  2009,  7679,  3701,  2006,\n",
      "         14110,  2103,  1010,  2019,  6388,  2930,  1997,  1996,  3827,  2073,\n",
      "          2035,  1996,  4442,  2031,  3221, 21430,  1998,  2227, 20546,  2015,\n",
      "          1010,  2061,  9394,  2003,  2025,  2152,  2006,  1996, 11376,  1012,\n",
      "          7861,  2103,  2003,  2188,  2000,  2116,  1012,  1012, 26030,  2015,\n",
      "          1010,  7486,  1010, 18542, 10230,  1010,  7402,  2015,  1010,  8135,\n",
      "          1010, 16773,  1010,  3493,  1998,  2062,  1012,  1012,  1012,  1012,\n",
      "          2061,  8040, 16093, 28331,  1010,  2331, 14020,  1010, 26489,  6292,\n",
      "         24069,  1998, 22824, 10540,  2024,  2196,  2521,  2185,  1012,  1045,\n",
      "          2052,  2360,  1996,  2364,  5574,  1997,  1996,  2265,  2003,  2349,\n",
      "          2000,  1996,  2755,  2008,  2009,  3632,  2073,  2060,  3065,  2876,\n",
      "          1005,  1056,  8108,  1012,  5293,  3492,  4620,  4993,  2005,  7731,\n",
      "          9501,  1010,  5293, 11084,  1010,  5293,  7472,  1012,  1012,  1012,\n",
      "         11472,  2987,  1005,  1056,  6752,  2105,  1012,  1996,  2034,  2792,\n",
      "          1045,  2412,  2387,  4930,  2033,  2004,  2061, 11808,  2009,  2001,\n",
      "         16524,  1010,  1045,  2481,  1005,  1056,  2360,  1045,  2001,  3201,\n",
      "          2005,  2009,  1010,  2021,  2004,  1045,  3427,  2062,  1010,  1045,\n",
      "          2764,  1037,  5510,  2005, 11472,  1010,  1998,  2288, 17730,  2000,\n",
      "          1996,  2152,  3798,  1997,  8425,  4808,  1012,  2025,  2074,  4808,\n",
      "          1010,  2021, 21321,  1006, 15274,  4932,  2040,  1005,  2222,  2022,\n",
      "          2853,  2041,  2005,  1037, 15519,  1010, 13187,  2040,  1005,  2222,\n",
      "          3102,  2006,  2344,  1998,  2131,  2185,  2007,  2009,  1010,  2092,\n",
      "          5450,  2098,  1010,  2690,  2465, 13187,  2108,  2357,  2046,  3827,\n",
      "          7743,  2229,  2349,  2000,  2037,  3768,  1997,  2395,  4813,  2030,\n",
      "          3827,  3325,  1007,  3666, 11472,  1010,  2017,  2089,  2468,  6625,\n",
      "          2007,  2054,  2003,  8796, 10523,  1012,  1012,  1012,  1012,  2008,\n",
      "          2015,  2065,  2017,  2064,  2131,  1999,  3543,  2007,  2115,  9904,\n",
      "          2217,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "token_out = df['review'].apply(lambda x: tokenizer(x,padding='max_length',truncation=True,max_length=512,return_tensors='pt')).to_list()\n",
    "print(token_out[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43a3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TextDataset(Dataset):\n",
    "  def __init__(self, token_o,labels):\n",
    "    self.text = token_o\n",
    "    self.labels = labels\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  def __getitem__(self, idx):\n",
    "    label = torch.tensor(self.labels[idx])\n",
    "    text = self.text[idx]\n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a88c576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training len:\t valid len:\t test len:\n",
      "37500 \t\t 5000 \t\t 7500\n"
     ]
    }
   ],
   "source": [
    "total_len = len(token_out)\n",
    "training_ratio = 0.75\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.15\n",
    "train_len, valid_len, test_len = training_ratio*total_len, validation_ratio*total_len, test_ratio*total_len\n",
    "train_len, valid_len, test_len = int(train_len), int(valid_len), int(test_len)\n",
    "print('training len:\\t valid len:\\t test len:')\n",
    "print(train_len, '\\t\\t', valid_len, '\\t\\t',test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723bc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "TotalData = TextDataset(token_out, df['sentiment'].to_numpy())\n",
    "train, valid = random_split(TotalData, [train_len,total_len-train_len], \n",
    "                            generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c50015",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test = random_split(valid, [valid_len,len(valid)-valid_len], \n",
    "                           generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbbca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training len:\t valid len:\t test len:\n",
      "37500 \t\t 5000 \t\t 7500\n"
     ]
    }
   ],
   "source": [
    "print('training len:\\t valid len:\\t test len:')\n",
    "print(len(train), '\\t\\t', len(valid), '\\t\\t',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c8d8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7766673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2146,  2792, 15173,  3815,  1997,  2004, 24826, 15683,\n",
      "          1997, 20096,  1010, 10874,  1010,  6547,  1998,  5936,  2055,  1037,\n",
      "          2645,  1997, 25433,  1997, 20052,  2114,  2798, 11668, 23689, 16874,\n",
      "          2239,  1010,  1037,  3040, 25044,  2121,  1012,  2023,  2003,  2019,\n",
      "          6581,  2058, 10052,  2448,  7292,  1997,  7441, 12049,  1011,  9106,\n",
      "          2186,  1012,  1999,  1996,  2143,  3711,  5156,  9106,  1005,  1055,\n",
      "          8854,  2004,  7742, 26693, 13662,  1998,  3680,  6842,  1010,  2295,\n",
      "          2053, 22993, 23871,  1010,  2174,  2003,  1037,  4602, 12700,  1010,\n",
      "          2798, 11668,  1012,  2009,  1005,  1055,  1037, 10218, 17039, 27158,\n",
      "          2007, 20014, 27611,  1010, 16959,  2015,  1010,  1998, 23873,  1010,\n",
      "          2164,  2019, 10990,  2345,  9792,  1012,  2023,  2003,  1037,  3327,\n",
      "         20052,  3185,  2021,  2057,  2424,  2000,  9106,  4634,  1999,  2293,\n",
      "          2007,  1037,  7947,  1010,  7618,  1010,  6933,  1998,  2130, 26211,\n",
      "          2075,  1012,  2023,  2051,  2247,  2007,  1996,  2792,  1074, 29378,\n",
      "          9305,  1999,  8945, 29122,  2063, 29651,  2007, 12855, 17969,  1010,\n",
      "          2765,  2000,  2022,  1996,  2069,  2028,  2029,  9106,  2003,  4372,\n",
      "         22591,  5596,  1012,  2327,  1011, 18624, 12049,  2836,  1010,  2002,\n",
      "          4077,  2848, 12731, 12227,  2024,  1996,  2190, 20052,  2694,  1010,\n",
      "          2096,  1999,  1996,  5988,  2003,  5091, 14732,  9350,  2232, 14417,\n",
      "          1012, 12049, 10438,  2004,  1037, 24501,  4747, 28546,  1010,  4641,\n",
      "         15312,  2290,  1010, 17727,  3388,  8918, 22889, 13765,  2705,  1012,\n",
      "          2182,  3460,  7908,  3475,  1005,  1056,  1037,  5021,  1010, 28516,\n",
      "          7474,  1010,  1998, 22902, 14412,  2711,  7810,  2011, 12829,  5503,\n",
      "          1010,  2021,  2003,  2019,  2004, 24518,  1998, 23626,  4256,  2092,\n",
      "         27523, 12789,  3064,  2011,  3487,  2524,  7184,  2063,  1010,  1037,\n",
      "          3819,  4675,  8400,  1997, 12049,  1012,  9179,  2003, 19597, 12047,\n",
      "          1010,  2569,  5254,  2000,  2728,  9532,  2004,  2004, 24518, 11808,\n",
      "          1012,  9532,  1010,  2651,  3297,  2011,  2535,  2004, 17354, 11865,\n",
      "         11818,  1999,  4302, 10693,  1010,  2003,  1037,  8003,  3364,  2007,\n",
      "          5659,  2086,  1997,  2476,  1998,  2007,  2195,  3112,  2107,  2004,\n",
      "          1010,  1996,  6049,  2983,  1998, 10180, 10888,  1012,  7297,  3711,\n",
      "          2117, 12086,  5889,  2007, 27547,  4616,  1010,  4172,  6030,  2015,\n",
      "          4519,  1010,  8234,  5146,  1010, 14419,  5146,  1010,  2426,  2500,\n",
      "          1012,  1996,  3185,  4152,  1037, 14231,  7224,  1010,  1996,  2414,\n",
      "          4534,  1998, 19594,  6243,  2395,  1005,  1055,  2160,  2024,  2092,\n",
      "          2881,  1012,  1996,  4367,  3861,  2003,  2092,  2856,  2011,  2848,\n",
      "         11309,  1010,  2472,  1997,  2536,  4178,  1012,  2009,  1005,  1055,\n",
      "          1037,  2442,  2156,  2005,  1996,  4300, 16608, 11294,  4599,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "b2= bert.to(device)\n",
    "\n",
    "embed=b2(input_ids=train[0][0]['input_ids'].to(device),\n",
    "          attention_mask=train[0][0]['attention_mask'].to(device))\n",
    "\n",
    "\n",
    "\n",
    "print(embed[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59359aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "class BERTLSTMnn(nn.Module):\n",
    "  def __init__(self, bert, seq_len, n_layers):\n",
    "    super().__init__()\n",
    "    self.bert = bert\n",
    "    for i in self.bert.parameters():\n",
    "      i.requires_grad = False  # Freeze BERT parameters\n",
    "    embedding_size = bert.config.to_dict()['hidden_size']\n",
    "    self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                        hidden_size=seq_len, \n",
    "                        num_layers=n_layers,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.2)\n",
    "    self.dense = nn.Linear(seq_len, 1)\n",
    "    self.softmax = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, sentence):\n",
    "    embedded = self.bert(input_ids=sentence['input_ids'].squeeze(1),\n",
    "                           attention_mask=sentence['attention_mask'])\n",
    "      \n",
    "    out, (HiddenStates, CellStates) = self.lstm(embedded['last_hidden_state'])\n",
    "\n",
    "    output = self.dense(out[:, -1, :])  # Get the last time step output\n",
    "    output = self.softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc1c858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Batch Loss: 0.6920819282531738\n",
      "Batch Loss: 0.6845941543579102\n",
      "Batch Loss: 0.6811965703964233\n",
      "Batch Loss: 0.6859957575798035\n",
      "Batch Loss: 0.7178672552108765\n",
      "Batch Loss: 0.6754839420318604\n",
      "Batch Loss: 0.6838299036026001\n",
      "Batch Loss: 0.6731332540512085\n",
      "Batch Loss: 0.6679762005805969\n",
      "Batch Loss: 0.676271378993988\n",
      "Batch Loss: 0.6276028156280518\n",
      "Batch Loss: 0.6026493310928345\n",
      "Batch Loss: 0.6561583280563354\n",
      "Batch Loss: 0.7046667337417603\n",
      "Batch Loss: 0.6442412734031677\n",
      "Batch Loss: 0.6641668081283569\n",
      "Batch Loss: 0.6328604817390442\n",
      "Batch Loss: 0.5977702736854553\n",
      "Batch Loss: 0.5740159749984741\n",
      "Batch Loss: 0.6541840434074402\n",
      "Batch Loss: 0.6627797484397888\n",
      "Batch Loss: 0.6382341980934143\n",
      "Batch Loss: 0.6344977617263794\n",
      "Batch Loss: 0.6197805404663086\n",
      "Batch Loss: 0.6526685953140259\n",
      "Batch Loss: 0.6146706342697144\n",
      "Batch Loss: 0.6312329769134521\n",
      "Batch Loss: 0.6497822999954224\n",
      "Batch Loss: 0.6179473400115967\n",
      "Batch Loss: 0.6722896099090576\n",
      "Batch Loss: 0.6754106283187866\n",
      "Batch Loss: 0.6270014643669128\n",
      "Batch Loss: 0.7126051187515259\n",
      "Batch Loss: 0.6910473108291626\n",
      "Batch Loss: 0.800409734249115\n",
      "Batch Loss: 0.7751019597053528\n",
      "Batch Loss: 0.8547853231430054\n",
      "Batch Loss: 0.7707352042198181\n",
      "Batch Loss: 0.75074303150177\n",
      "Batch Loss: 0.6904356479644775\n",
      "Batch Loss: 0.8019875884056091\n",
      "Batch Loss: 0.7685534358024597\n",
      "Batch Loss: 0.7960503101348877\n",
      "Batch Loss: 0.7529317736625671\n",
      "Batch Loss: 0.7588685750961304\n",
      "Batch Loss: 0.7060617208480835\n",
      "Batch Loss: 0.9404178857803345\n",
      "Batch Loss: 0.9404165744781494\n",
      "Batch Loss: 0.8369882106781006\n",
      "Batch Loss: 0.7804288864135742\n",
      "Batch Loss: 0.6807510852813721\n",
      "Batch Loss: 0.8369845151901245\n",
      "Batch Loss: 0.743243932723999\n",
      "Batch Loss: 0.8622982501983643\n",
      "Batch Loss: 0.7157469987869263\n",
      "Batch Loss: 0.7001231908798218\n",
      "Batch Loss: 0.7276179194450378\n",
      "Batch Loss: 0.6726278066635132\n",
      "Batch Loss: 0.815423846244812\n",
      "Batch Loss: 0.7626177072525024\n",
      "Batch Loss: 0.7410553693771362\n",
      "Batch Loss: 0.7901122570037842\n",
      "Batch Loss: 0.8660433292388916\n",
      "Batch Loss: 0.6941863298416138\n",
      "Batch Loss: 0.7157456874847412\n",
      "Batch Loss: 0.8347944021224976\n",
      "Batch Loss: 0.9210315942764282\n",
      "Batch Loss: 0.7841691970825195\n",
      "Batch Loss: 0.6785606145858765\n",
      "Batch Loss: 0.8444756269454956\n",
      "Batch Loss: 0.856345534324646\n",
      "Batch Loss: 0.7194894552230835\n",
      "Batch Loss: 0.7879160046577454\n",
      "Batch Loss: 0.7997861504554749\n",
      "Batch Loss: 0.684491753578186\n",
      "Batch Loss: 0.8154001235961914\n",
      "Batch Loss: 0.8154035210609436\n",
      "Batch Loss: 0.7410354614257812\n",
      "Batch Loss: 0.7275968790054321\n",
      "Batch Loss: 0.7863314151763916\n",
      "Batch Loss: 0.8056949377059937\n",
      "Batch Loss: 0.7938218116760254\n",
      "Batch Loss: 0.7566372156143188\n",
      "Batch Loss: 0.8131700158119202\n",
      "Batch Loss: 0.8368965983390808\n",
      "Batch Loss: 0.8153263926506042\n",
      "Batch Loss: 0.7178645133972168\n",
      "Batch Loss: 0.8502669334411621\n",
      "Batch Loss: 0.8464813232421875\n",
      "Batch Loss: 0.8873158693313599\n",
      "Batch Loss: 0.809184730052948\n",
      "Batch Loss: 0.8090654611587524\n",
      "Batch Loss: 0.8303531408309937\n",
      "Batch Loss: 0.8861924409866333\n",
      "Batch Loss: 0.8289906978607178\n",
      "Batch Loss: 0.7689821124076843\n",
      "Batch Loss: 0.7276996374130249\n",
      "Batch Loss: 0.7757460474967957\n",
      "Batch Loss: 0.773218035697937\n",
      "Batch Loss: 0.7842006087303162\n",
      "Batch Loss: 0.7372649908065796\n",
      "Batch Loss: 0.7402518391609192\n",
      "Batch Loss: 0.6912574768066406\n",
      "Batch Loss: 0.7106330394744873\n",
      "Batch Loss: 0.6841992139816284\n",
      "Batch Loss: 0.6872769594192505\n",
      "Batch Loss: 0.6947088241577148\n",
      "Batch Loss: 0.6900568604469299\n",
      "Batch Loss: 0.6871219277381897\n",
      "Batch Loss: 0.6978414058685303\n",
      "Batch Loss: 0.6830222606658936\n",
      "Batch Loss: 0.6902757287025452\n",
      "Batch Loss: 0.6978602409362793\n",
      "Batch Loss: 0.6935915946960449\n",
      "Batch Loss: 0.7020578384399414\n",
      "Batch Loss: 0.6993675827980042\n",
      "Batch Loss: 0.6899712085723877\n",
      "Batch Loss: 0.696662187576294\n",
      "Batch Loss: 0.6989986300468445\n",
      "Batch Loss: 0.6998941898345947\n",
      "Batch Loss: 0.6932027339935303\n",
      "Batch Loss: 0.6835008859634399\n",
      "Batch Loss: 0.6947262287139893\n",
      "Batch Loss: 0.6991867423057556\n",
      "Batch Loss: 0.6974780559539795\n",
      "Batch Loss: 0.6893765926361084\n",
      "Batch Loss: 0.6922082304954529\n",
      "Batch Loss: 0.6900315284729004\n",
      "Batch Loss: 0.6883443593978882\n",
      "Batch Loss: 0.6918118000030518\n",
      "Batch Loss: 0.6876229047775269\n",
      "Batch Loss: 0.6930791139602661\n",
      "Batch Loss: 0.687193751335144\n",
      "Batch Loss: 0.6956126689910889\n",
      "Batch Loss: 0.6905364394187927\n",
      "Batch Loss: 0.6883890628814697\n",
      "Batch Loss: 0.6943910121917725\n",
      "Batch Loss: 0.6887562274932861\n",
      "Batch Loss: 0.690461277961731\n",
      "Batch Loss: 0.6962254047393799\n",
      "Batch Loss: 0.6993790864944458\n",
      "Batch Loss: 0.691314160823822\n",
      "Batch Loss: 0.6922121047973633\n",
      "Batch Loss: 0.6935574412345886\n",
      "Batch Loss: 0.6859437823295593\n",
      "Batch Loss: 0.6940096020698547\n",
      "Batch Loss: 0.6922037601470947\n",
      "Batch Loss: 0.6912776231765747\n",
      "Batch Loss: 0.6944933533668518\n",
      "Batch Loss: 0.6972567439079285\n",
      "Batch Loss: 0.6930943727493286\n",
      "Batch Loss: 0.685731053352356\n",
      "Batch Loss: 0.6949717998504639\n",
      "Batch Loss: 0.6884339451789856\n",
      "Batch Loss: 0.6940537095069885\n",
      "Batch Loss: 0.6912133693695068\n",
      "Batch Loss: 0.687409520149231\n",
      "Batch Loss: 0.6955230236053467\n",
      "Batch Loss: 0.6907047629356384\n",
      "Batch Loss: 0.6906872987747192\n",
      "Batch Loss: 0.699641764163971\n",
      "Batch Loss: 0.6996430158615112\n",
      "Batch Loss: 0.6966384649276733\n",
      "Batch Loss: 0.6941357851028442\n",
      "Batch Loss: 0.6970857977867126\n",
      "Batch Loss: 0.6897128820419312\n",
      "Batch Loss: 0.6844230890274048\n",
      "Batch Loss: 0.6916847229003906\n",
      "Batch Loss: 0.6936216354370117\n",
      "Batch Loss: 0.6916446685791016\n",
      "Batch Loss: 0.6955881118774414\n",
      "Batch Loss: 0.6887162923812866\n",
      "Batch Loss: 0.6931489706039429\n",
      "Batch Loss: 0.6951318979263306\n",
      "Batch Loss: 0.6956301331520081\n",
      "Batch Loss: 0.6975797414779663\n",
      "Batch Loss: 0.6931356191635132\n",
      "Batch Loss: 0.6965148448944092\n",
      "Batch Loss: 0.6979211568832397\n",
      "Batch Loss: 0.6916975975036621\n",
      "Batch Loss: 0.6958816051483154\n",
      "Batch Loss: 0.6894596815109253\n",
      "Batch Loss: 0.691761314868927\n",
      "Batch Loss: 0.695330023765564\n",
      "Batch Loss: 0.6930883526802063\n",
      "Batch Loss: 0.6935377717018127\n",
      "Batch Loss: 0.6922168135643005\n",
      "Batch Loss: 0.6905219554901123\n",
      "Batch Loss: 0.6862854957580566\n",
      "Batch Loss: 0.6913771629333496\n",
      "Batch Loss: 0.6922327280044556\n",
      "Batch Loss: 0.6892029643058777\n",
      "Batch Loss: 0.6939514875411987\n",
      "Batch Loss: 0.691338062286377\n",
      "Batch Loss: 0.6904392242431641\n",
      "Batch Loss: 0.6931109428405762\n",
      "Batch Loss: 0.6944593191146851\n",
      "Batch Loss: 0.6899294257164001\n",
      "Batch Loss: 0.688526451587677\n",
      "Batch Loss: 0.6898527145385742\n",
      "Batch Loss: 0.6959553956985474\n",
      "Batch Loss: 0.6936103105545044\n",
      "Batch Loss: 0.6969883441925049\n",
      "Batch Loss: 0.693603515625\n",
      "Batch Loss: 0.6940978765487671\n",
      "Batch Loss: 0.6926392912864685\n",
      "Batch Loss: 0.692636251449585\n",
      "Batch Loss: 0.6950507760047913\n",
      "Batch Loss: 0.6955236196517944\n",
      "Batch Loss: 0.689803957939148\n",
      "Batch Loss: 0.6921693682670593\n",
      "Batch Loss: 0.6850778460502625\n",
      "Batch Loss: 0.6907447576522827\n",
      "Batch Loss: 0.6892845630645752\n",
      "Batch Loss: 0.6911922693252563\n",
      "Batch Loss: 0.6807760000228882\n",
      "Batch Loss: 0.6829867362976074\n",
      "Batch Loss: 0.6837138533592224\n",
      "Batch Loss: 0.6915408372879028\n",
      "Batch Loss: 0.689237117767334\n",
      "Batch Loss: 0.6920642256736755\n",
      "Batch Loss: 0.6938932538032532\n",
      "Batch Loss: 0.6952077150344849\n",
      "Batch Loss: 0.7004364728927612\n",
      "Batch Loss: 0.6894328594207764\n",
      "Batch Loss: 0.696675717830658\n",
      "Batch Loss: 0.6966859698295593\n",
      "Batch Loss: 0.6906602382659912\n",
      "Batch Loss: 0.702781081199646\n",
      "Batch Loss: 0.6940534710884094\n",
      "Batch Loss: 0.697986364364624\n",
      "Batch Loss: 0.6972384452819824\n",
      "Batch Loss: 0.6920104026794434\n",
      "Batch Loss: 0.700196385383606\n",
      "Batch Loss: 0.6926526427268982\n",
      "Batch Loss: 0.6842955946922302\n",
      "Batch Loss: 0.6932587623596191\n",
      "Batch Loss: 0.6961830854415894\n",
      "Batch Loss: 0.6915233731269836\n",
      "Batch Loss: 0.6960735321044922\n",
      "Batch Loss: 0.6881762742996216\n",
      "Batch Loss: 0.6921058297157288\n",
      "Batch Loss: 0.6876559257507324\n",
      "Batch Loss: 0.6898744106292725\n",
      "Batch Loss: 0.6976593732833862\n",
      "Batch Loss: 0.6992932558059692\n",
      "Batch Loss: 0.6931902766227722\n",
      "Batch Loss: 0.6915539503097534\n",
      "Batch Loss: 0.6980235576629639\n",
      "Batch Loss: 0.6921266317367554\n",
      "Batch Loss: 0.6858270168304443\n",
      "Batch Loss: 0.6968165636062622\n",
      "Batch Loss: 0.6905598640441895\n",
      "Batch Loss: 0.692124605178833\n",
      "Batch Loss: 0.6941877007484436\n",
      "Batch Loss: 0.6941920518875122\n",
      "Batch Loss: 0.6936776041984558\n",
      "Batch Loss: 0.6992321610450745\n",
      "Batch Loss: 0.6876558065414429\n",
      "Batch Loss: 0.6971146464347839\n",
      "Batch Loss: 0.6892205476760864\n",
      "Batch Loss: 0.6989628672599792\n",
      "Batch Loss: 0.6888070106506348\n",
      "Batch Loss: 0.7031440734863281\n",
      "Batch Loss: 0.6917019486427307\n",
      "Batch Loss: 0.6875759363174438\n",
      "Batch Loss: 0.6949373483657837\n",
      "Batch Loss: 0.6940176486968994\n",
      "Batch Loss: 0.6935617327690125\n",
      "Batch Loss: 0.6913164258003235\n",
      "Batch Loss: 0.6886794567108154\n",
      "Batch Loss: 0.6935352087020874\n",
      "Batch Loss: 0.690018892288208\n",
      "Batch Loss: 0.6926554441452026\n",
      "Batch Loss: 0.6895691752433777\n",
      "Batch Loss: 0.6935286521911621\n",
      "Batch Loss: 0.6930816173553467\n",
      "Batch Loss: 0.6895281672477722\n",
      "Batch Loss: 0.7007251977920532\n",
      "Batch Loss: 0.6922136545181274\n",
      "Batch Loss: 0.6957658529281616\n",
      "Batch Loss: 0.6917699575424194\n",
      "Batch Loss: 0.6922194957733154\n",
      "Batch Loss: 0.6900251507759094\n",
      "Batch Loss: 0.6926556825637817\n",
      "Batch Loss: 0.6992290019989014\n",
      "Batch Loss: 0.6991875767707825\n",
      "Batch Loss: 0.6978036761283875\n",
      "Batch Loss: 0.6880291700363159\n",
      "Batch Loss: 0.687659740447998\n",
      "Batch Loss: 0.6997030973434448\n",
      "Batch Loss: 0.6918483376502991\n",
      "Batch Loss: 0.6918529272079468\n",
      "Batch Loss: 0.6902492046356201\n",
      "Batch Loss: 0.6938749551773071\n",
      "Batch Loss: 0.6954652070999146\n",
      "Batch Loss: 0.6938596367835999\n",
      "Batch Loss: 0.6926681995391846\n",
      "Batch Loss: 0.6868095397949219\n",
      "Batch Loss: 0.6961946487426758\n",
      "Batch Loss: 0.6895514726638794\n",
      "Batch Loss: 0.6914952993392944\n",
      "Batch Loss: 0.6911047697067261\n",
      "Batch Loss: 0.6903057098388672\n",
      "Batch Loss: 0.6950379014015198\n",
      "Batch Loss: 0.6922752857208252\n",
      "Batch Loss: 0.6946697235107422\n",
      "Batch Loss: 0.697464108467102\n",
      "Batch Loss: 0.6926752328872681\n",
      "Batch Loss: 0.6954469680786133\n",
      "Batch Loss: 0.6899097561836243\n",
      "Batch Loss: 0.6930661201477051\n",
      "Batch Loss: 0.6926750540733337\n",
      "Batch Loss: 0.6914961338043213\n",
      "Batch Loss: 0.6930575370788574\n",
      "Batch Loss: 0.6934579610824585\n",
      "Batch Loss: 0.6973708868026733\n",
      "Batch Loss: 0.6950064897537231\n",
      "Batch Loss: 0.6957497000694275\n",
      "Batch Loss: 0.6934452056884766\n",
      "Batch Loss: 0.6987044811248779\n",
      "Batch Loss: 0.6945350170135498\n",
      "Batch Loss: 0.6926878094673157\n",
      "Batch Loss: 0.6973303556442261\n",
      "Batch Loss: 0.6909418106079102\n",
      "Batch Loss: 0.6906266212463379\n",
      "Batch Loss: 0.696448564529419\n",
      "Batch Loss: 0.692363977432251\n",
      "Batch Loss: 0.693703293800354\n",
      "Batch Loss: 0.6950039863586426\n",
      "Batch Loss: 0.6956137418746948\n",
      "Batch Loss: 0.6939775943756104\n",
      "Batch Loss: 0.6924088001251221\n",
      "Batch Loss: 0.6914920806884766\n",
      "Batch Loss: 0.693630576133728\n",
      "Batch Loss: 0.6903072595596313\n",
      "Batch Loss: 0.6861249208450317\n",
      "Batch Loss: 0.6930298805236816\n",
      "Batch Loss: 0.6939374208450317\n",
      "Batch Loss: 0.69545578956604\n",
      "Batch Loss: 0.6963589787483215\n",
      "Batch Loss: 0.6948369145393372\n",
      "Batch Loss: 0.6915372014045715\n",
      "Batch Loss: 0.6900616884231567\n",
      "Batch Loss: 0.6936169266700745\n",
      "Batch Loss: 0.6953963041305542\n",
      "Batch Loss: 0.6897854804992676\n",
      "Batch Loss: 0.6933189034461975\n",
      "Batch Loss: 0.6924364566802979\n",
      "Batch Loss: 0.6924353837966919\n",
      "Batch Loss: 0.695096492767334\n",
      "Batch Loss: 0.6968579292297363\n",
      "Batch Loss: 0.6959505081176758\n",
      "Batch Loss: 0.6953394412994385\n",
      "Batch Loss: 0.6901735663414001\n",
      "Batch Loss: 0.6958631873130798\n",
      "Batch Loss: 0.6944313645362854\n",
      "Batch Loss: 0.6933015584945679\n",
      "Batch Loss: 0.6930195093154907\n",
      "Batch Loss: 0.6946510672569275\n",
      "Batch Loss: 0.690078854560852\n",
      "Batch Loss: 0.6938284039497375\n",
      "Batch Loss: 0.6956628561019897\n",
      "Batch Loss: 0.6951093077659607\n",
      "Batch Loss: 0.6909596920013428\n",
      "Batch Loss: 0.6917523145675659\n",
      "Batch Loss: 0.6948065757751465\n",
      "Batch Loss: 0.6922634840011597\n",
      "Batch Loss: 0.6922651529312134\n",
      "Batch Loss: 0.6927731037139893\n",
      "Batch Loss: 0.6915304064750671\n",
      "Batch Loss: 0.6937676668167114\n",
      "Batch Loss: 0.6895523071289062\n",
      "Batch Loss: 0.693026065826416\n",
      "Batch Loss: 0.6905196905136108\n",
      "Batch Loss: 0.6922624111175537\n",
      "Batch Loss: 0.6930173635482788\n",
      "Batch Loss: 0.6935330629348755\n",
      "Batch Loss: 0.6935380697250366\n",
      "Batch Loss: 0.6930221319198608\n",
      "Batch Loss: 0.6919828653335571\n",
      "Batch Loss: 0.6914491057395935\n",
      "Batch Loss: 0.6959065794944763\n",
      "Batch Loss: 0.6927574872970581\n",
      "Batch Loss: 0.6911736130714417\n",
      "Batch Loss: 0.693018913269043\n",
      "Batch Loss: 0.6911546587944031\n",
      "Batch Loss: 0.6916886568069458\n",
      "Batch Loss: 0.6951899528503418\n",
      "Batch Loss: 0.6911221742630005\n",
      "Batch Loss: 0.6913934946060181\n",
      "Batch Loss: 0.6908234357833862\n",
      "Batch Loss: 0.6916346549987793\n",
      "Batch Loss: 0.691896915435791\n",
      "Batch Loss: 0.6915984153747559\n",
      "Batch Loss: 0.6924530267715454\n",
      "Batch Loss: 0.692153811454773\n",
      "Batch Loss: 0.6945031881332397\n",
      "Batch Loss: 0.6903402805328369\n",
      "Batch Loss: 0.6897035837173462\n",
      "Batch Loss: 0.689966082572937\n",
      "Batch Loss: 0.6908456683158875\n",
      "Batch Loss: 0.693034291267395\n",
      "Batch Loss: 0.6888251304626465\n",
      "Batch Loss: 0.6933681964874268\n",
      "Batch Loss: 0.6943929195404053\n",
      "Batch Loss: 0.6923483610153198\n",
      "Batch Loss: 0.6860647201538086\n",
      "Batch Loss: 0.6880009174346924\n",
      "Batch Loss: 0.6911705732345581\n",
      "Batch Loss: 0.6977459192276001\n",
      "Batch Loss: 0.6894773244857788\n",
      "Batch Loss: 0.6983977556228638\n",
      "Batch Loss: 0.6914242506027222\n",
      "Batch Loss: 0.6939094066619873\n",
      "Batch Loss: 0.6905628442764282\n",
      "Batch Loss: 0.695605993270874\n",
      "Batch Loss: 0.6922184824943542\n",
      "Batch Loss: 0.6884106397628784\n",
      "Batch Loss: 0.6935107707977295\n",
      "Batch Loss: 0.6909394860267639\n",
      "Batch Loss: 0.6943936944007874\n",
      "Batch Loss: 0.6926643252372742\n",
      "Batch Loss: 0.6913055181503296\n",
      "Batch Loss: 0.6984930038452148\n",
      "Batch Loss: 0.6917437314987183\n",
      "Batch Loss: 0.6926438808441162\n",
      "Batch Loss: 0.6917251944541931\n",
      "Batch Loss: 0.6944489479064941\n",
      "Batch Loss: 0.691277265548706\n",
      "Batch Loss: 0.6921608448028564\n",
      "Batch Loss: 0.6912756562232971\n",
      "Batch Loss: 0.6944794654846191\n",
      "Batch Loss: 0.6926497220993042\n",
      "Batch Loss: 0.6889714002609253\n",
      "Batch Loss: 0.6968011260032654\n",
      "Batch Loss: 0.6931389570236206\n",
      "Batch Loss: 0.6995906829833984\n",
      "Batch Loss: 0.6976439952850342\n",
      "Batch Loss: 0.6926418542861938\n",
      "Batch Loss: 0.686506986618042\n",
      "Batch Loss: 0.6913548111915588\n",
      "Batch Loss: 0.6922106742858887\n",
      "Batch Loss: 0.6948227286338806\n",
      "Batch Loss: 0.6956963539123535\n",
      "Batch Loss: 0.6930848956108093\n",
      "Batch Loss: 0.6866784691810608\n",
      "Batch Loss: 0.6943785548210144\n",
      "Batch Loss: 0.6921995878219604\n",
      "Batch Loss: 0.690503716468811\n",
      "Batch Loss: 0.6930800676345825\n",
      "Batch Loss: 0.6922101974487305\n",
      "Batch Loss: 0.6921826601028442\n",
      "Batch Loss: 0.6952629685401917\n",
      "Batch Loss: 0.6961717009544373\n",
      "Batch Loss: 0.6861060261726379\n",
      "Batch Loss: 0.696166455745697\n",
      "Batch Loss: 0.6904665231704712\n",
      "Batch Loss: 0.6952889561653137\n",
      "Batch Loss: 0.6939941048622131\n",
      "Batch Loss: 0.6939424872398376\n",
      "Batch Loss: 0.6895658373832703\n",
      "Batch Loss: 0.6930980682373047\n",
      "Batch Loss: 0.6895944476127625\n",
      "Batch Loss: 0.6948387622833252\n",
      "Batch Loss: 0.7006057500839233\n",
      "Batch Loss: 0.6952552795410156\n",
      "Batch Loss: 0.6909406185150146\n",
      "Batch Loss: 0.6930669546127319\n",
      "Batch Loss: 0.6947561502456665\n",
      "Batch Loss: 0.693897545337677\n",
      "Batch Loss: 0.6901750564575195\n",
      "Batch Loss: 0.6934826374053955\n",
      "Batch Loss: 0.6886079907417297\n",
      "Batch Loss: 0.6906365752220154\n",
      "Batch Loss: 0.6914396286010742\n",
      "Batch Loss: 0.7000223994255066\n",
      "Batch Loss: 0.691428542137146\n",
      "Batch Loss: 0.6938607692718506\n",
      "Batch Loss: 0.6930599212646484\n",
      "Batch Loss: 0.6898483037948608\n",
      "Batch Loss: 0.6902350783348083\n",
      "Batch Loss: 0.6954998970031738\n",
      "Batch Loss: 0.6938686370849609\n",
      "Batch Loss: 0.6962975859642029\n",
      "Batch Loss: 0.6942782402038574\n",
      "Batch Loss: 0.6922476291656494\n",
      "Batch Loss: 0.6934595704078674\n",
      "Batch Loss: 0.6930675506591797\n",
      "Batch Loss: 0.6926599740982056\n",
      "Batch Loss: 0.6911008954048157\n",
      "Batch Loss: 0.6969271898269653\n",
      "Batch Loss: 0.6884393692016602\n",
      "Batch Loss: 0.6918913125991821\n",
      "Batch Loss: 0.6891979575157166\n",
      "Batch Loss: 0.69187331199646\n",
      "Batch Loss: 0.6918802261352539\n",
      "Batch Loss: 0.689864993095398\n",
      "Batch Loss: 0.6994640231132507\n",
      "Batch Loss: 0.6938566565513611\n",
      "Batch Loss: 0.6998757123947144\n",
      "Batch Loss: 0.6970264315605164\n",
      "Batch Loss: 0.6942082643508911\n",
      "Batch Loss: 0.6869726181030273\n",
      "Batch Loss: 0.693052351474762\n",
      "Batch Loss: 0.6907920837402344\n",
      "Batch Loss: 0.6930517554283142\n",
      "Batch Loss: 0.6915625929832458\n",
      "Batch Loss: 0.6922930479049683\n",
      "Batch Loss: 0.6937860250473022\n",
      "Batch Loss: 0.6937892436981201\n",
      "Batch Loss: 0.691569447517395\n",
      "Batch Loss: 0.6934128999710083\n",
      "Batch Loss: 0.6893346309661865\n",
      "Batch Loss: 0.6934318542480469\n",
      "Batch Loss: 0.6934020519256592\n",
      "Batch Loss: 0.6926631331443787\n",
      "Batch Loss: 0.6919131278991699\n",
      "Batch Loss: 0.6869654655456543\n",
      "Batch Loss: 0.6911077499389648\n",
      "Batch Loss: 0.6965826749801636\n",
      "Batch Loss: 0.6910814046859741\n",
      "Batch Loss: 0.6842371225357056\n",
      "Batch Loss: 0.6959081888198853\n",
      "Batch Loss: 0.6930363178253174\n",
      "Batch Loss: 0.7024070620536804\n",
      "Batch Loss: 0.6922369003295898\n",
      "Batch Loss: 0.6922333836555481\n",
      "Batch Loss: 0.6913629770278931\n",
      "Batch Loss: 0.6876040697097778\n",
      "Batch Loss: 0.6956067085266113\n",
      "Batch Loss: 0.6951979398727417\n",
      "Batch Loss: 0.6934653520584106\n",
      "Batch Loss: 0.6934763193130493\n",
      "Batch Loss: 0.6976770162582397\n",
      "Batch Loss: 0.6926038265228271\n",
      "Batch Loss: 0.6913853883743286\n",
      "Batch Loss: 0.6946656703948975\n",
      "Batch Loss: 0.6890355348587036\n",
      "Batch Loss: 0.6894299387931824\n",
      "Batch Loss: 0.6966598033905029\n",
      "Batch Loss: 0.696656346321106\n",
      "Batch Loss: 0.6914185285568237\n",
      "Batch Loss: 0.6914316415786743\n",
      "Batch Loss: 0.6958320140838623\n",
      "Batch Loss: 0.696178674697876\n",
      "Batch Loss: 0.6937501430511475\n",
      "Batch Loss: 0.691826343536377\n",
      "Batch Loss: 0.690716028213501\n",
      "Batch Loss: 0.6910597681999207\n",
      "Batch Loss: 0.695283055305481\n",
      "Batch Loss: 0.693771243095398\n",
      "Batch Loss: 0.6937803626060486\n",
      "Batch Loss: 0.6914180517196655\n",
      "Batch Loss: 0.6910783052444458\n",
      "Batch Loss: 0.6967611312866211\n",
      "Batch Loss: 0.6881945133209229\n",
      "Batch Loss: 0.6907556056976318\n",
      "Batch Loss: 0.6910890936851501\n",
      "Batch Loss: 0.6929682493209839\n",
      "Batch Loss: 0.6887474060058594\n",
      "Batch Loss: 0.6913828253746033\n",
      "Batch Loss: 0.6974990367889404\n",
      "Batch Loss: 0.6934547424316406\n",
      "Batch Loss: 0.7016081213951111\n",
      "Batch Loss: 0.6877961754798889\n",
      "Batch Loss: 0.6909876465797424\n",
      "Batch Loss: 0.6929615139961243\n",
      "Batch Loss: 0.697826623916626\n",
      "Batch Loss: 0.6917989253997803\n",
      "Batch Loss: 0.6886885166168213\n",
      "Batch Loss: 0.6909992098808289\n",
      "Batch Loss: 0.6870802640914917\n",
      "Batch Loss: 0.690920889377594\n",
      "Batch Loss: 0.6921707987785339\n",
      "Batch Loss: 0.6951727867126465\n",
      "Batch Loss: 0.6865178346633911\n",
      "Batch Loss: 0.6925851106643677\n",
      "Batch Loss: 0.6939424276351929\n",
      "Batch Loss: 0.7003272771835327\n",
      "Batch Loss: 0.6997107863426208\n",
      "Batch Loss: 0.6929231882095337\n",
      "Batch Loss: 0.6954342126846313\n",
      "Batch Loss: 0.693475604057312\n",
      "Batch Loss: 0.6950086951255798\n",
      "Batch Loss: 0.6953741908073425\n",
      "Epoch 1/20, Loss: 0.701520633473738, Time: 505.60s\n",
      "Batch Loss: 0.6933611035346985\n",
      "Batch Loss: 0.6929898858070374\n",
      "Batch Loss: 0.6964486837387085\n",
      "Batch Loss: 0.6963462829589844\n",
      "Batch Loss: 0.6939944624900818\n",
      "Batch Loss: 0.6899030804634094\n",
      "Batch Loss: 0.6921122074127197\n",
      "Batch Loss: 0.6941996812820435\n",
      "Batch Loss: 0.6921305656433105\n",
      "Batch Loss: 0.6988255977630615\n",
      "Batch Loss: 0.6907345056533813\n",
      "Batch Loss: 0.6938519477844238\n",
      "Batch Loss: 0.6910667419433594\n",
      "Batch Loss: 0.6930164098739624\n",
      "Batch Loss: 0.6927398443222046\n",
      "Batch Loss: 0.6889920234680176\n",
      "Batch Loss: 0.6943445801734924\n",
      "Batch Loss: 0.6919397115707397\n",
      "Batch Loss: 0.6940816640853882\n",
      "Batch Loss: 0.6943380832672119\n",
      "Batch Loss: 0.6919162273406982\n",
      "Batch Loss: 0.6919111013412476\n",
      "Batch Loss: 0.6935077905654907\n",
      "Batch Loss: 0.6898107528686523\n",
      "Batch Loss: 0.692187488079071\n",
      "Batch Loss: 0.6970648765563965\n",
      "Batch Loss: 0.6899996399879456\n",
      "Batch Loss: 0.6919023990631104\n",
      "Batch Loss: 0.6921552419662476\n",
      "Batch Loss: 0.6904217004776001\n",
      "Batch Loss: 0.6932452917098999\n",
      "Batch Loss: 0.6923832297325134\n",
      "Batch Loss: 0.6926488280296326\n",
      "Batch Loss: 0.6938129663467407\n",
      "Batch Loss: 0.6941436529159546\n",
      "Batch Loss: 0.6938381195068359\n",
      "Batch Loss: 0.6902365684509277\n",
      "Batch Loss: 0.6934791803359985\n",
      "Batch Loss: 0.6913406848907471\n",
      "Batch Loss: 0.6931855082511902\n",
      "Batch Loss: 0.6912399530410767\n",
      "Batch Loss: 0.6912664771080017\n",
      "Batch Loss: 0.6931439638137817\n",
      "Batch Loss: 0.693135678768158\n",
      "Batch Loss: 0.6887283325195312\n",
      "Batch Loss: 0.697955846786499\n",
      "Batch Loss: 0.6908969283103943\n",
      "Batch Loss: 0.691445529460907\n",
      "Batch Loss: 0.6913851499557495\n",
      "Batch Loss: 0.6934186220169067\n",
      "Batch Loss: 0.6937016248703003\n",
      "Batch Loss: 0.690629243850708\n",
      "Batch Loss: 0.6947271823883057\n",
      "Batch Loss: 0.6906206607818604\n",
      "Batch Loss: 0.6895033121109009\n",
      "Batch Loss: 0.6888266801834106\n",
      "Batch Loss: 0.6899359226226807\n",
      "Batch Loss: 0.6893985271453857\n",
      "Batch Loss: 0.6892606019973755\n",
      "Batch Loss: 0.6905543804168701\n",
      "Batch Loss: 0.6876907348632812\n",
      "Batch Loss: 0.7011862993240356\n",
      "Batch Loss: 0.6901888847351074\n",
      "Batch Loss: 0.686631441116333\n",
      "Batch Loss: 0.6950826644897461\n",
      "Batch Loss: 0.6855412721633911\n",
      "Batch Loss: 0.6971516013145447\n",
      "Batch Loss: 0.6981496810913086\n",
      "Batch Loss: 0.6993786096572876\n",
      "Batch Loss: 0.691144585609436\n",
      "Batch Loss: 0.6933262348175049\n",
      "Batch Loss: 0.6947448253631592\n",
      "Batch Loss: 0.6988997459411621\n",
      "Batch Loss: 0.6905364394187927\n",
      "Batch Loss: 0.6881884336471558\n",
      "Batch Loss: 0.6900969743728638\n",
      "Batch Loss: 0.6955608129501343\n",
      "Batch Loss: 0.6926811933517456\n",
      "Batch Loss: 0.6869131326675415\n",
      "Batch Loss: 0.6898425817489624\n",
      "Batch Loss: 0.695796549320221\n",
      "Batch Loss: 0.6892411708831787\n",
      "Batch Loss: 0.693374514579773\n",
      "Batch Loss: 0.6918723583221436\n",
      "Batch Loss: 0.687625527381897\n",
      "Batch Loss: 0.6897845268249512\n",
      "Batch Loss: 0.6873517036437988\n",
      "Batch Loss: 0.6929882168769836\n",
      "Batch Loss: 0.684721052646637\n",
      "Batch Loss: 0.6853101849555969\n",
      "Batch Loss: 0.6947892904281616\n",
      "Batch Loss: 0.6866827011108398\n",
      "Batch Loss: 0.691062331199646\n",
      "Batch Loss: 0.6786353588104248\n",
      "Batch Loss: 0.6935125589370728\n",
      "Batch Loss: 0.6828579902648926\n",
      "Batch Loss: 0.6710706949234009\n",
      "Batch Loss: 0.6767635345458984\n",
      "Batch Loss: 0.6704630851745605\n",
      "Batch Loss: 0.6887458562850952\n",
      "Batch Loss: 0.6852620840072632\n",
      "Batch Loss: 0.6720600724220276\n",
      "Batch Loss: 0.6860486268997192\n",
      "Batch Loss: 0.6601034998893738\n",
      "Batch Loss: 0.6607792973518372\n",
      "Batch Loss: 0.6662669777870178\n",
      "Batch Loss: 0.6653841137886047\n",
      "Batch Loss: 0.6700435876846313\n",
      "Batch Loss: 0.6432053446769714\n",
      "Batch Loss: 0.6504809856414795\n",
      "Batch Loss: 0.6533650159835815\n",
      "Batch Loss: 0.6383746266365051\n",
      "Batch Loss: 0.6367133855819702\n",
      "Batch Loss: 0.6520075798034668\n",
      "Batch Loss: 0.6750566959381104\n",
      "Batch Loss: 0.6382958292961121\n",
      "Batch Loss: 0.6509483456611633\n",
      "Batch Loss: 0.6381725072860718\n",
      "Batch Loss: 0.6636916399002075\n",
      "Batch Loss: 0.6507763862609863\n",
      "Batch Loss: 0.6428372859954834\n",
      "Batch Loss: 0.6410938501358032\n",
      "Batch Loss: 0.6210724115371704\n",
      "Batch Loss: 0.6333189606666565\n",
      "Batch Loss: 0.653708815574646\n",
      "Batch Loss: 0.6781206130981445\n",
      "Batch Loss: 0.6587175130844116\n",
      "Batch Loss: 0.6868473887443542\n",
      "Batch Loss: 0.6331551671028137\n",
      "Batch Loss: 0.6362159252166748\n",
      "Batch Loss: 0.6479485630989075\n",
      "Batch Loss: 0.6562161445617676\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6705820560455322\n",
      "Batch Loss: 0.6697800159454346\n",
      "Batch Loss: 0.6872602105140686\n",
      "Batch Loss: 0.652295708656311\n",
      "Batch Loss: 0.6700810194015503\n",
      "Batch Loss: 0.658190131187439\n",
      "Batch Loss: 0.6667044758796692\n",
      "Batch Loss: 0.659093976020813\n",
      "Batch Loss: 0.664078414440155\n",
      "Batch Loss: 0.6509062647819519\n",
      "Batch Loss: 0.6245443224906921\n",
      "Batch Loss: 0.6618565917015076\n",
      "Batch Loss: 0.6735395789146423\n",
      "Batch Loss: 0.6580801606178284\n",
      "Batch Loss: 0.6640055179595947\n",
      "Batch Loss: 0.6907976865768433\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6480006575584412\n",
      "Batch Loss: 0.6347999572753906\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6698960065841675\n",
      "Batch Loss: 0.640454888343811\n",
      "Batch Loss: 0.6622474789619446\n",
      "Batch Loss: 0.6466111540794373\n",
      "Batch Loss: 0.6701081395149231\n",
      "Batch Loss: 0.6736217141151428\n",
      "Batch Loss: 0.6522849798202515\n",
      "Batch Loss: 0.6698577404022217\n",
      "Batch Loss: 0.6505371928215027\n",
      "Batch Loss: 0.6579768657684326\n",
      "Batch Loss: 0.6584113836288452\n",
      "Batch Loss: 0.6467480659484863\n",
      "Batch Loss: 0.670049250125885\n",
      "Batch Loss: 0.6559885740280151\n",
      "Batch Loss: 0.6462926268577576\n",
      "Batch Loss: 0.6765676736831665\n",
      "Batch Loss: 0.6698171496391296\n",
      "Batch Loss: 0.6583513021469116\n",
      "Batch Loss: 0.6520026922225952\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6517965793609619\n",
      "Batch Loss: 0.661880612373352\n",
      "Batch Loss: 0.6464477777481079\n",
      "Batch Loss: 0.6820055246353149\n",
      "Batch Loss: 0.6464371085166931\n",
      "Batch Loss: 0.6638540625572205\n",
      "Batch Loss: 0.6733494997024536\n",
      "Batch Loss: 0.6949093341827393\n",
      "Batch Loss: 0.6699725389480591\n",
      "Batch Loss: 0.6697809100151062\n",
      "Batch Loss: 0.6580946445465088\n",
      "Batch Loss: 0.6618447303771973\n",
      "Batch Loss: 0.657902717590332\n",
      "Batch Loss: 0.6446436047554016\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6384506821632385\n",
      "Batch Loss: 0.6695845127105713\n",
      "Batch Loss: 0.6833840608596802\n",
      "Batch Loss: 0.6519527435302734\n",
      "Batch Loss: 0.6463678479194641\n",
      "Batch Loss: 0.663819432258606\n",
      "Batch Loss: 0.6519455909729004\n",
      "Batch Loss: 0.6517704725265503\n",
      "Batch Loss: 0.6639846563339233\n",
      "Batch Loss: 0.6636396050453186\n",
      "Batch Loss: 0.6638085842132568\n",
      "Batch Loss: 0.66991126537323\n",
      "Batch Loss: 0.6582049131393433\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6463256478309631\n",
      "Batch Loss: 0.6906899213790894\n",
      "Batch Loss: 0.6641253232955933\n",
      "Batch Loss: 0.6695675849914551\n",
      "Batch Loss: 0.6520845890045166\n",
      "Batch Loss: 0.6637917757034302\n",
      "Batch Loss: 0.6578545570373535\n",
      "Batch Loss: 0.6500546932220459\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6581657528877258\n",
      "Batch Loss: 0.658004879951477\n",
      "Batch Loss: 0.6814322471618652\n",
      "Batch Loss: 0.6228525042533875\n",
      "Batch Loss: 0.6498790979385376\n",
      "Batch Loss: 0.6345587968826294\n",
      "Batch Loss: 0.6736160516738892\n",
      "Batch Loss: 0.6461166143417358\n",
      "Batch Loss: 0.6552495360374451\n",
      "Batch Loss: 0.7009539604187012\n",
      "Batch Loss: 0.6598491668701172\n",
      "Batch Loss: 0.6911130547523499\n",
      "Batch Loss: 0.6639101505279541\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6640507578849792\n",
      "Batch Loss: 0.6637580394744873\n",
      "Batch Loss: 0.6460932493209839\n",
      "Batch Loss: 0.6578191518783569\n",
      "Batch Loss: 0.6521664261817932\n",
      "Batch Loss: 0.6638932228088379\n",
      "Batch Loss: 0.6737208366394043\n",
      "Batch Loss: 0.6520168781280518\n",
      "Batch Loss: 0.675618052482605\n",
      "Batch Loss: 0.6517354249954224\n",
      "Batch Loss: 0.6282666921615601\n",
      "Batch Loss: 0.6518706679344177\n",
      "Batch Loss: 0.6224627494812012\n",
      "Batch Loss: 0.6346014738082886\n",
      "Batch Loss: 0.6576672792434692\n",
      "Batch Loss: 0.6579335927963257\n",
      "Batch Loss: 0.6402568817138672\n",
      "Batch Loss: 0.6579288244247437\n",
      "Batch Loss: 0.6674845218658447\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6674816608428955\n",
      "Batch Loss: 0.679351806640625\n",
      "Batch Loss: 0.6519824862480164\n",
      "Batch Loss: 0.669787585735321\n",
      "Batch Loss: 0.6282356977462769\n",
      "Batch Loss: 0.6521031260490417\n",
      "Batch Loss: 0.6460387706756592\n",
      "Batch Loss: 0.6755902767181396\n",
      "Batch Loss: 0.6576573252677917\n",
      "Batch Loss: 0.6695281267166138\n",
      "Batch Loss: 0.6404651403427124\n",
      "Batch Loss: 0.655963659286499\n",
      "Batch Loss: 0.6675878763198853\n",
      "Batch Loss: 0.6755824685096741\n",
      "Batch Loss: 0.6852707862854004\n",
      "Batch Loss: 0.6672605872154236\n",
      "Batch Loss: 0.6695236563682556\n",
      "Batch Loss: 0.667934775352478\n",
      "Batch Loss: 0.640434741973877\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6695212721824646\n",
      "Batch Loss: 0.6519460678100586\n",
      "Batch Loss: 0.667801022529602\n",
      "Batch Loss: 0.6462371349334717\n",
      "Batch Loss: 0.6518262028694153\n",
      "Batch Loss: 0.667563796043396\n",
      "Batch Loss: 0.6579859256744385\n",
      "Batch Loss: 0.6461121439933777\n",
      "Batch Loss: 0.6675581932067871\n",
      "Batch Loss: 0.6734919548034668\n",
      "Batch Loss: 0.6578652858734131\n",
      "Batch Loss: 0.6579734086990356\n",
      "Batch Loss: 0.6637972593307495\n",
      "Batch Loss: 0.6494495868682861\n",
      "Batch Loss: 0.6698377132415771\n",
      "Batch Loss: 0.6729764342308044\n",
      "Batch Loss: 0.6556726694107056\n",
      "Batch Loss: 0.658066987991333\n",
      "Batch Loss: 0.6461929082870483\n",
      "Batch Loss: 0.6695101261138916\n",
      "Batch Loss: 0.6517024040222168\n",
      "Batch Loss: 0.6673269867897034\n",
      "Batch Loss: 0.652014434337616\n",
      "Batch Loss: 0.682951033115387\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6619045734405518\n",
      "Batch Loss: 0.651904821395874\n",
      "Batch Loss: 0.6578391790390015\n",
      "Batch Loss: 0.6341967582702637\n",
      "Batch Loss: 0.6399281024932861\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6578338742256165\n",
      "Batch Loss: 0.6519968509674072\n",
      "Batch Loss: 0.6698024272918701\n",
      "Batch Loss: 0.6399238109588623\n",
      "Batch Loss: 0.675438642501831\n",
      "Batch Loss: 0.6754382848739624\n",
      "Batch Loss: 0.6755356788635254\n",
      "Batch Loss: 0.645953893661499\n",
      "Batch Loss: 0.6886189579963684\n",
      "Batch Loss: 0.6695010662078857\n",
      "Batch Loss: 0.6733508110046387\n",
      "Batch Loss: 0.6400142908096313\n",
      "Batch Loss: 0.6813716292381287\n",
      "Batch Loss: 0.6615732908248901\n",
      "Batch Loss: 0.6518830060958862\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.667506217956543\n",
      "Batch Loss: 0.6636573672294617\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6615679264068604\n",
      "Batch Loss: 0.6849651336669922\n",
      "Batch Loss: 0.6829404830932617\n",
      "Batch Loss: 0.6457545757293701\n",
      "Batch Loss: 0.6579041481018066\n",
      "Batch Loss: 0.663561224937439\n",
      "Batch Loss: 0.6577175855636597\n",
      "Batch Loss: 0.6579012870788574\n",
      "Batch Loss: 0.6460286378860474\n",
      "Batch Loss: 0.6847832202911377\n",
      "Batch Loss: 0.6754313111305237\n",
      "Batch Loss: 0.6458436250686646\n",
      "Batch Loss: 0.6793661117553711\n",
      "Batch Loss: 0.6694949865341187\n",
      "Batch Loss: 0.6282157897949219\n",
      "Batch Loss: 0.6461119055747986\n",
      "Batch Loss: 0.634059488773346\n",
      "Batch Loss: 0.6754295229911804\n",
      "Batch Loss: 0.640082597732544\n",
      "Batch Loss: 0.6578885316848755\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6401671171188354\n",
      "Batch Loss: 0.6733337640762329\n",
      "Batch Loss: 0.6458367109298706\n",
      "Batch Loss: 0.6793554425239563\n",
      "Batch Loss: 0.6578809022903442\n",
      "Batch Loss: 0.6636419296264648\n",
      "Batch Loss: 0.6342217326164246\n",
      "Batch Loss: 0.6651525497436523\n",
      "Batch Loss: 0.6340470314025879\n",
      "Batch Loss: 0.6635539531707764\n",
      "Batch Loss: 0.6458315253257751\n",
      "Batch Loss: 0.657787024974823\n",
      "Batch Loss: 0.6594420075416565\n",
      "Batch Loss: 0.6577010154724121\n",
      "Batch Loss: 0.6791774034500122\n",
      "Batch Loss: 0.6614534854888916\n",
      "Batch Loss: 0.6461607813835144\n",
      "Batch Loss: 0.6576986312866211\n",
      "Batch Loss: 0.6813583374023438\n",
      "Batch Loss: 0.6637154817581177\n",
      "Batch Loss: 0.651679277420044\n",
      "Batch Loss: 0.6378703713417053\n",
      "Batch Loss: 0.6944994926452637\n",
      "Batch Loss: 0.6637121438980103\n",
      "Batch Loss: 0.6576138138771057\n",
      "Batch Loss: 0.6694850325584412\n",
      "Batch Loss: 0.634353518486023\n",
      "Batch Loss: 0.669484555721283\n",
      "Batch Loss: 0.6614465117454529\n",
      "Batch Loss: 0.6517566442489624\n",
      "Batch Loss: 0.6696426868438721\n",
      "Batch Loss: 0.651755690574646\n",
      "Batch Loss: 0.6280123591423035\n",
      "Batch Loss: 0.663783609867096\n",
      "Batch Loss: 0.6615219116210938\n",
      "Batch Loss: 0.6734707355499268\n",
      "Batch Loss: 0.6791715621948242\n",
      "Batch Loss: 0.6497257947921753\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6378524303436279\n",
      "Batch Loss: 0.6613633632659912\n",
      "Batch Loss: 0.6673755645751953\n",
      "Batch Loss: 0.6576857566833496\n",
      "Batch Loss: 0.6793222427368164\n",
      "Batch Loss: 0.6401057243347168\n",
      "Batch Loss: 0.6556535959243774\n",
      "Batch Loss: 0.673308789730072\n",
      "Batch Loss: 0.6558017134666443\n",
      "Batch Loss: 0.6516721248626709\n",
      "Batch Loss: 0.651746392250061\n",
      "Batch Loss: 0.6577559113502502\n",
      "Batch Loss: 0.6790421009063721\n",
      "Batch Loss: 0.6437234282493591\n",
      "Batch Loss: 0.6576800346374512\n",
      "Batch Loss: 0.6694777011871338\n",
      "Batch Loss: 0.6518166661262512\n",
      "Batch Loss: 0.6696231365203857\n",
      "Batch Loss: 0.6734488010406494\n",
      "Batch Loss: 0.6341522932052612\n",
      "Batch Loss: 0.6341509819030762\n",
      "Batch Loss: 0.669620156288147\n",
      "Batch Loss: 0.6495802402496338\n",
      "Batch Loss: 0.6400827765464783\n",
      "Batch Loss: 0.6614997982978821\n",
      "Batch Loss: 0.6889245510101318\n",
      "Batch Loss: 0.6402902603149414\n",
      "Batch Loss: 0.6400770545005798\n",
      "Batch Loss: 0.6161227822303772\n",
      "Batch Loss: 0.6519452333450317\n",
      "Batch Loss: 0.6636072397232056\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6731100082397461\n",
      "Batch Loss: 0.6636056900024414\n",
      "Batch Loss: 0.6791619062423706\n",
      "Batch Loss: 0.6341303586959839\n",
      "Batch Loss: 0.6518008708953857\n",
      "Batch Loss: 0.6695395708084106\n",
      "Batch Loss: 0.6554856300354004\n",
      "Batch Loss: 0.6339915990829468\n",
      "Batch Loss: 0.6517981290817261\n",
      "Batch Loss: 0.6615536212921143\n",
      "Batch Loss: 0.6438118815422058\n",
      "Batch Loss: 0.663534939289093\n",
      "Batch Loss: 0.6695364117622375\n",
      "Batch Loss: 0.6517946720123291\n",
      "Batch Loss: 0.6635998487472534\n",
      "Batch Loss: 0.6339209079742432\n",
      "Batch Loss: 0.6459223628044128\n",
      "Batch Loss: 0.6652545928955078\n",
      "Batch Loss: 0.6635333895683289\n",
      "Batch Loss: 0.6694689393043518\n",
      "Batch Loss: 0.6814045906066895\n",
      "Batch Loss: 0.651918351650238\n",
      "Batch Loss: 0.657724916934967\n",
      "Batch Loss: 0.6437345743179321\n",
      "Batch Loss: 0.6694679260253906\n",
      "Batch Loss: 0.6731135249137878\n",
      "Batch Loss: 0.6458513140678406\n",
      "Batch Loss: 0.633979320526123\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6635940670967102\n",
      "Batch Loss: 0.6399761438369751\n",
      "Batch Loss: 0.6792185306549072\n",
      "Batch Loss: 0.645972728729248\n",
      "Batch Loss: 0.6673462986946106\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6517206430435181\n",
      "Batch Loss: 0.6635918617248535\n",
      "Batch Loss: 0.670932948589325\n",
      "Batch Loss: 0.6850906610488892\n",
      "Batch Loss: 0.6694655418395996\n",
      "Batch Loss: 0.6437236070632935\n",
      "Batch Loss: 0.655430018901825\n",
      "Batch Loss: 0.6400904059410095\n",
      "Batch Loss: 0.6672403812408447\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6576536297798157\n",
      "Batch Loss: 0.6635288596153259\n",
      "Batch Loss: 0.6459018588066101\n",
      "Batch Loss: 0.6636486053466797\n",
      "Batch Loss: 0.6459008455276489\n",
      "Batch Loss: 0.6637073159217834\n",
      "Batch Loss: 0.6674602031707764\n",
      "Batch Loss: 0.6813943982124329\n",
      "Batch Loss: 0.6695817708969116\n",
      "Batch Loss: 0.6517151594161987\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6695214509963989\n",
      "Batch Loss: 0.6517724990844727\n",
      "Batch Loss: 0.6694626808166504\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6792097091674805\n",
      "Batch Loss: 0.6850873231887817\n",
      "Batch Loss: 0.6755135655403137\n",
      "Batch Loss: 0.6577060222625732\n",
      "Batch Loss: 0.6578208208084106\n",
      "Batch Loss: 0.6850466132164001\n",
      "Batch Loss: 0.6340765953063965\n",
      "Batch Loss: 0.6458330154418945\n",
      "Batch Loss: 0.6495459079742432\n",
      "Batch Loss: 0.6695181131362915\n",
      "Batch Loss: 0.6635253429412842\n",
      "Batch Loss: 0.6577027440071106\n",
      "Batch Loss: 0.6732143759727478\n",
      "Batch Loss: 0.6458304524421692\n",
      "Batch Loss: 0.6694605350494385\n",
      "Batch Loss: 0.6613593101501465\n",
      "Batch Loss: 0.6518210172653198\n",
      "Batch Loss: 0.6733253598213196\n",
      "Batch Loss: 0.6457728743553162\n",
      "Batch Loss: 0.639836847782135\n",
      "Batch Loss: 0.6635240316390991\n",
      "Batch Loss: 0.6458827257156372\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6635236740112305\n",
      "Batch Loss: 0.6695141792297363\n",
      "Batch Loss: 0.6672385931015015\n",
      "Batch Loss: 0.6671291589736938\n",
      "Batch Loss: 0.6910743117332458\n",
      "Batch Loss: 0.6694588661193848\n",
      "Batch Loss: 0.6636864542961121\n",
      "Batch Loss: 0.6872658133506775\n",
      "Batch Loss: 0.6672765016555786\n",
      "Batch Loss: 0.6576412916183472\n",
      "Batch Loss: 0.6044900417327881\n",
      "Batch Loss: 0.657640814781189\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6910187602043152\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6535434722900391\n",
      "Batch Loss: 0.6635754704475403\n",
      "Batch Loss: 0.6397790908813477\n",
      "Batch Loss: 0.6792000532150269\n",
      "Batch Loss: 0.6732641458511353\n",
      "Batch Loss: 0.6674341559410095\n",
      "Batch Loss: 0.65545654296875\n",
      "Batch Loss: 0.6614447832107544\n",
      "Batch Loss: 0.6695095896720886\n",
      "Batch Loss: 0.694823682308197\n",
      "Batch Loss: 0.6576377153396606\n",
      "Batch Loss: 0.6694566011428833\n",
      "Batch Loss: 0.6888872385025024\n",
      "Batch Loss: 0.6635727286338806\n",
      "Batch Loss: 0.6458693146705627\n",
      "Batch Loss: 0.6399331092834473\n",
      "Batch Loss: 0.645661473274231\n",
      "Batch Loss: 0.6576361656188965\n",
      "Batch Loss: 0.6695072650909424\n",
      "Batch Loss: 0.6458669900894165\n",
      "Batch Loss: 0.6399308443069458\n",
      "Batch Loss: 0.6576862335205078\n",
      "Batch Loss: 0.6753910779953003\n",
      "Batch Loss: 0.6732088327407837\n",
      "Batch Loss: 0.6378989815711975\n",
      "Batch Loss: 0.6694549322128296\n",
      "Batch Loss: 0.6458635330200195\n",
      "Batch Loss: 0.6457118988037109\n",
      "Batch Loss: 0.6281055808067322\n",
      "Batch Loss: 0.6495654582977295\n",
      "Batch Loss: 0.6458113789558411\n",
      "Batch Loss: 0.6338399052619934\n",
      "Batch Loss: 0.6577814817428589\n",
      "Batch Loss: 0.6518450975418091\n",
      "Batch Loss: 0.639824628829956\n",
      "Batch Loss: 0.6495628952980042\n",
      "Batch Loss: 0.6280018091201782\n",
      "Batch Loss: 0.6695513129234314\n",
      "Batch Loss: 0.6695509552955627\n",
      "Batch Loss: 0.6732553243637085\n",
      "Batch Loss: 0.6517429947853088\n",
      "Batch Loss: 0.6753884553909302\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.655447244644165\n",
      "Batch Loss: 0.6458539962768555\n",
      "Batch Loss: 0.6674141883850098\n",
      "Batch Loss: 0.6458051204681396\n",
      "Batch Loss: 0.6910605430603027\n",
      "Batch Loss: 0.6516448259353638\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575803160667419\n",
      "Batch Loss: 0.6851239800453186\n",
      "Batch Loss: 0.6339789628982544\n",
      "Batch Loss: 0.6399613618850708\n",
      "Batch Loss: 0.6339781284332275\n",
      "Batch Loss: 0.6673629283905029\n",
      "Batch Loss: 0.685076117515564\n",
      "Batch Loss: 0.6672688722610474\n",
      "Batch Loss: 0.6458942890167236\n",
      "Batch Loss: 0.6576257944107056\n",
      "Batch Loss: 0.6319323182106018\n",
      "Batch Loss: 0.6730791330337524\n",
      "Batch Loss: 0.6694965362548828\n",
      "Batch Loss: 0.6517351865768433\n",
      "Batch Loss: 0.6577164530754089\n",
      "Batch Loss: 0.6694501042366028\n",
      "Batch Loss: 0.6636512279510498\n",
      "Batch Loss: 0.6399990916252136\n",
      "Batch Loss: 0.6459341049194336\n",
      "Batch Loss: 0.6457973718643188\n",
      "Batch Loss: 0.66949462890625\n",
      "Batch Loss: 0.663603663444519\n",
      "Batch Loss: 0.6436588764190674\n",
      "Batch Loss: 0.6694490909576416\n",
      "Batch Loss: 0.6753846406936646\n",
      "Batch Loss: 0.6695379018783569\n",
      "Batch Loss: 0.6518193483352661\n",
      "Batch Loss: 0.673038125038147\n",
      "Batch Loss: 0.673290491104126\n",
      "Batch Loss: 0.6552057266235352\n",
      "Epoch 2/20, Loss: 0.6652426804088488, Time: 509.17s\n",
      "Batch Loss: 0.6651281118392944\n",
      "Batch Loss: 0.6636004447937012\n",
      "Batch Loss: 0.6555260419845581\n",
      "Batch Loss: 0.6457489132881165\n",
      "Batch Loss: 0.6872550845146179\n",
      "Batch Loss: 0.6850728988647461\n",
      "Batch Loss: 0.657576322555542\n",
      "Batch Loss: 0.6496319770812988\n",
      "Batch Loss: 0.6340497732162476\n",
      "Batch Loss: 0.6673085689544678\n",
      "Batch Loss: 0.6576191186904907\n",
      "Batch Loss: 0.628069281578064\n",
      "Batch Loss: 0.6635972261428833\n",
      "Batch Loss: 0.6457898616790771\n",
      "Batch Loss: 0.6340034008026123\n",
      "Batch Loss: 0.6813608407974243\n",
      "Batch Loss: 0.6635534763336182\n",
      "Batch Loss: 0.6576175689697266\n",
      "Batch Loss: 0.7005823850631714\n",
      "Batch Loss: 0.6517658233642578\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6495829224586487\n",
      "Batch Loss: 0.6615378856658936\n",
      "Batch Loss: 0.6575747132301331\n",
      "Batch Loss: 0.6813591718673706\n",
      "Batch Loss: 0.6695290803909302\n",
      "Batch Loss: 0.6969007849693298\n",
      "Batch Loss: 0.6614108085632324\n",
      "Batch Loss: 0.6457028388977051\n",
      "Batch Loss: 0.6694868803024292\n",
      "Batch Loss: 0.6672755479812622\n",
      "Batch Loss: 0.649702787399292\n",
      "Batch Loss: 0.6850414872169495\n",
      "Batch Loss: 0.6553916931152344\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6340347528457642\n",
      "Batch Loss: 0.6339528560638428\n",
      "Batch Loss: 0.6753807067871094\n",
      "Batch Loss: 0.6791055202484131\n",
      "Batch Loss: 0.6516780853271484\n",
      "Batch Loss: 0.6517990827560425\n",
      "Batch Loss: 0.65765380859375\n",
      "Batch Loss: 0.6338704824447632\n",
      "Batch Loss: 0.6635890007019043\n",
      "Batch Loss: 0.6635086536407471\n",
      "Batch Loss: 0.6576128602027893\n",
      "Batch Loss: 0.6851490139961243\n",
      "Batch Loss: 0.6673017740249634\n",
      "Batch Loss: 0.6517561674118042\n",
      "Batch Loss: 0.6576915383338928\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6576513648033142\n",
      "Batch Loss: 0.6813151836395264\n",
      "Batch Loss: 0.6280509829521179\n",
      "Batch Loss: 0.6635863184928894\n",
      "Batch Loss: 0.655468225479126\n",
      "Batch Loss: 0.6850684285163879\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6635463237762451\n",
      "Batch Loss: 0.6516748666763306\n",
      "Batch Loss: 0.6576491594314575\n",
      "Batch Loss: 0.6673381328582764\n",
      "Batch Loss: 0.6694815158843994\n",
      "Batch Loss: 0.6517512798309326\n",
      "Batch Loss: 0.657686710357666\n",
      "Batch Loss: 0.6791703701019287\n",
      "Batch Loss: 0.6340198516845703\n",
      "Batch Loss: 0.6614392995834351\n",
      "Batch Loss: 0.6376960873603821\n",
      "Batch Loss: 0.687249481678009\n",
      "Batch Loss: 0.64573734998703\n",
      "Batch Loss: 0.6339414715766907\n",
      "Batch Loss: 0.6635441780090332\n",
      "Batch Loss: 0.6946920156478882\n",
      "Batch Loss: 0.6695171594619751\n",
      "Batch Loss: 0.6517848372459412\n",
      "Batch Loss: 0.669441819190979\n",
      "Batch Loss: 0.6635433435440063\n",
      "Batch Loss: 0.6575702428817749\n",
      "Batch Loss: 0.64577317237854\n",
      "Batch Loss: 0.6516715288162231\n",
      "Batch Loss: 0.6635428071022034\n",
      "Batch Loss: 0.6517082452774048\n",
      "Batch Loss: 0.6516710519790649\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6672590970993042\n",
      "Batch Loss: 0.6635054349899292\n",
      "Batch Loss: 0.633936882019043\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.657642662525177\n",
      "Batch Loss: 0.6635051369667053\n",
      "Batch Loss: 0.6458802819252014\n",
      "Batch Loss: 0.673230767250061\n",
      "Batch Loss: 0.6457341909408569\n",
      "Batch Loss: 0.6850656270980835\n",
      "Batch Loss: 0.63994300365448\n",
      "Batch Loss: 0.6613948941230774\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6576049327850342\n",
      "Batch Loss: 0.6613943576812744\n",
      "Batch Loss: 0.6576046347618103\n",
      "Batch Loss: 0.6694400906562805\n",
      "Batch Loss: 0.6517401933670044\n",
      "Batch Loss: 0.6591401100158691\n",
      "Batch Loss: 0.6635398268699646\n",
      "Batch Loss: 0.6517394781112671\n",
      "Batch Loss: 0.6694753170013428\n",
      "Batch Loss: 0.6710215210914612\n",
      "Batch Loss: 0.6576036214828491\n",
      "Batch Loss: 0.6850646734237671\n",
      "Batch Loss: 0.6636096239089966\n",
      "Batch Loss: 0.6456966996192932\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6753751039505005\n",
      "Batch Loss: 0.6576730012893677\n",
      "Batch Loss: 0.6731332540512085\n",
      "Batch Loss: 0.6849697232246399\n",
      "Batch Loss: 0.6694391965866089\n",
      "Batch Loss: 0.6694740653038025\n",
      "Batch Loss: 0.6613560914993286\n",
      "Batch Loss: 0.6732622385025024\n",
      "Batch Loss: 0.6576023697853088\n",
      "Batch Loss: 0.6517012715339661\n",
      "Batch Loss: 0.6576021909713745\n",
      "Batch Loss: 0.6635724306106567\n",
      "Batch Loss: 0.6754091382026672\n",
      "Batch Loss: 0.6576018929481506\n",
      "Batch Loss: 0.669507622718811\n",
      "Batch Loss: 0.6695418357849121\n",
      "Batch Loss: 0.6457988023757935\n",
      "Batch Loss: 0.6517000198364258\n",
      "Batch Loss: 0.6635028123855591\n",
      "Batch Loss: 0.6516996622085571\n",
      "Batch Loss: 0.663536787033081\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6731678247451782\n",
      "Batch Loss: 0.6517328023910522\n",
      "Batch Loss: 0.6458307504653931\n",
      "Batch Loss: 0.6339589953422546\n",
      "Batch Loss: 0.6671645641326904\n",
      "Batch Loss: 0.6694380044937134\n",
      "Batch Loss: 0.6753736734390259\n",
      "Batch Loss: 0.6694378852844238\n",
      "Batch Loss: 0.6517312526702881\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6614535450935364\n",
      "Batch Loss: 0.6457949280738831\n",
      "Batch Loss: 0.6339565515518188\n",
      "Batch Loss: 0.6554837822914124\n",
      "Batch Loss: 0.6576655507087708\n",
      "Batch Loss: 0.6457277536392212\n",
      "Batch Loss: 0.6635016798973083\n",
      "Batch Loss: 0.6102449893951416\n",
      "Batch Loss: 0.6576316356658936\n",
      "Batch Loss: 0.6828567981719971\n",
      "Batch Loss: 0.6635341644287109\n",
      "Batch Loss: 0.6612633466720581\n",
      "Batch Loss: 0.6754053235054016\n",
      "Batch Loss: 0.6635338068008423\n",
      "Batch Loss: 0.6457915902137756\n",
      "Batch Loss: 0.6791585683822632\n",
      "Batch Loss: 0.6338224411010742\n",
      "Batch Loss: 0.6458232402801514\n",
      "Batch Loss: 0.6516295075416565\n",
      "Batch Loss: 0.6576296091079712\n",
      "Batch Loss: 0.6635651588439941\n",
      "Batch Loss: 0.6554793119430542\n",
      "Batch Loss: 0.6635648012161255\n",
      "Batch Loss: 0.651661217212677\n",
      "Batch Loss: 0.6397897005081177\n",
      "Batch Loss: 0.669468104839325\n",
      "Batch Loss: 0.6694362163543701\n",
      "Batch Loss: 0.6731671690940857\n",
      "Batch Loss: 0.6517558097839355\n",
      "Batch Loss: 0.6458831429481506\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6162036657333374\n",
      "Batch Loss: 0.6397572755813599\n",
      "Batch Loss: 0.6731669306755066\n",
      "Batch Loss: 0.6517226099967957\n",
      "Batch Loss: 0.661380410194397\n",
      "Batch Loss: 0.6398195028305054\n",
      "Batch Loss: 0.6695290207862854\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6732820868492126\n",
      "Batch Loss: 0.7125257253646851\n",
      "Batch Loss: 0.6731888651847839\n",
      "Batch Loss: 0.6496003866195679\n",
      "Batch Loss: 0.6613789796829224\n",
      "Batch Loss: 0.6672619581222534\n",
      "Batch Loss: 0.6457536220550537\n",
      "Batch Loss: 0.6886999607086182\n",
      "Batch Loss: 0.6397870779037476\n",
      "Batch Loss: 0.6732190251350403\n",
      "Batch Loss: 0.6754316091537476\n",
      "Batch Loss: 0.6614084243774414\n",
      "Batch Loss: 0.669465184211731\n",
      "Batch Loss: 0.6732490062713623\n",
      "Batch Loss: 0.6457524299621582\n",
      "Batch Loss: 0.6694345474243164\n",
      "Batch Loss: 0.671066403388977\n",
      "Batch Loss: 0.6671706438064575\n",
      "Batch Loss: 0.657623291015625\n",
      "Batch Loss: 0.6576231718063354\n",
      "Batch Loss: 0.6576530933380127\n",
      "Batch Loss: 0.6733078360557556\n",
      "Batch Loss: 0.671035647392273\n",
      "Batch Loss: 0.6554105281829834\n",
      "Batch Loss: 0.6339094638824463\n",
      "Batch Loss: 0.6791532039642334\n",
      "Batch Loss: 0.6338793039321899\n",
      "Batch Loss: 0.6377216577529907\n",
      "Batch Loss: 0.6635278463363647\n",
      "Batch Loss: 0.6731874942779541\n",
      "Batch Loss: 0.6576509475708008\n",
      "Batch Loss: 0.6635274887084961\n",
      "Batch Loss: 0.6576210856437683\n",
      "Batch Loss: 0.6694629788398743\n",
      "Batch Loss: 0.6575914621353149\n",
      "Batch Loss: 0.663497805595398\n",
      "Batch Loss: 0.6397841572761536\n",
      "Batch Loss: 0.663497805595398\n",
      "Batch Loss: 0.6694625020027161\n",
      "Batch Loss: 0.6813048124313354\n",
      "Batch Loss: 0.6694333553314209\n",
      "Batch Loss: 0.6613444089889526\n",
      "Batch Loss: 0.6634975671768188\n",
      "Batch Loss: 0.6635552644729614\n",
      "Batch Loss: 0.6280562281608582\n",
      "Batch Loss: 0.6517122983932495\n",
      "Batch Loss: 0.6634973287582397\n",
      "Batch Loss: 0.6694903373718262\n",
      "Batch Loss: 0.6575902104377747\n",
      "Batch Loss: 0.6457759141921997\n",
      "Batch Loss: 0.663554310798645\n",
      "Batch Loss: 0.6554932594299316\n",
      "Batch Loss: 0.6576182246208191\n",
      "Batch Loss: 0.694775402545929\n",
      "Batch Loss: 0.6791219711303711\n",
      "Batch Loss: 0.6694326400756836\n",
      "Batch Loss: 0.6517100930213928\n",
      "Batch Loss: 0.6399229764938354\n",
      "Batch Loss: 0.6694887280464172\n",
      "Batch Loss: 0.645773708820343\n",
      "Batch Loss: 0.6576169729232788\n",
      "Batch Loss: 0.6576167345046997\n",
      "Batch Loss: 0.6435431241989136\n",
      "Batch Loss: 0.673241376876831\n",
      "Batch Loss: 0.663551926612854\n",
      "Batch Loss: 0.6102135181427002\n",
      "Batch Loss: 0.6398364305496216\n",
      "Batch Loss: 0.661369264125824\n",
      "Batch Loss: 0.669486939907074\n",
      "Batch Loss: 0.6828277111053467\n",
      "Batch Loss: 0.627936601638794\n",
      "Batch Loss: 0.6672769784927368\n",
      "Batch Loss: 0.6458253860473633\n",
      "Batch Loss: 0.6694861054420471\n",
      "Batch Loss: 0.657614529132843\n",
      "Batch Loss: 0.651705801486969\n",
      "Batch Loss: 0.6769193410873413\n",
      "Batch Loss: 0.6219727993011475\n",
      "Batch Loss: 0.669458270072937\n",
      "Batch Loss: 0.6969007849693298\n",
      "Batch Loss: 0.6613481044769287\n",
      "Batch Loss: 0.6516778469085693\n",
      "Batch Loss: 0.6101812720298767\n",
      "Batch Loss: 0.6575864553451538\n",
      "Batch Loss: 0.6694310903549194\n",
      "Batch Loss: 0.6495751142501831\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6495023965835571\n",
      "Batch Loss: 0.6709381937980652\n",
      "Batch Loss: 0.657585859298706\n",
      "Batch Loss: 0.6279600858688354\n",
      "Batch Loss: 0.6672749519348145\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6457667946815491\n",
      "Batch Loss: 0.6398046016693115\n",
      "Batch Loss: 0.6494488716125488\n",
      "Batch Loss: 0.651675820350647\n",
      "Batch Loss: 0.6673007011413574\n",
      "Batch Loss: 0.6672744750976562\n",
      "Batch Loss: 0.6613126397132874\n",
      "Batch Loss: 0.6576371192932129\n",
      "Batch Loss: 0.6458176374435425\n",
      "Batch Loss: 0.6732098460197449\n",
      "Batch Loss: 0.6516490578651428\n",
      "Batch Loss: 0.7006802558898926\n",
      "Batch Loss: 0.6694560050964355\n",
      "Batch Loss: 0.673209547996521\n",
      "Batch Loss: 0.6791452169418335\n",
      "Batch Loss: 0.6694815158843994\n",
      "Batch Loss: 0.6694557666778564\n",
      "Batch Loss: 0.6732348799705505\n",
      "Batch Loss: 0.6635198593139648\n",
      "Batch Loss: 0.688764750957489\n",
      "Batch Loss: 0.6694298982620239\n",
      "Batch Loss: 0.6753655672073364\n",
      "Batch Loss: 0.6694808006286621\n",
      "Batch Loss: 0.645737886428833\n",
      "Batch Loss: 0.6457377672195435\n",
      "Batch Loss: 0.6457122564315796\n",
      "Batch Loss: 0.6398271918296814\n",
      "Batch Loss: 0.6339672803878784\n",
      "Batch Loss: 0.6754158735275269\n",
      "Batch Loss: 0.6732083559036255\n",
      "Batch Loss: 0.6279299259185791\n",
      "Batch Loss: 0.6576083302497864\n",
      "Batch Loss: 0.65169757604599\n",
      "Batch Loss: 0.669479489326477\n",
      "Batch Loss: 0.6575579047203064\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6495646238327026\n",
      "Batch Loss: 0.6576324105262756\n",
      "Batch Loss: 0.6694291830062866\n",
      "Batch Loss: 0.6576321125030518\n",
      "Batch Loss: 0.6849621534347534\n",
      "Batch Loss: 0.6397998929023743\n",
      "Batch Loss: 0.6575822830200195\n",
      "Batch Loss: 0.6753647327423096\n",
      "Batch Loss: 0.663567066192627\n",
      "Batch Loss: 0.6887162923812866\n",
      "Batch Loss: 0.6769360303878784\n",
      "Batch Loss: 0.6790271997451782\n",
      "Batch Loss: 0.6517196893692017\n",
      "Batch Loss: 0.669428825378418\n",
      "Batch Loss: 0.6576306819915771\n",
      "Batch Loss: 0.6791180372238159\n",
      "Batch Loss: 0.6575573682785034\n",
      "Batch Loss: 0.7044322490692139\n",
      "Batch Loss: 0.6635172963142395\n",
      "Batch Loss: 0.6516945362091064\n",
      "Batch Loss: 0.6909893751144409\n",
      "Batch Loss: 0.6614077687263489\n",
      "Batch Loss: 0.6458067893981934\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6516938209533691\n",
      "Batch Loss: 0.6575570702552795\n",
      "Batch Loss: 0.6672945022583008\n",
      "Batch Loss: 0.6102155447006226\n",
      "Batch Loss: 0.6338621377944946\n",
      "Batch Loss: 0.6694523096084595\n",
      "Batch Loss: 0.6694521903991699\n",
      "Batch Loss: 0.633861780166626\n",
      "Batch Loss: 0.6516449451446533\n",
      "Batch Loss: 0.6694519519805908\n",
      "Batch Loss: 0.6635161638259888\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6516209244728088\n",
      "Batch Loss: 0.6457089185714722\n",
      "Batch Loss: 0.6516208648681641\n",
      "Batch Loss: 0.6672930717468262\n",
      "Batch Loss: 0.659151554107666\n",
      "Batch Loss: 0.6279485821723938\n",
      "Batch Loss: 0.6613335609436035\n",
      "Batch Loss: 0.6753870248794556\n",
      "Batch Loss: 0.6399134397506714\n",
      "Batch Loss: 0.6754103302955627\n",
      "Batch Loss: 0.6969242095947266\n",
      "Batch Loss: 0.6872348189353943\n",
      "Batch Loss: 0.6398190259933472\n",
      "Batch Loss: 0.6517136096954346\n",
      "Batch Loss: 0.6947021484375\n",
      "Batch Loss: 0.6436185836791992\n",
      "Batch Loss: 0.6575560569763184\n",
      "Batch Loss: 0.6457539796829224\n",
      "Batch Loss: 0.6495305299758911\n",
      "Batch Loss: 0.6554199457168579\n",
      "Batch Loss: 0.6635146141052246\n",
      "Batch Loss: 0.6635145545005798\n",
      "Batch Loss: 0.6591339111328125\n",
      "Batch Loss: 0.669427216053009\n",
      "Batch Loss: 0.6555107831954956\n",
      "Batch Loss: 0.6576013565063477\n",
      "Batch Loss: 0.6850521564483643\n",
      "Batch Loss: 0.6494605541229248\n",
      "Batch Loss: 0.639793872833252\n",
      "Batch Loss: 0.669472336769104\n",
      "Batch Loss: 0.6576007604598999\n",
      "Batch Loss: 0.6850519180297852\n",
      "Batch Loss: 0.6435470581054688\n",
      "Batch Loss: 0.6634911298751831\n",
      "Batch Loss: 0.6457065343856812\n",
      "Batch Loss: 0.6694267988204956\n",
      "Batch Loss: 0.6398155093193054\n",
      "Batch Loss: 0.6457287073135376\n",
      "Batch Loss: 0.6910097599029541\n",
      "Batch Loss: 0.643613338470459\n",
      "Batch Loss: 0.6398372650146484\n",
      "Batch Loss: 0.645683765411377\n",
      "Batch Loss: 0.6280320882797241\n",
      "Batch Loss: 0.6612929105758667\n",
      "Batch Loss: 0.6694486141204834\n",
      "Batch Loss: 0.6457056999206543\n",
      "Batch Loss: 0.6613085865974426\n",
      "Batch Loss: 0.6517073512077332\n",
      "Batch Loss: 0.6338779926300049\n",
      "Batch Loss: 0.6613962650299072\n",
      "Batch Loss: 0.6635124683380127\n",
      "Batch Loss: 0.6575984954833984\n",
      "Batch Loss: 0.6457269787788391\n",
      "Batch Loss: 0.6220494508743286\n",
      "Batch Loss: 0.6517059803009033\n",
      "Batch Loss: 0.6457266211509705\n",
      "Batch Loss: 0.6672872304916382\n",
      "Batch Loss: 0.675361692905426\n",
      "Batch Loss: 0.6456831097602844\n",
      "Batch Loss: 0.6338762640953064\n",
      "Batch Loss: 0.6635116338729858\n",
      "Batch Loss: 0.6457045078277588\n",
      "Batch Loss: 0.6516615152359009\n",
      "Batch Loss: 0.6575757265090942\n",
      "Batch Loss: 0.6575970649719238\n",
      "Batch Loss: 0.6575756072998047\n",
      "Batch Loss: 0.6575968265533447\n",
      "Batch Loss: 0.6613503098487854\n",
      "Batch Loss: 0.6516821384429932\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.625762939453125\n",
      "Batch Loss: 0.6397892236709595\n",
      "Batch Loss: 0.675361156463623\n",
      "Batch Loss: 0.6576172113418579\n",
      "Batch Loss: 0.6813178062438965\n",
      "Batch Loss: 0.6731640100479126\n",
      "Batch Loss: 0.661292552947998\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6575747728347778\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6635313034057617\n",
      "Batch Loss: 0.6494210958480835\n",
      "Batch Loss: 0.6575745940208435\n",
      "Batch Loss: 0.657616138458252\n",
      "Batch Loss: 0.6517012119293213\n",
      "Batch Loss: 0.6829095482826233\n",
      "Batch Loss: 0.6516594290733337\n",
      "Batch Loss: 0.6635721921920776\n",
      "Batch Loss: 0.6339555382728577\n",
      "Batch Loss: 0.6554126739501953\n",
      "Batch Loss: 0.6219598650932312\n",
      "Batch Loss: 0.6457437872886658\n",
      "Batch Loss: 0.6634891629219055\n",
      "Batch Loss: 0.667242705821991\n",
      "Batch Loss: 0.6635095477104187\n",
      "Batch Loss: 0.6575738191604614\n",
      "Batch Loss: 0.6516380310058594\n",
      "Batch Loss: 0.6635093688964844\n",
      "Batch Loss: 0.6791750192642212\n",
      "Batch Loss: 0.6732189059257507\n",
      "Batch Loss: 0.6495571136474609\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6591650247573853\n",
      "Batch Loss: 0.6634888052940369\n",
      "Batch Loss: 0.6753602027893066\n",
      "Batch Loss: 0.6650055646896362\n",
      "Batch Loss: 0.6457217931747437\n",
      "Batch Loss: 0.6710561513900757\n",
      "Batch Loss: 0.6575730443000793\n",
      "Batch Loss: 0.667248010635376\n",
      "Batch Loss: 0.6516773104667664\n",
      "Batch Loss: 0.6732178926467896\n",
      "Batch Loss: 0.679153561592102\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397855281829834\n",
      "Batch Loss: 0.6731977462768555\n",
      "Batch Loss: 0.6694241762161255\n",
      "Batch Loss: 0.6575726270675659\n",
      "Batch Loss: 0.6316136717796326\n",
      "Batch Loss: 0.6338494420051575\n",
      "Batch Loss: 0.6828472018241882\n",
      "Batch Loss: 0.6554297804832458\n",
      "Batch Loss: 0.6516761779785156\n",
      "Batch Loss: 0.6694240570068359\n",
      "Batch Loss: 0.6613258123397827\n",
      "Batch Loss: 0.6634882688522339\n",
      "Batch Loss: 0.645720362663269\n",
      "Batch Loss: 0.661345362663269\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6672474145889282\n",
      "Batch Loss: 0.6753791570663452\n",
      "Batch Loss: 0.6613451242446899\n",
      "Batch Loss: 0.6634881496429443\n",
      "Batch Loss: 0.6753596067428589\n",
      "Batch Loss: 0.6516751050949097\n",
      "Batch Loss: 0.6672278642654419\n",
      "Batch Loss: 0.6635463237762451\n",
      "Batch Loss: 0.639803409576416\n",
      "Batch Loss: 0.6865536570549011\n",
      "Batch Loss: 0.6575910449028015\n",
      "Batch Loss: 0.6554088592529297\n",
      "Batch Loss: 0.6635072827339172\n",
      "Batch Loss: 0.6753786206245422\n",
      "Batch Loss: 0.6457000970840454\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6731771230697632\n",
      "Batch Loss: 0.6495112180709839\n",
      "Batch Loss: 0.6575905084609985\n",
      "Batch Loss: 0.6457574367523193\n",
      "Batch Loss: 0.6398024559020996\n",
      "Batch Loss: 0.6495298743247986\n",
      "Batch Loss: 0.6635259389877319\n",
      "Batch Loss: 0.6747920513153076\n",
      "Batch Loss: 0.6635067462921143\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694233417510986\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6554076075553894\n",
      "Batch Loss: 0.6694232225418091\n",
      "Batch Loss: 0.6457182168960571\n",
      "Batch Loss: 0.6694232225418091\n",
      "Batch Loss: 0.6435548067092896\n",
      "Batch Loss: 0.639819860458374\n",
      "Batch Loss: 0.6925928592681885\n",
      "Batch Loss: 0.6872302293777466\n",
      "Batch Loss: 0.663487434387207\n",
      "Batch Loss: 0.6575703620910645\n",
      "Batch Loss: 0.6790803074836731\n",
      "Batch Loss: 0.6576076745986938\n",
      "Batch Loss: 0.6397817730903625\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.679061770439148\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6710129976272583\n",
      "Batch Loss: 0.6694415211677551\n",
      "Batch Loss: 0.6495078802108765\n",
      "Batch Loss: 0.6635242700576782\n",
      "Batch Loss: 0.6635241508483887\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6376545429229736\n",
      "Batch Loss: 0.667259156703949\n",
      "Batch Loss: 0.6613417863845825\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6672406196594238\n",
      "Batch Loss: 0.6553691625595093\n",
      "Batch Loss: 0.6554242372512817\n",
      "Batch Loss: 0.633826732635498\n",
      "Batch Loss: 0.6456798315048218\n",
      "Batch Loss: 0.6694409847259521\n",
      "Batch Loss: 0.6634869575500488\n",
      "Batch Loss: 0.6672952175140381\n",
      "Batch Loss: 0.6397987604141235\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6791300773620605\n",
      "Batch Loss: 0.6494877934455872\n",
      "Batch Loss: 0.6220093965530396\n",
      "Batch Loss: 0.6791480779647827\n",
      "Batch Loss: 0.6576234102249146\n",
      "Batch Loss: 0.6634867191314697\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6516332626342773\n",
      "Batch Loss: 0.6516512036323547\n",
      "Batch Loss: 0.6731938719749451\n",
      "Batch Loss: 0.6575688123703003\n",
      "Batch Loss: 0.6591940522193909\n",
      "Batch Loss: 0.6516151428222656\n",
      "Batch Loss: 0.6613401174545288\n",
      "Batch Loss: 0.6732115745544434\n",
      "Batch Loss: 0.6278900504112244\n",
      "Batch Loss: 0.6457328200340271\n",
      "Batch Loss: 0.6456971168518066\n",
      "Batch Loss: 0.645732581615448\n",
      "Batch Loss: 0.6397613286972046\n",
      "Batch Loss: 0.6850470900535583\n",
      "Batch Loss: 0.6872291564941406\n",
      "Batch Loss: 0.6516679525375366\n",
      "Batch Loss: 0.6849991083145142\n",
      "Batch Loss: 0.6635391712188721\n",
      "Batch Loss: 0.6278896331787109\n",
      "Batch Loss: 0.6635038256645203\n",
      "Batch Loss: 0.673193097114563\n",
      "Batch Loss: 0.6673275828361511\n",
      "Batch Loss: 0.669439435005188\n",
      "Batch Loss: 0.6457315683364868\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6694393157958984\n",
      "Batch Loss: 0.6575678586959839\n",
      "Batch Loss: 0.6279589533805847\n",
      "Batch Loss: 0.6575851440429688\n",
      "Batch Loss: 0.6635381579399109\n",
      "Batch Loss: 0.6753574013710022\n",
      "Batch Loss: 0.6456788778305054\n",
      "Batch Loss: 0.6575502157211304\n",
      "Batch Loss: 0.6718807816505432\n",
      "Epoch 3/20, Loss: 0.6603213446945867, Time: 501.33s\n",
      "Batch Loss: 0.6791108846664429\n",
      "Batch Loss: 0.6753572821617126\n",
      "Batch Loss: 0.6709930300712585\n",
      "Batch Loss: 0.6768820285797119\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6576016545295715\n",
      "Batch Loss: 0.6457301378250122\n",
      "Batch Loss: 0.6457129716873169\n",
      "Batch Loss: 0.6457129120826721\n",
      "Batch Loss: 0.6435307264328003\n",
      "Batch Loss: 0.6575841903686523\n",
      "Batch Loss: 0.657550036907196\n",
      "Batch Loss: 0.6672563552856445\n",
      "Batch Loss: 0.6317272186279297\n",
      "Batch Loss: 0.6532367467880249\n",
      "Batch Loss: 0.679110586643219\n",
      "Batch Loss: 0.6613204479217529\n",
      "Batch Loss: 0.6575838327407837\n",
      "Batch Loss: 0.6575667858123779\n",
      "Batch Loss: 0.6731458902359009\n",
      "Batch Loss: 0.6576005220413208\n",
      "Batch Loss: 0.6398100852966309\n",
      "Batch Loss: 0.6435636281967163\n",
      "Batch Loss: 0.6457119584083557\n",
      "Batch Loss: 0.6554012298583984\n",
      "Batch Loss: 0.6375939846038818\n",
      "Batch Loss: 0.6613080501556396\n",
      "Batch Loss: 0.6457952260971069\n",
      "Batch Loss: 0.6576164364814758\n",
      "Batch Loss: 0.6457281708717346\n",
      "Batch Loss: 0.6710256934165955\n",
      "Batch Loss: 0.6909982562065125\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694208979606628\n",
      "Batch Loss: 0.6398249864578247\n",
      "Batch Loss: 0.6635181307792664\n",
      "Batch Loss: 0.6220505237579346\n",
      "Batch Loss: 0.649480938911438\n",
      "Batch Loss: 0.639824390411377\n",
      "Batch Loss: 0.6635178327560425\n",
      "Batch Loss: 0.6613683104515076\n",
      "Batch Loss: 0.6671942472457886\n",
      "Batch Loss: 0.6576144695281982\n",
      "Batch Loss: 0.655415952205658\n",
      "Batch Loss: 0.6516134738922119\n",
      "Batch Loss: 0.6613513827323914\n",
      "Batch Loss: 0.6398229598999023\n",
      "Batch Loss: 0.6338223814964294\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6279671788215637\n",
      "Batch Loss: 0.6866490840911865\n",
      "Batch Loss: 0.6694364547729492\n",
      "Batch Loss: 0.6338702440261841\n",
      "Batch Loss: 0.6575489044189453\n",
      "Batch Loss: 0.6516931056976318\n",
      "Batch Loss: 0.6634845733642578\n",
      "Batch Loss: 0.6613661050796509\n",
      "Batch Loss: 0.6457569003105164\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6671950817108154\n",
      "Batch Loss: 0.6338692307472229\n",
      "Batch Loss: 0.6457088589668274\n",
      "Batch Loss: 0.6635159254074097\n",
      "Batch Loss: 0.6888144016265869\n",
      "Batch Loss: 0.6575486660003662\n",
      "Batch Loss: 0.6634843349456787\n",
      "Batch Loss: 0.627948522567749\n",
      "Batch Loss: 0.6671953201293945\n",
      "Batch Loss: 0.6887404322624207\n",
      "Batch Loss: 0.6613490581512451\n",
      "Batch Loss: 0.6694512367248535\n",
      "Batch Loss: 0.6554132103919983\n",
      "Batch Loss: 0.6850605010986328\n",
      "Batch Loss: 0.679082453250885\n",
      "Batch Loss: 0.6634842157363892\n",
      "Batch Loss: 0.669435441493988\n",
      "Batch Loss: 0.6338522434234619\n",
      "Batch Loss: 0.6338831186294556\n",
      "Batch Loss: 0.6575639247894287\n",
      "Batch Loss: 0.6710686087608337\n",
      "Batch Loss: 0.6694507002830505\n",
      "Batch Loss: 0.6220112442970276\n",
      "Batch Loss: 0.6338671445846558\n",
      "Batch Loss: 0.6516433954238892\n",
      "Batch Loss: 0.6731733083724976\n",
      "Batch Loss: 0.6731316447257996\n",
      "Batch Loss: 0.6694350242614746\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6279155015945435\n",
      "Batch Loss: 0.7065486311912537\n",
      "Batch Loss: 0.671021580696106\n",
      "Batch Loss: 0.6769877076148987\n",
      "Batch Loss: 0.6635143160820007\n",
      "Batch Loss: 0.6613473296165466\n",
      "Batch Loss: 0.6397865414619446\n",
      "Batch Loss: 0.669419527053833\n",
      "Batch Loss: 0.6457068920135498\n",
      "Batch Loss: 0.6791087985038757\n",
      "Batch Loss: 0.65545654296875\n",
      "Batch Loss: 0.6731880903244019\n",
      "Batch Loss: 0.6613317131996155\n",
      "Batch Loss: 0.67100590467453\n",
      "Batch Loss: 0.6516573429107666\n",
      "Batch Loss: 0.6576080322265625\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753849983215332\n",
      "Batch Loss: 0.6457512378692627\n",
      "Batch Loss: 0.6731877326965332\n",
      "Batch Loss: 0.6575627326965332\n",
      "Batch Loss: 0.6516567468643188\n",
      "Batch Loss: 0.6516120433807373\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575477719306946\n",
      "Batch Loss: 0.6457059383392334\n",
      "Batch Loss: 0.6516711711883545\n",
      "Batch Loss: 0.657547652721405\n",
      "Batch Loss: 0.6457352638244629\n",
      "Batch Loss: 0.6575623750686646\n",
      "Batch Loss: 0.6516119241714478\n",
      "Batch Loss: 0.6753841638565063\n",
      "Batch Loss: 0.6397845149040222\n",
      "Batch Loss: 0.6635125875473022\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6553800702095032\n",
      "Batch Loss: 0.6397696733474731\n",
      "Batch Loss: 0.6554092168807983\n",
      "Batch Loss: 0.6160703897476196\n",
      "Batch Loss: 0.6456906199455261\n",
      "Batch Loss: 0.6516118049621582\n",
      "Batch Loss: 0.6672118902206421\n",
      "Batch Loss: 0.6634976863861084\n",
      "Batch Loss: 0.6732013821601868\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753689646720886\n",
      "Batch Loss: 0.6753544807434082\n",
      "Batch Loss: 0.6672511100769043\n",
      "Batch Loss: 0.670979917049408\n",
      "Batch Loss: 0.651654839515686\n",
      "Batch Loss: 0.6753688454627991\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6634973287582397\n",
      "Batch Loss: 0.6634830236434937\n",
      "Batch Loss: 0.6694329977035522\n",
      "Batch Loss: 0.6219903230667114\n",
      "Batch Loss: 0.6279259920120239\n",
      "Batch Loss: 0.6753543615341187\n",
      "Batch Loss: 0.6435222625732422\n",
      "Batch Loss: 0.6753685474395752\n",
      "Batch Loss: 0.6516542434692383\n",
      "Batch Loss: 0.6397969722747803\n",
      "Batch Loss: 0.6694470047950745\n",
      "Batch Loss: 0.6850191950798035\n",
      "Batch Loss: 0.6494576930999756\n",
      "Batch Loss: 0.6613432168960571\n",
      "Batch Loss: 0.6435642838478088\n",
      "Batch Loss: 0.6753683090209961\n",
      "Batch Loss: 0.657575249671936\n",
      "Batch Loss: 0.6634827852249146\n",
      "Batch Loss: 0.669432520866394\n",
      "Batch Loss: 0.6613146066665649\n",
      "Batch Loss: 0.6553548574447632\n",
      "Batch Loss: 0.6694183945655823\n",
      "Batch Loss: 0.6672642827033997\n",
      "Batch Loss: 0.6634966731071472\n",
      "Batch Loss: 0.6694463491439819\n",
      "Batch Loss: 0.6575748920440674\n",
      "Batch Loss: 0.6731858253479004\n",
      "Batch Loss: 0.6634826064109802\n",
      "Batch Loss: 0.651652991771698\n",
      "Batch Loss: 0.6634964942932129\n",
      "Batch Loss: 0.6850710511207581\n",
      "Batch Loss: 0.6457586884498596\n",
      "Batch Loss: 0.6160800457000732\n",
      "Batch Loss: 0.6909788846969604\n",
      "Batch Loss: 0.6634963154792786\n",
      "Batch Loss: 0.6257689595222473\n",
      "Batch Loss: 0.6457028985023499\n",
      "Batch Loss: 0.679097592830658\n",
      "Batch Loss: 0.6731991767883301\n",
      "Batch Loss: 0.6575603485107422\n",
      "Batch Loss: 0.6516109108924866\n",
      "Batch Loss: 0.6516382694244385\n",
      "Batch Loss: 0.6850195527076721\n",
      "Batch Loss: 0.6279227137565613\n",
      "Batch Loss: 0.6576011776924133\n",
      "Batch Loss: 0.6435105204582214\n",
      "Batch Loss: 0.6694452166557312\n",
      "Batch Loss: 0.6575601100921631\n",
      "Batch Loss: 0.6634821891784668\n",
      "Batch Loss: 0.6694586277008057\n",
      "Batch Loss: 0.6732121706008911\n",
      "Batch Loss: 0.6338847875595093\n",
      "Batch Loss: 0.6397663354873657\n",
      "Batch Loss: 0.6457289457321167\n",
      "Batch Loss: 0.6731482744216919\n",
      "Batch Loss: 0.6397526860237122\n",
      "Batch Loss: 0.6575464010238647\n",
      "Batch Loss: 0.6516777276992798\n",
      "Batch Loss: 0.6731483936309814\n",
      "Batch Loss: 0.6731981039047241\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6791470646858215\n",
      "Batch Loss: 0.6635086536407471\n",
      "Batch Loss: 0.6694309711456299\n",
      "Batch Loss: 0.6495082378387451\n",
      "Batch Loss: 0.6456880569458008\n",
      "Batch Loss: 0.6338697671890259\n",
      "Batch Loss: 0.6516237258911133\n",
      "Batch Loss: 0.6635083556175232\n",
      "Batch Loss: 0.6672391891479492\n",
      "Batch Loss: 0.6731617450714111\n",
      "Batch Loss: 0.6753664016723633\n",
      "Batch Loss: 0.6634818315505981\n",
      "Batch Loss: 0.6694175004959106\n",
      "Batch Loss: 0.6634818315505981\n",
      "Batch Loss: 0.6516234874725342\n",
      "Batch Loss: 0.6672484874725342\n",
      "Batch Loss: 0.6812888383865356\n",
      "Batch Loss: 0.679132878780365\n",
      "Batch Loss: 0.6516625881195068\n",
      "Batch Loss: 0.6516363620758057\n",
      "Batch Loss: 0.6516494750976562\n",
      "Batch Loss: 0.6338683366775513\n",
      "Batch Loss: 0.6634947061538696\n",
      "Batch Loss: 0.6457005739212036\n",
      "Batch Loss: 0.6575589179992676\n",
      "Batch Loss: 0.6397647261619568\n",
      "Batch Loss: 0.6516101360321045\n",
      "Batch Loss: 0.6553637385368347\n",
      "Batch Loss: 0.673170804977417\n",
      "Batch Loss: 0.6887736916542053\n",
      "Batch Loss: 0.6709665656089783\n",
      "Batch Loss: 0.6575716137886047\n",
      "Batch Loss: 0.6694172620773315\n",
      "Batch Loss: 0.6516229510307312\n",
      "Batch Loss: 0.6575844287872314\n",
      "Batch Loss: 0.6516228914260864\n",
      "Batch Loss: 0.6591686010360718\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6575841903686523\n",
      "Batch Loss: 0.6850549578666687\n",
      "Batch Loss: 0.6694298982620239\n",
      "Batch Loss: 0.6397769451141357\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6672477722167969\n",
      "Batch Loss: 0.6753528118133545\n",
      "Batch Loss: 0.663506805896759\n",
      "Batch Loss: 0.6791191101074219\n",
      "Batch Loss: 0.64568692445755\n",
      "Batch Loss: 0.6575837135314941\n",
      "Batch Loss: 0.6575709581375122\n",
      "Batch Loss: 0.6279304027557373\n",
      "Batch Loss: 0.6516604423522949\n",
      "Batch Loss: 0.6791315674781799\n",
      "Batch Loss: 0.6753653287887573\n",
      "Batch Loss: 0.6456993222236633\n",
      "Batch Loss: 0.6575958728790283\n",
      "Batch Loss: 0.6635063886642456\n",
      "Batch Loss: 0.6575706005096436\n",
      "Batch Loss: 0.657558023929596\n",
      "Batch Loss: 0.6516348123550415\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6516597270965576\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672008037567139\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6753525137901306\n",
      "Batch Loss: 0.6456987857818604\n",
      "Batch Loss: 0.6694167256355286\n",
      "Batch Loss: 0.6909437775611877\n",
      "Batch Loss: 0.6634934544563293\n",
      "Batch Loss: 0.6398001909255981\n",
      "Batch Loss: 0.6516343951225281\n",
      "Batch Loss: 0.6694166660308838\n",
      "Batch Loss: 0.6338518857955933\n",
      "Batch Loss: 0.6338889598846436\n",
      "Batch Loss: 0.6635056734085083\n",
      "Batch Loss: 0.6338270902633667\n",
      "Batch Loss: 0.6635178923606873\n",
      "Batch Loss: 0.6694166660308838\n",
      "Batch Loss: 0.6813002824783325\n",
      "Batch Loss: 0.6753645539283752\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6456860303878784\n",
      "Batch Loss: 0.6516338586807251\n",
      "Batch Loss: 0.6791058778762817\n",
      "Batch Loss: 0.6909894347190857\n",
      "Batch Loss: 0.6694409251213074\n",
      "Batch Loss: 0.6553629636764526\n",
      "Batch Loss: 0.6850085258483887\n",
      "Batch Loss: 0.6516579985618591\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6575693488121033\n",
      "Batch Loss: 0.6494064331054688\n",
      "Batch Loss: 0.6731700301170349\n",
      "Batch Loss: 0.6457099914550781\n",
      "Batch Loss: 0.6494306325912476\n",
      "Batch Loss: 0.6634927988052368\n",
      "Batch Loss: 0.6457339525222778\n",
      "Batch Loss: 0.6791056990623474\n",
      "Batch Loss: 0.6672463417053223\n",
      "Batch Loss: 0.6753520965576172\n",
      "Batch Loss: 0.6575570106506348\n",
      "Batch Loss: 0.6575570106506348\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6850413084030151\n",
      "Batch Loss: 0.67318195104599\n",
      "Batch Loss: 0.6575809121131897\n",
      "Batch Loss: 0.6456974744796753\n",
      "Batch Loss: 0.6575808525085449\n",
      "Batch Loss: 0.6725831031799316\n",
      "Batch Loss: 0.6694402098655701\n",
      "Batch Loss: 0.6634805202484131\n",
      "Batch Loss: 0.6397496461868286\n",
      "Batch Loss: 0.6672341227531433\n",
      "Batch Loss: 0.6753519773483276\n",
      "Batch Loss: 0.6516091227531433\n",
      "Batch Loss: 0.6494388580322266\n",
      "Batch Loss: 0.6279017925262451\n",
      "Batch Loss: 0.6694399118423462\n",
      "Batch Loss: 0.6731697916984558\n",
      "Batch Loss: 0.6257787942886353\n",
      "Batch Loss: 0.6435418725013733\n",
      "Batch Loss: 0.6634804010391235\n",
      "Batch Loss: 0.6909768581390381\n",
      "Batch Loss: 0.6694396734237671\n",
      "Batch Loss: 0.6634922027587891\n",
      "Batch Loss: 0.6828824281692505\n",
      "Batch Loss: 0.6397610306739807\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6791170835494995\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634920239448547\n",
      "Batch Loss: 0.66349196434021\n",
      "Batch Loss: 0.6635036468505859\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6494733095169067\n",
      "Batch Loss: 0.6575446128845215\n",
      "Batch Loss: 0.6456964015960693\n",
      "Batch Loss: 0.6494731903076172\n",
      "Batch Loss: 0.663480281829834\n",
      "Batch Loss: 0.6494531631469727\n",
      "Batch Loss: 0.6575561165809631\n",
      "Batch Loss: 0.6494730114936829\n",
      "Batch Loss: 0.6575676202774048\n",
      "Batch Loss: 0.6397836208343506\n",
      "Batch Loss: 0.6694158911705017\n",
      "Batch Loss: 0.667279839515686\n",
      "Batch Loss: 0.6397718191146851\n",
      "Batch Loss: 0.6397602558135986\n",
      "Batch Loss: 0.6575673818588257\n",
      "Batch Loss: 0.645707368850708\n",
      "Batch Loss: 0.6947301030158997\n",
      "Batch Loss: 0.6635029315948486\n",
      "Batch Loss: 0.6694158315658569\n",
      "Batch Loss: 0.6925821304321289\n",
      "Batch Loss: 0.6516200304031372\n",
      "Batch Loss: 0.657567024230957\n",
      "Batch Loss: 0.6850520372390747\n",
      "Batch Loss: 0.6634799838066101\n",
      "Batch Loss: 0.6613205671310425\n",
      "Batch Loss: 0.6812984347343445\n",
      "Batch Loss: 0.6812983751296997\n",
      "Batch Loss: 0.6554299592971802\n",
      "Batch Loss: 0.6946992874145508\n",
      "Batch Loss: 0.6694382429122925\n",
      "Batch Loss: 0.6753625869750977\n",
      "Batch Loss: 0.6634911894798279\n",
      "Batch Loss: 0.6575554609298706\n",
      "Batch Loss: 0.6694267988204956\n",
      "Batch Loss: 0.6635023355484009\n",
      "Batch Loss: 0.6850405931472778\n",
      "Batch Loss: 0.6516196131706238\n",
      "Batch Loss: 0.6731691360473633\n",
      "Batch Loss: 0.6553763747215271\n",
      "Batch Loss: 0.621974527835846\n",
      "Batch Loss: 0.6397704482078552\n",
      "Batch Loss: 0.651619553565979\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.66351318359375\n",
      "Batch Loss: 0.6635131239891052\n",
      "Batch Loss: 0.6516305208206177\n",
      "Batch Loss: 0.6397813558578491\n",
      "Batch Loss: 0.6516305208206177\n",
      "Batch Loss: 0.673180103302002\n",
      "Batch Loss: 0.6635128855705261\n",
      "Batch Loss: 0.6887860894203186\n",
      "Batch Loss: 0.6397589445114136\n",
      "Batch Loss: 0.657543957233429\n",
      "Batch Loss: 0.6635017395019531\n",
      "Batch Loss: 0.6457164883613586\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456944346427917\n",
      "Batch Loss: 0.6375765800476074\n",
      "Batch Loss: 0.6672143936157227\n",
      "Batch Loss: 0.6672253608703613\n",
      "Batch Loss: 0.6456834077835083\n",
      "Batch Loss: 0.6613302230834961\n",
      "Batch Loss: 0.6516408920288086\n",
      "Batch Loss: 0.633833646774292\n",
      "Batch Loss: 0.6694260835647583\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6828907132148743\n",
      "Batch Loss: 0.6575654745101929\n",
      "Batch Loss: 0.6694368720054626\n",
      "Batch Loss: 0.6516188979148865\n",
      "Batch Loss: 0.6338658928871155\n",
      "Batch Loss: 0.6160370111465454\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6732010841369629\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6850508451461792\n",
      "Batch Loss: 0.6790644526481628\n",
      "Batch Loss: 0.6672544479370117\n",
      "Batch Loss: 0.6494580507278442\n",
      "Batch Loss: 0.6694150567054749\n",
      "Batch Loss: 0.6694150567054749\n",
      "Batch Loss: 0.6791257858276367\n",
      "Batch Loss: 0.6694364547729492\n",
      "Batch Loss: 0.6731685996055603\n",
      "Batch Loss: 0.6457042694091797\n",
      "Batch Loss: 0.6634793281555176\n",
      "Batch Loss: 0.6731685400009155\n",
      "Batch Loss: 0.6791149377822876\n",
      "Batch Loss: 0.6887753009796143\n",
      "Batch Loss: 0.6694256067276001\n",
      "Batch Loss: 0.6575647592544556\n",
      "Batch Loss: 0.667232871055603\n",
      "Batch Loss: 0.661339521408081\n",
      "Batch Loss: 0.639757513999939\n",
      "Batch Loss: 0.671018123626709\n",
      "Batch Loss: 0.645693302154541\n",
      "Batch Loss: 0.6591466665267944\n",
      "Batch Loss: 0.6672433614730835\n",
      "Batch Loss: 0.663479208946228\n",
      "Batch Loss: 0.6575750112533569\n",
      "Batch Loss: 0.700675368309021\n",
      "Batch Loss: 0.6575645208358765\n",
      "Batch Loss: 0.669425368309021\n",
      "Batch Loss: 0.6456930041313171\n",
      "Batch Loss: 0.6731609106063843\n",
      "Batch Loss: 0.6553537845611572\n",
      "Batch Loss: 0.6753504872322083\n",
      "Batch Loss: 0.663489580154419\n",
      "Batch Loss: 0.6694148182868958\n",
      "Batch Loss: 0.6553537845611572\n",
      "Batch Loss: 0.6397675275802612\n",
      "Batch Loss: 0.6553716659545898\n",
      "Batch Loss: 0.6694459915161133\n",
      "Batch Loss: 0.6731891632080078\n",
      "Batch Loss: 0.6753608584403992\n",
      "Batch Loss: 0.6338420510292053\n",
      "Batch Loss: 0.6613280177116394\n",
      "Batch Loss: 0.6338315010070801\n",
      "Batch Loss: 0.6790862083435059\n",
      "Batch Loss: 0.6575433015823364\n",
      "Batch Loss: 0.6612790822982788\n",
      "Batch Loss: 0.6575742363929749\n",
      "Batch Loss: 0.6516178846359253\n",
      "Batch Loss: 0.7043799161911011\n",
      "Batch Loss: 0.6672325134277344\n",
      "Batch Loss: 0.6575638055801392\n",
      "Batch Loss: 0.6791244745254517\n",
      "Batch Loss: 0.6731681823730469\n",
      "Batch Loss: 0.6456717252731323\n",
      "Batch Loss: 0.6672530174255371\n",
      "Batch Loss: 0.6731784343719482\n",
      "Batch Loss: 0.6397360563278198\n",
      "Batch Loss: 0.6494662761688232\n",
      "Batch Loss: 0.6575738787651062\n",
      "Batch Loss: 0.6791141033172607\n",
      "Batch Loss: 0.6753605008125305\n",
      "Batch Loss: 0.6575533151626587\n",
      "Batch Loss: 0.6494559049606323\n",
      "Batch Loss: 0.6516380310058594\n",
      "Batch Loss: 0.6634889841079712\n",
      "Batch Loss: 0.6575430631637573\n",
      "Batch Loss: 0.6516175270080566\n",
      "Batch Loss: 0.6516276597976685\n",
      "Batch Loss: 0.661327064037323\n",
      "Batch Loss: 0.6850119829177856\n",
      "Batch Loss: 0.6516276001930237\n",
      "Batch Loss: 0.6456918716430664\n",
      "Batch Loss: 0.6768941283226013\n",
      "Batch Loss: 0.6457119584083557\n",
      "Batch Loss: 0.6397560834884644\n",
      "Batch Loss: 0.6753501296043396\n",
      "Batch Loss: 0.661306619644165\n",
      "Batch Loss: 0.6338504552841187\n",
      "Batch Loss: 0.6613094806671143\n",
      "Batch Loss: 0.6575630903244019\n",
      "Batch Loss: 0.6634887456893921\n",
      "Batch Loss: 0.6694143414497375\n",
      "Batch Loss: 0.6672250032424927\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.657572865486145\n",
      "Batch Loss: 0.645691454410553\n",
      "Batch Loss: 0.6278942823410034\n",
      "Batch Loss: 0.6791135668754578\n",
      "Batch Loss: 0.673167884349823\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634985208511353\n",
      "Batch Loss: 0.679133415222168\n",
      "Batch Loss: 0.6672520637512207\n",
      "Batch Loss: 0.6516368985176086\n",
      "Batch Loss: 0.6575428247451782\n",
      "Batch Loss: 0.6575428247451782\n",
      "Batch Loss: 0.6753499507904053\n",
      "Batch Loss: 0.63383948802948\n",
      "Batch Loss: 0.6850589513778687\n",
      "Batch Loss: 0.6634784936904907\n",
      "Batch Loss: 0.6634982228279114\n",
      "Batch Loss: 0.6753597259521484\n",
      "Batch Loss: 0.6634981632232666\n",
      "Batch Loss: 0.6613160371780396\n",
      "Batch Loss: 0.6694141626358032\n",
      "Batch Loss: 0.6694141626358032\n",
      "Batch Loss: 0.6731677055358887\n",
      "Batch Loss: 0.6338194608688354\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6435380578041077\n",
      "Batch Loss: 0.6397649049758911\n",
      "Batch Loss: 0.6338388919830322\n",
      "Batch Loss: 0.6575621366500854\n",
      "Batch Loss: 0.6338290572166443\n",
      "Batch Loss: 0.679122805595398\n",
      "Batch Loss: 0.639764666557312\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694236993789673\n",
      "Batch Loss: 0.663507342338562\n",
      "Batch Loss: 0.6575425863265991\n",
      "Batch Loss: 0.6634880304336548\n",
      "Batch Loss: 0.6397547721862793\n",
      "Batch Loss: 0.6753497123718262\n",
      "Batch Loss: 0.6456904411315918\n",
      "Batch Loss: 0.6613250374794006\n",
      "Batch Loss: 0.661315381526947\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6397641897201538\n",
      "Batch Loss: 0.6316490769386292\n",
      "Batch Loss: 0.6694139242172241\n",
      "Batch Loss: 0.621985673904419\n",
      "Batch Loss: 0.6694139242172241\n",
      "Batch Loss: 0.6376010179519653\n",
      "Batch Loss: 0.663497269153595\n",
      "Batch Loss: 0.6634876728057861\n",
      "Batch Loss: 0.6532257795333862\n",
      "Batch Loss: 0.6316459774971008\n",
      "Batch Loss: 0.6338280439376831\n",
      "Batch Loss: 0.6634781360626221\n",
      "Batch Loss: 0.6634780764579773\n",
      "Batch Loss: 0.6575707197189331\n",
      "Batch Loss: 0.6494528651237488\n",
      "Batch Loss: 0.65754234790802\n",
      "Batch Loss: 0.6575612425804138\n",
      "Batch Loss: 0.6575517654418945\n",
      "Batch Loss: 0.645699143409729\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.651606559753418\n",
      "Batch Loss: 0.6612704396247864\n",
      "Batch Loss: 0.6812945008277893\n",
      "Batch Loss: 0.667259693145752\n",
      "Batch Loss: 0.6575422883033752\n",
      "Batch Loss: 0.6909583806991577\n",
      "Batch Loss: 0.6694324016571045\n",
      "Batch Loss: 0.633855402469635\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6791029572486877\n",
      "Batch Loss: 0.6338366270065308\n",
      "Batch Loss: 0.6516157984733582\n",
      "Batch Loss: 0.6516250967979431\n",
      "Batch Loss: 0.6553786396980286\n",
      "Batch Loss: 0.6769140958786011\n",
      "Batch Loss: 0.6731698513031006\n",
      "Batch Loss: 0.6456800103187561\n",
      "Batch Loss: 0.6456985473632812\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6516433954238892\n",
      "Batch Loss: 0.6791120767593384\n",
      "Batch Loss: 0.675349235534668\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6791027784347534\n",
      "Batch Loss: 0.6634870171546936\n",
      "Batch Loss: 0.6575421094894409\n",
      "Batch Loss: 0.6279186606407166\n",
      "Batch Loss: 0.6615096926689148\n",
      "Epoch 4/20, Loss: 0.6602338813881011, Time: 490.51s\n",
      "Batch Loss: 0.6634869575500488\n",
      "Batch Loss: 0.6612799167633057\n",
      "Batch Loss: 0.6694226264953613\n",
      "Batch Loss: 0.6694318056106567\n",
      "Batch Loss: 0.6850476264953613\n",
      "Batch Loss: 0.645679771900177\n",
      "Batch Loss: 0.6634777784347534\n",
      "Batch Loss: 0.6694226264953613\n",
      "Batch Loss: 0.6850136518478394\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6456888318061829\n",
      "Batch Loss: 0.6812848448753357\n",
      "Batch Loss: 0.6575784087181091\n",
      "Batch Loss: 0.6672403812408447\n",
      "Batch Loss: 0.6613046526908875\n",
      "Batch Loss: 0.6709939241409302\n",
      "Batch Loss: 0.6338263750076294\n",
      "Batch Loss: 0.669422447681427\n",
      "Batch Loss: 0.6812938451766968\n",
      "Batch Loss: 0.6575690507888794\n",
      "Batch Loss: 0.6634776592254639\n",
      "Batch Loss: 0.663495659828186\n",
      "Batch Loss: 0.6494537591934204\n",
      "Batch Loss: 0.663495659828186\n",
      "Batch Loss: 0.6635046005249023\n",
      "Batch Loss: 0.6694133281707764\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456974744796753\n",
      "Batch Loss: 0.6575688123703003\n",
      "Batch Loss: 0.6456973552703857\n",
      "Batch Loss: 0.6694132685661316\n",
      "Batch Loss: 0.6672490239143372\n",
      "Batch Loss: 0.6753579378128052\n",
      "Batch Loss: 0.6456972360610962\n",
      "Batch Loss: 0.6731693744659424\n",
      "Batch Loss: 0.655335545539856\n",
      "Batch Loss: 0.673142671585083\n",
      "Batch Loss: 0.6434972286224365\n",
      "Batch Loss: 0.6456703543663025\n",
      "Batch Loss: 0.649432897567749\n",
      "Batch Loss: 0.6791291236877441\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575772762298584\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456969380378723\n",
      "Batch Loss: 0.6812846064567566\n",
      "Batch Loss: 0.639761209487915\n",
      "Batch Loss: 0.6694220304489136\n",
      "Batch Loss: 0.6516413688659668\n",
      "Batch Loss: 0.6850382089614868\n",
      "Batch Loss: 0.6634774208068848\n",
      "Batch Loss: 0.6553859710693359\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6338340044021606\n",
      "Batch Loss: 0.6516411304473877\n",
      "Batch Loss: 0.6731754541397095\n",
      "Batch Loss: 0.6634861826896667\n",
      "Batch Loss: 0.6456878185272217\n",
      "Batch Loss: 0.6828409433364868\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6732016205787659\n",
      "Batch Loss: 0.6850380897521973\n",
      "Batch Loss: 0.6516059637069702\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6575764417648315\n",
      "Batch Loss: 0.6694217324256897\n",
      "Batch Loss: 0.6375784277915955\n",
      "Batch Loss: 0.631668746471405\n",
      "Batch Loss: 0.6575676202774048\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6672481894493103\n",
      "Batch Loss: 0.6850466728210449\n",
      "Batch Loss: 0.6516145467758179\n",
      "Batch Loss: 0.6516144871711731\n",
      "Batch Loss: 0.6865946054458618\n",
      "Batch Loss: 0.6575415134429932\n",
      "Batch Loss: 0.6397688388824463\n",
      "Batch Loss: 0.6650683283805847\n",
      "Batch Loss: 0.6613061428070068\n",
      "Batch Loss: 0.6338244080543518\n",
      "Batch Loss: 0.6612950563430786\n",
      "Batch Loss: 0.6397601366043091\n",
      "Batch Loss: 0.6338072419166565\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6457042694091797\n",
      "Batch Loss: 0.6731835603713989\n",
      "Batch Loss: 0.6397343873977661\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6909735202789307\n",
      "Batch Loss: 0.6456955671310425\n",
      "Batch Loss: 0.6494320631027222\n",
      "Batch Loss: 0.6456869840621948\n",
      "Batch Loss: 0.6634856462478638\n",
      "Batch Loss: 0.6634771227836609\n",
      "Batch Loss: 0.6160253286361694\n",
      "Batch Loss: 0.6635025143623352\n",
      "Batch Loss: 0.6753569841384888\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6516225337982178\n",
      "Batch Loss: 0.649448812007904\n",
      "Batch Loss: 0.6457120776176453\n",
      "Batch Loss: 0.6456699371337891\n",
      "Batch Loss: 0.6672306060791016\n",
      "Batch Loss: 0.6613032817840576\n",
      "Batch Loss: 0.6887912750244141\n",
      "Batch Loss: 0.6650484800338745\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6516056060791016\n",
      "Batch Loss: 0.6731746792793274\n",
      "Batch Loss: 0.6753568053245544\n",
      "Batch Loss: 0.6435211896896362\n",
      "Batch Loss: 0.6457033157348633\n",
      "Batch Loss: 0.6694210767745972\n",
      "Batch Loss: 0.6634769439697266\n",
      "Batch Loss: 0.6456865072250366\n",
      "Batch Loss: 0.6554007530212402\n",
      "Batch Loss: 0.6850376129150391\n",
      "Batch Loss: 0.6634935736656189\n",
      "Batch Loss: 0.6279125213623047\n",
      "Batch Loss: 0.6553839445114136\n",
      "Batch Loss: 0.6516220569610596\n",
      "Batch Loss: 0.6791019439697266\n",
      "Batch Loss: 0.6575659513473511\n",
      "Batch Loss: 0.6397505402565002\n",
      "Batch Loss: 0.6575411558151245\n",
      "Batch Loss: 0.6634851098060608\n",
      "Batch Loss: 0.6397587060928345\n",
      "Batch Loss: 0.679110050201416\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6812839508056641\n",
      "Batch Loss: 0.657557487487793\n",
      "Batch Loss: 0.6516135931015015\n",
      "Batch Loss: 0.6516217589378357\n",
      "Batch Loss: 0.675356388092041\n",
      "Batch Loss: 0.6278870105743408\n",
      "Batch Loss: 0.6100962162017822\n",
      "Batch Loss: 0.6753563284873962\n",
      "Batch Loss: 0.657541036605835\n",
      "Batch Loss: 0.6397339105606079\n",
      "Batch Loss: 0.6575573086738586\n",
      "Batch Loss: 0.6791017651557922\n",
      "Batch Loss: 0.6694124937057495\n",
      "Batch Loss: 0.6634767055511475\n",
      "Batch Loss: 0.6575653553009033\n",
      "Batch Loss: 0.6731740832328796\n",
      "Batch Loss: 0.6553831100463867\n",
      "Batch Loss: 0.6887990832328796\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6516375541687012\n",
      "Batch Loss: 0.6516295075416565\n",
      "Batch Loss: 0.6634847521781921\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6457017064094543\n",
      "Batch Loss: 0.6456695199012756\n",
      "Batch Loss: 0.6456936597824097\n",
      "Batch Loss: 0.6338061094284058\n",
      "Batch Loss: 0.6375997066497803\n",
      "Batch Loss: 0.6575409173965454\n",
      "Batch Loss: 0.6672462224960327\n",
      "Batch Loss: 0.6516052484512329\n",
      "Batch Loss: 0.6731681823730469\n",
      "Batch Loss: 0.6397337913513184\n",
      "Batch Loss: 0.6516051292419434\n",
      "Batch Loss: 0.6850532293319702\n",
      "Batch Loss: 0.6634765863418579\n",
      "Batch Loss: 0.6375755071640015\n",
      "Batch Loss: 0.6731522083282471\n",
      "Batch Loss: 0.6456932425498962\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6397574543952942\n",
      "Batch Loss: 0.6516130566596985\n",
      "Batch Loss: 0.6731737852096558\n",
      "Batch Loss: 0.6456851959228516\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575723886489868\n",
      "Batch Loss: 0.6850451231002808\n",
      "Batch Loss: 0.6694358587265015\n",
      "Batch Loss: 0.6575565338134766\n",
      "Batch Loss: 0.6634843349456787\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6694278717041016\n",
      "Batch Loss: 0.6575564742088318\n",
      "Batch Loss: 0.6753479242324829\n",
      "Batch Loss: 0.6456849575042725\n",
      "Batch Loss: 0.6456928253173828\n",
      "Batch Loss: 0.6516128778457642\n",
      "Batch Loss: 0.6516284942626953\n",
      "Batch Loss: 0.6575562953948975\n",
      "Batch Loss: 0.651620626449585\n",
      "Batch Loss: 0.6575719118118286\n",
      "Batch Loss: 0.6375747919082642\n",
      "Batch Loss: 0.6338289380073547\n",
      "Batch Loss: 0.694718599319458\n",
      "Batch Loss: 0.6672532558441162\n",
      "Batch Loss: 0.6731734275817871\n",
      "Batch Loss: 0.6634840965270996\n",
      "Batch Loss: 0.6731734275817871\n",
      "Batch Loss: 0.6516281366348267\n",
      "Batch Loss: 0.6709569692611694\n",
      "Batch Loss: 0.6397489309310913\n",
      "Batch Loss: 0.6516203284263611\n",
      "Batch Loss: 0.6456845998764038\n",
      "Batch Loss: 0.6753477454185486\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6531994342803955\n",
      "Batch Loss: 0.6456922292709351\n",
      "Batch Loss: 0.6753477454185486\n",
      "Batch Loss: 0.6769059896469116\n",
      "Batch Loss: 0.6575635671615601\n",
      "Batch Loss: 0.6612886786460876\n",
      "Batch Loss: 0.6613039970397949\n",
      "Batch Loss: 0.679101288318634\n",
      "Batch Loss: 0.6791012287139893\n",
      "Batch Loss: 0.6634991765022278\n",
      "Batch Loss: 0.6613038778305054\n",
      "Batch Loss: 0.6494531631469727\n",
      "Batch Loss: 0.6456843614578247\n",
      "Batch Loss: 0.6791012287139893\n",
      "Batch Loss: 0.6516200304031372\n",
      "Batch Loss: 0.6613017320632935\n",
      "Batch Loss: 0.6613168716430664\n",
      "Batch Loss: 0.6516123414039612\n",
      "Batch Loss: 0.6516199111938477\n",
      "Batch Loss: 0.669419527053833\n",
      "Batch Loss: 0.6753475666046143\n",
      "Batch Loss: 0.6753551959991455\n",
      "Batch Loss: 0.6456841230392456\n",
      "Batch Loss: 0.6338353753089905\n",
      "Batch Loss: 0.6612940430641174\n",
      "Batch Loss: 0.6613090634346008\n",
      "Batch Loss: 0.6672447919845581\n",
      "Batch Loss: 0.6575554609298706\n",
      "Batch Loss: 0.6634836196899414\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.669411838054657\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6338424682617188\n",
      "Batch Loss: 0.6575478315353394\n",
      "Batch Loss: 0.6278618574142456\n",
      "Batch Loss: 0.6553657054901123\n",
      "Batch Loss: 0.6516419649124146\n",
      "Batch Loss: 0.649437427520752\n",
      "Batch Loss: 0.6575403809547424\n",
      "Batch Loss: 0.6731451749801636\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.645683765411377\n",
      "Batch Loss: 0.6753548979759216\n",
      "Batch Loss: 0.6516120433807373\n",
      "Batch Loss: 0.6575477719306946\n",
      "Batch Loss: 0.6672370433807373\n",
      "Batch Loss: 0.6672370433807373\n",
      "Batch Loss: 0.6694265604019165\n",
      "Batch Loss: 0.6731600761413574\n",
      "Batch Loss: 0.6634759902954102\n",
      "Batch Loss: 0.6791010499000549\n",
      "Batch Loss: 0.6694190502166748\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6613085865974426\n",
      "Batch Loss: 0.6634907722473145\n",
      "Batch Loss: 0.6694117188453674\n",
      "Batch Loss: 0.6516265869140625\n",
      "Batch Loss: 0.6909524202346802\n",
      "Batch Loss: 0.6769261956214905\n",
      "Batch Loss: 0.6516339182853699\n",
      "Batch Loss: 0.6634833216667175\n",
      "Batch Loss: 0.6456761956214905\n",
      "Batch Loss: 0.6278836727142334\n",
      "Batch Loss: 0.679088294506073\n",
      "Batch Loss: 0.6516337990760803\n",
      "Batch Loss: 0.6731871366500854\n",
      "Batch Loss: 0.6456906795501709\n",
      "Batch Loss: 0.6456760764122009\n",
      "Batch Loss: 0.6753473281860352\n",
      "Batch Loss: 0.6812830567359924\n",
      "Batch Loss: 0.6575402021408081\n",
      "Batch Loss: 0.6397476196289062\n",
      "Batch Loss: 0.6634831428527832\n",
      "Batch Loss: 0.6694116592407227\n",
      "Batch Loss: 0.6753472685813904\n",
      "Batch Loss: 0.6672366857528687\n",
      "Batch Loss: 0.6694115996360779\n",
      "Batch Loss: 0.6672170162200928\n",
      "Batch Loss: 0.6731796264648438\n",
      "Batch Loss: 0.6575473546981812\n",
      "Batch Loss: 0.6516188979148865\n",
      "Batch Loss: 0.6694115400314331\n",
      "Batch Loss: 0.6850365400314331\n",
      "Batch Loss: 0.6494439244270325\n",
      "Batch Loss: 0.6338261365890503\n",
      "Batch Loss: 0.6553868055343628\n",
      "Batch Loss: 0.6575473546981812\n",
      "Batch Loss: 0.6731866598129272\n",
      "Batch Loss: 0.6575545072555542\n",
      "Batch Loss: 0.6753472089767456\n",
      "Batch Loss: 0.6672098636627197\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6731722354888916\n",
      "Batch Loss: 0.6456829905509949\n",
      "Batch Loss: 0.663475751876831\n",
      "Batch Loss: 0.6456900835037231\n",
      "Batch Loss: 0.6575543880462646\n",
      "Batch Loss: 0.6613079309463501\n",
      "Batch Loss: 0.6613150238990784\n",
      "Batch Loss: 0.6575471758842468\n",
      "Batch Loss: 0.655372142791748\n",
      "Batch Loss: 0.6516185402870178\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6575613617897034\n",
      "Batch Loss: 0.6634899377822876\n",
      "Batch Loss: 0.6338184475898743\n",
      "Batch Loss: 0.651618480682373\n",
      "Batch Loss: 0.6575541496276855\n",
      "Batch Loss: 0.6694114208221436\n",
      "Batch Loss: 0.669418454170227\n",
      "Batch Loss: 0.645696759223938\n",
      "Batch Loss: 0.655371904373169\n",
      "Batch Loss: 0.6278825998306274\n",
      "Batch Loss: 0.6887708306312561\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694114208221436\n",
      "Batch Loss: 0.6753610968589783\n",
      "Batch Loss: 0.6591604948043823\n",
      "Batch Loss: 0.6516252756118774\n",
      "Batch Loss: 0.6278893947601318\n",
      "Batch Loss: 0.6516112089157104\n",
      "Batch Loss: 0.6397538185119629\n",
      "Batch Loss: 0.6516251564025879\n",
      "Batch Loss: 0.6613074541091919\n",
      "Batch Loss: 0.6456823945045471\n",
      "Batch Loss: 0.6575468182563782\n",
      "Batch Loss: 0.6828680634498596\n",
      "Batch Loss: 0.6575468182563782\n",
      "Batch Loss: 0.6397466063499451\n",
      "Batch Loss: 0.6575467586517334\n",
      "Batch Loss: 0.6494635343551636\n",
      "Batch Loss: 0.6731786727905273\n",
      "Batch Loss: 0.6553527116775513\n",
      "Batch Loss: 0.6650489568710327\n",
      "Batch Loss: 0.6516109704971313\n",
      "Batch Loss: 0.645689070224762\n",
      "Batch Loss: 0.6575398445129395\n",
      "Batch Loss: 0.6672496795654297\n",
      "Batch Loss: 0.6575466990470886\n",
      "Batch Loss: 0.6850361824035645\n",
      "Batch Loss: 0.6694180369377136\n",
      "Batch Loss: 0.6575603485107422\n",
      "Batch Loss: 0.6575397253036499\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6968890428543091\n",
      "Batch Loss: 0.6575534343719482\n",
      "Batch Loss: 0.651617705821991\n",
      "Batch Loss: 0.675346851348877\n",
      "Batch Loss: 0.694706916809082\n",
      "Batch Loss: 0.6397530436515808\n",
      "Batch Loss: 0.6456751823425293\n",
      "Batch Loss: 0.6279088258743286\n",
      "Batch Loss: 0.6553663611412048\n",
      "Batch Loss: 0.6397461891174316\n",
      "Batch Loss: 0.6694111824035645\n",
      "Batch Loss: 0.6575533151626587\n",
      "Batch Loss: 0.6613000631332397\n",
      "Batch Loss: 0.6613000631332397\n",
      "Batch Loss: 0.6812893152236938\n",
      "Batch Loss: 0.649416983127594\n",
      "Batch Loss: 0.6634753942489624\n",
      "Batch Loss: 0.6634888648986816\n",
      "Batch Loss: 0.6672492027282715\n",
      "Batch Loss: 0.6516309976577759\n",
      "Batch Loss: 0.6397459506988525\n",
      "Batch Loss: 0.7065900564193726\n",
      "Batch Loss: 0.657559871673584\n",
      "Batch Loss: 0.67317134141922\n",
      "Batch Loss: 0.6397459506988525\n",
      "Batch Loss: 0.6731712818145752\n",
      "Batch Loss: 0.6338168382644653\n",
      "Batch Loss: 0.65755295753479\n",
      "Batch Loss: 0.6634752750396729\n",
      "Batch Loss: 0.6612817049026489\n",
      "Batch Loss: 0.6575596332550049\n",
      "Batch Loss: 0.6456948518753052\n",
      "Batch Loss: 0.6791069507598877\n",
      "Batch Loss: 0.6397591829299927\n",
      "Batch Loss: 0.6634819507598877\n",
      "Batch Loss: 0.6634819507598877\n",
      "Batch Loss: 0.6731645464897156\n",
      "Batch Loss: 0.6812824010848999\n",
      "Batch Loss: 0.6753532886505127\n",
      "Batch Loss: 0.6753532886505127\n",
      "Batch Loss: 0.6866140365600586\n",
      "Batch Loss: 0.6947006583213806\n",
      "Batch Loss: 0.6872180700302124\n",
      "Batch Loss: 0.6575593948364258\n",
      "Batch Loss: 0.6575394868850708\n",
      "Batch Loss: 0.6634883880615234\n",
      "Batch Loss: 0.6516236066818237\n",
      "Batch Loss: 0.6575527191162109\n",
      "Batch Loss: 0.649448037147522\n",
      "Batch Loss: 0.6456812620162964\n",
      "Batch Loss: 0.6909716129302979\n",
      "Batch Loss: 0.6634817123413086\n",
      "Batch Loss: 0.6575526595115662\n",
      "Batch Loss: 0.6591240763664246\n",
      "Batch Loss: 0.6516103148460388\n",
      "Batch Loss: 0.6456876993179321\n",
      "Batch Loss: 0.6812822818756104\n",
      "Batch Loss: 0.6769245862960815\n",
      "Batch Loss: 0.6791001558303833\n",
      "Batch Loss: 0.6338162422180176\n",
      "Batch Loss: 0.633803129196167\n",
      "Batch Loss: 0.6694173812866211\n",
      "Batch Loss: 0.6575459241867065\n",
      "Batch Loss: 0.6694173812866211\n",
      "Batch Loss: 0.6338095664978027\n",
      "Batch Loss: 0.6575524210929871\n",
      "Batch Loss: 0.676924467086792\n",
      "Batch Loss: 0.6575523614883423\n",
      "Batch Loss: 0.6375631093978882\n",
      "Batch Loss: 0.6828490495681763\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6850247383117676\n",
      "Batch Loss: 0.6672480702400208\n",
      "Batch Loss: 0.6316531300544739\n",
      "Batch Loss: 0.6575523018836975\n",
      "Batch Loss: 0.6672351360321045\n",
      "Batch Loss: 0.6435115337371826\n",
      "Batch Loss: 0.651623010635376\n",
      "Batch Loss: 0.6694172024726868\n",
      "Batch Loss: 0.6553893089294434\n",
      "Batch Loss: 0.6456807851791382\n",
      "Batch Loss: 0.6553828716278076\n",
      "Batch Loss: 0.6575521230697632\n",
      "Batch Loss: 0.6612992286682129\n",
      "Batch Loss: 0.669417142868042\n",
      "Batch Loss: 0.6456871032714844\n",
      "Batch Loss: 0.6278862953186035\n",
      "Batch Loss: 0.6456679105758667\n",
      "Batch Loss: 0.645693302154541\n",
      "Batch Loss: 0.6694107055664062\n",
      "Batch Loss: 0.6160019636154175\n",
      "Batch Loss: 0.6516035795211792\n",
      "Batch Loss: 0.6219567060470581\n",
      "Batch Loss: 0.6753463745117188\n",
      "Batch Loss: 0.6375563144683838\n",
      "Batch Loss: 0.6575518846511841\n",
      "Batch Loss: 0.661281943321228\n",
      "Batch Loss: 0.6634938716888428\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634874939918518\n",
      "Batch Loss: 0.667241096496582\n",
      "Batch Loss: 0.6613116264343262\n",
      "Batch Loss: 0.6634812355041504\n",
      "Batch Loss: 0.6612990498542786\n",
      "Batch Loss: 0.6397445797920227\n",
      "Batch Loss: 0.6138339042663574\n",
      "Batch Loss: 0.6694168448448181\n",
      "Batch Loss: 0.7006668448448181\n",
      "Batch Loss: 0.6575579047203064\n",
      "Batch Loss: 0.657551646232605\n",
      "Batch Loss: 0.6769132614135742\n",
      "Batch Loss: 0.6612989902496338\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.637580931186676\n",
      "Batch Loss: 0.6516158580780029\n",
      "Batch Loss: 0.6456925272941589\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753524541854858\n",
      "Batch Loss: 0.6634933948516846\n",
      "Batch Loss: 0.6575514078140259\n",
      "Batch Loss: 0.6553693413734436\n",
      "Batch Loss: 0.6516095399856567\n",
      "Batch Loss: 0.6494458913803101\n",
      "Batch Loss: 0.6434934139251709\n",
      "Batch Loss: 0.6634809374809265\n",
      "Batch Loss: 0.645686149597168\n",
      "Batch Loss: 0.6456860899925232\n",
      "Batch Loss: 0.6516156792640686\n",
      "Batch Loss: 0.6731702089309692\n",
      "Batch Loss: 0.6338268518447876\n",
      "Batch Loss: 0.6753584146499634\n",
      "Batch Loss: 0.6866130232810974\n",
      "Batch Loss: 0.6628596782684326\n",
      "Batch Loss: 0.6694165468215942\n",
      "Batch Loss: 0.6494333744049072\n",
      "Batch Loss: 0.6278848648071289\n",
      "Batch Loss: 0.6909711360931396\n",
      "Batch Loss: 0.6575572490692139\n",
      "Batch Loss: 0.6694164872169495\n",
      "Batch Loss: 0.6791118383407593\n",
      "Batch Loss: 0.6278907656669617\n",
      "Batch Loss: 0.6575510501861572\n",
      "Batch Loss: 0.6434975862503052\n",
      "Batch Loss: 0.6575510501861572\n",
      "Batch Loss: 0.6650581955909729\n",
      "Batch Loss: 0.6516274213790894\n",
      "Batch Loss: 0.6947022676467896\n",
      "Batch Loss: 0.6435154676437378\n",
      "Batch Loss: 0.6634806394577026\n",
      "Batch Loss: 0.6278724074363708\n",
      "Batch Loss: 0.6613045930862427\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634926795959473\n",
      "Batch Loss: 0.6753460168838501\n",
      "Batch Loss: 0.6397437453269958\n",
      "Batch Loss: 0.6634865999221802\n",
      "Batch Loss: 0.6694222688674927\n",
      "Batch Loss: 0.6575448513031006\n",
      "Batch Loss: 0.6634865403175354\n",
      "Batch Loss: 0.6634745597839355\n",
      "Batch Loss: 0.6887786388397217\n",
      "Batch Loss: 0.6672298908233643\n",
      "Batch Loss: 0.6456793546676636\n",
      "Batch Loss: 0.6731698513031006\n",
      "Batch Loss: 0.6634805202484131\n",
      "Batch Loss: 0.6672400236129761\n",
      "Batch Loss: 0.6634745597839355\n",
      "Batch Loss: 0.6456911563873291\n",
      "Batch Loss: 0.62788987159729\n",
      "Batch Loss: 0.6672281622886658\n",
      "Batch Loss: 0.6709994673728943\n",
      "Batch Loss: 0.6709994077682495\n",
      "Batch Loss: 0.6575623750686646\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575506329536438\n",
      "Batch Loss: 0.6516266465187073\n",
      "Batch Loss: 0.673169732093811\n",
      "Batch Loss: 0.6634862422943115\n",
      "Batch Loss: 0.6100707650184631\n",
      "Batch Loss: 0.6634803414344788\n",
      "Batch Loss: 0.6553624868392944\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6650692820549011\n",
      "Batch Loss: 0.669410228729248\n",
      "Batch Loss: 0.6613039970397949\n",
      "Batch Loss: 0.6694159507751465\n",
      "Batch Loss: 0.700650155544281\n",
      "Batch Loss: 0.6731696128845215\n",
      "Batch Loss: 0.6516205072402954\n",
      "Batch Loss: 0.621947705745697\n",
      "Batch Loss: 0.6731695532798767\n",
      "Batch Loss: 0.6694217324256897\n",
      "Batch Loss: 0.6575444936752319\n",
      "Batch Loss: 0.6672238111495972\n",
      "Batch Loss: 0.6731653213500977\n",
      "Batch Loss: 0.6790894269943237\n",
      "Batch Loss: 0.6909708380699158\n",
      "Batch Loss: 0.6575444936752319\n",
      "Batch Loss: 0.6338015794754028\n",
      "Batch Loss: 0.6278716921806335\n",
      "Batch Loss: 0.6516029834747314\n",
      "Batch Loss: 0.6516087651252747\n",
      "Batch Loss: 0.643486738204956\n",
      "Batch Loss: 0.6613037586212158\n",
      "Batch Loss: 0.6338131427764893\n",
      "Batch Loss: 0.6688051819801331\n",
      "Batch Loss: 0.6634801626205444\n",
      "Batch Loss: 0.6575443744659424\n",
      "Batch Loss: 0.6672337055206299\n",
      "Batch Loss: 0.6672295928001404\n",
      "Batch Loss: 0.6494436860084534\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397372484207153\n",
      "Batch Loss: 0.6338015198707581\n",
      "Batch Loss: 0.6634800434112549\n",
      "Batch Loss: 0.6456786394119263\n",
      "Batch Loss: 0.6338186264038086\n",
      "Batch Loss: 0.6553735733032227\n",
      "Batch Loss: 0.670971691608429\n",
      "Batch Loss: 0.651637077331543\n",
      "Batch Loss: 0.690949559211731\n",
      "Batch Loss: 0.6516312956809998\n",
      "Batch Loss: 0.6694157123565674\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6634799838066101\n",
      "Batch Loss: 0.6219583749771118\n",
      "Batch Loss: 0.6650416851043701\n",
      "Batch Loss: 0.6456727981567383\n",
      "Batch Loss: 0.6553733944892883\n",
      "Batch Loss: 0.673186182975769\n",
      "Batch Loss: 0.6909763216972351\n",
      "Batch Loss: 0.6516197919845581\n",
      "Batch Loss: 0.639737069606781\n",
      "Batch Loss: 0.6575441956520081\n",
      "Batch Loss: 0.6753456592559814\n",
      "Batch Loss: 0.6614901423454285\n",
      "Epoch 5/20, Loss: 0.6602092122868873, Time: 501.19s\n",
      "Batch Loss: 0.6575385332107544\n",
      "Batch Loss: 0.6456784009933472\n",
      "Batch Loss: 0.6634854078292847\n",
      "Batch Loss: 0.6516084671020508\n",
      "Batch Loss: 0.6456782817840576\n",
      "Batch Loss: 0.6634798049926758\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.669409990310669\n",
      "Batch Loss: 0.6672277450561523\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6278822422027588\n",
      "Batch Loss: 0.6575440764427185\n",
      "Batch Loss: 0.6694098711013794\n",
      "Batch Loss: 0.643518328666687\n",
      "Batch Loss: 0.645672619342804\n",
      "Batch Loss: 0.6456726789474487\n",
      "Batch Loss: 0.6456781625747681\n",
      "Batch Loss: 0.663479745388031\n",
      "Batch Loss: 0.643486499786377\n",
      "Batch Loss: 0.6694098711013794\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6612920165061951\n",
      "Batch Loss: 0.6694098711013794\n",
      "Batch Loss: 0.6375492215156555\n",
      "Batch Loss: 0.6397478580474854\n",
      "Batch Loss: 0.6694154143333435\n",
      "Batch Loss: 0.6516302824020386\n",
      "Batch Loss: 0.6731594800949097\n",
      "Batch Loss: 0.6984682679176331\n",
      "Batch Loss: 0.6634906530380249\n",
      "Batch Loss: 0.6338120698928833\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6613029837608337\n",
      "Batch Loss: 0.6694153547286987\n",
      "Batch Loss: 0.6828582286834717\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6753455400466919\n",
      "Batch Loss: 0.6516081690788269\n",
      "Batch Loss: 0.6516081094741821\n",
      "Batch Loss: 0.6575493812561035\n",
      "Batch Loss: 0.6575438380241394\n",
      "Batch Loss: 0.645677924156189\n",
      "Batch Loss: 0.6575384140014648\n",
      "Batch Loss: 0.6397530436515808\n",
      "Batch Loss: 0.6219295859336853\n",
      "Batch Loss: 0.6494314074516296\n",
      "Batch Loss: 0.6634849309921265\n",
      "Batch Loss: 0.6553726196289062\n",
      "Batch Loss: 0.6456669569015503\n",
      "Batch Loss: 0.6456886529922485\n",
      "Batch Loss: 0.6709827184677124\n",
      "Batch Loss: 0.6516135334968567\n",
      "Batch Loss: 0.6694151759147644\n",
      "Batch Loss: 0.6435173153877258\n",
      "Batch Loss: 0.6516134738922119\n",
      "Batch Loss: 0.6516134738922119\n",
      "Batch Loss: 0.6887937188148499\n",
      "Batch Loss: 0.6397581100463867\n",
      "Batch Loss: 0.6634848117828369\n",
      "Batch Loss: 0.6397473812103271\n",
      "Batch Loss: 0.6575436592102051\n",
      "Batch Loss: 0.6634955406188965\n",
      "Batch Loss: 0.6731686592102051\n",
      "Batch Loss: 0.6613079309463501\n",
      "Batch Loss: 0.6694150567054749\n",
      "Batch Loss: 0.6575382947921753\n",
      "Batch Loss: 0.6516079306602478\n",
      "Batch Loss: 0.6397578716278076\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6872168183326721\n",
      "Batch Loss: 0.6634793281555176\n",
      "Batch Loss: 0.6709970831871033\n",
      "Batch Loss: 0.6516237854957581\n",
      "Batch Loss: 0.6575541496276855\n",
      "Batch Loss: 0.6709825992584229\n",
      "Batch Loss: 0.6434899568557739\n",
      "Batch Loss: 0.6397575736045837\n",
      "Batch Loss: 0.6456932425498962\n",
      "Batch Loss: 0.6812863349914551\n",
      "Batch Loss: 0.639746904373169\n",
      "Batch Loss: 0.6850203275680542\n",
      "Batch Loss: 0.663473904132843\n",
      "Batch Loss: 0.657548725605011\n",
      "Batch Loss: 0.6634844541549683\n",
      "Batch Loss: 0.6456930041313171\n",
      "Batch Loss: 0.6553627848625183\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.6397467851638794\n",
      "Batch Loss: 0.6338109970092773\n",
      "Batch Loss: 0.6613022089004517\n",
      "Batch Loss: 0.6769167184829712\n",
      "Batch Loss: 0.6575486063957214\n",
      "Batch Loss: 0.6731735467910767\n",
      "Batch Loss: 0.6553522944450378\n",
      "Batch Loss: 0.6575485467910767\n",
      "Batch Loss: 0.6672482490539551\n",
      "Batch Loss: 0.6456823348999023\n",
      "Batch Loss: 0.6494358777999878\n",
      "Batch Loss: 0.6456822752952576\n",
      "Batch Loss: 0.6516127586364746\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6397465467453003\n",
      "Batch Loss: 0.6753504276275635\n",
      "Batch Loss: 0.6790988445281982\n",
      "Batch Loss: 0.6612916588783264\n",
      "Batch Loss: 0.6516023874282837\n",
      "Batch Loss: 0.6516075134277344\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575432419776917\n",
      "Batch Loss: 0.6278904676437378\n",
      "Batch Loss: 0.657553493976593\n",
      "Batch Loss: 0.6850396394729614\n",
      "Batch Loss: 0.6456923484802246\n",
      "Batch Loss: 0.6694145798683167\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397514343261719\n",
      "Batch Loss: 0.6516125202178955\n",
      "Batch Loss: 0.6456819176673889\n",
      "Batch Loss: 0.6687914133071899\n",
      "Batch Loss: 0.6613069176673889\n",
      "Batch Loss: 0.6753502488136292\n",
      "Batch Loss: 0.6516175866127014\n",
      "Batch Loss: 0.6278899908065796\n",
      "Batch Loss: 0.6709961295127869\n",
      "Batch Loss: 0.6553522348403931\n",
      "Batch Loss: 0.6790987253189087\n",
      "Batch Loss: 0.6850343942642212\n",
      "Batch Loss: 0.6694144606590271\n",
      "Batch Loss: 0.6575480699539185\n",
      "Batch Loss: 0.6278847455978394\n",
      "Batch Loss: 0.6456766724586487\n",
      "Batch Loss: 0.6828674077987671\n",
      "Batch Loss: 0.6553659439086914\n",
      "Batch Loss: 0.6456665396690369\n",
      "Batch Loss: 0.6791037321090698\n",
      "Batch Loss: 0.6694144010543823\n",
      "Batch Loss: 0.6753501296043396\n",
      "Batch Loss: 0.6672272086143494\n",
      "Batch Loss: 0.6397508978843689\n",
      "Batch Loss: 0.6516122817993164\n",
      "Batch Loss: 0.6909750699996948\n",
      "Batch Loss: 0.6613065600395203\n",
      "Batch Loss: 0.6731679439544678\n",
      "Batch Loss: 0.6672372221946716\n",
      "Batch Loss: 0.6672186255455017\n",
      "Batch Loss: 0.7006457448005676\n",
      "Batch Loss: 0.6634786128997803\n",
      "Batch Loss: 0.6516071557998657\n",
      "Batch Loss: 0.6634786128997803\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456664800643921\n",
      "Batch Loss: 0.6553707122802734\n",
      "Batch Loss: 0.6456763744354248\n",
      "Batch Loss: 0.6634835004806519\n",
      "Batch Loss: 0.6278891563415527\n",
      "Batch Loss: 0.6694192290306091\n",
      "Batch Loss: 0.6456813216209412\n",
      "Batch Loss: 0.6613013744354248\n",
      "Batch Loss: 0.6812807321548462\n",
      "Batch Loss: 0.6575428247451782\n",
      "Batch Loss: 0.6516120433807373\n",
      "Batch Loss: 0.6397455334663391\n",
      "Batch Loss: 0.6516070365905762\n",
      "Batch Loss: 0.6456910371780396\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575378775596619\n",
      "Batch Loss: 0.6575427055358887\n",
      "Batch Loss: 0.6516021490097046\n",
      "Batch Loss: 0.6812806129455566\n",
      "Batch Loss: 0.6753449440002441\n",
      "Batch Loss: 0.6694092750549316\n",
      "Batch Loss: 0.6790984869003296\n",
      "Batch Loss: 0.6753498315811157\n",
      "Batch Loss: 0.6612962484359741\n",
      "Batch Loss: 0.6553605794906616\n",
      "Batch Loss: 0.6694092750549316\n",
      "Batch Loss: 0.667236864566803\n",
      "Batch Loss: 0.6753498315811157\n",
      "Batch Loss: 0.6650595664978027\n",
      "Batch Loss: 0.6769261360168457\n",
      "Batch Loss: 0.63974529504776\n",
      "Batch Loss: 0.6672416925430298\n",
      "Batch Loss: 0.6456809639930725\n",
      "Batch Loss: 0.6338192224502563\n",
      "Batch Loss: 0.6925427317619324\n",
      "Batch Loss: 0.6634783744812012\n",
      "Batch Loss: 0.6694092154502869\n",
      "Batch Loss: 0.6634880304336548\n",
      "Batch Loss: 0.6694236993789673\n",
      "Batch Loss: 0.6575377583503723\n",
      "Batch Loss: 0.6812854409217834\n",
      "Batch Loss: 0.6612733602523804\n",
      "Batch Loss: 0.6634782552719116\n",
      "Batch Loss: 0.6634734869003296\n",
      "Batch Loss: 0.6337997317314148\n",
      "Batch Loss: 0.6575376987457275\n",
      "Batch Loss: 0.645685613155365\n",
      "Batch Loss: 0.6925461292266846\n",
      "Batch Loss: 0.696892499923706\n",
      "Batch Loss: 0.6456807255744934\n",
      "Batch Loss: 0.6575424671173096\n",
      "Batch Loss: 0.6197570562362671\n",
      "Batch Loss: 0.6731640696525574\n",
      "Batch Loss: 0.6613104939460754\n",
      "Batch Loss: 0.6397401094436646\n",
      "Batch Loss: 0.6456854343414307\n",
      "Batch Loss: 0.6397353410720825\n",
      "Batch Loss: 0.6613008379936218\n",
      "Batch Loss: 0.6575472354888916\n",
      "Batch Loss: 0.6812805533409119\n",
      "Batch Loss: 0.6316378712654114\n",
      "Batch Loss: 0.6672364473342896\n",
      "Batch Loss: 0.645675778388977\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.676925778388977\n",
      "Batch Loss: 0.6338232755661011\n",
      "Batch Loss: 0.6634781360626221\n",
      "Batch Loss: 0.6516256332397461\n",
      "Batch Loss: 0.6456851959228516\n",
      "Batch Loss: 0.6316269040107727\n",
      "Batch Loss: 0.639739990234375\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6634827852249146\n",
      "Batch Loss: 0.655379056930542\n",
      "Batch Loss: 0.663487434387207\n",
      "Batch Loss: 0.663487434387207\n",
      "Batch Loss: 0.6553742289543152\n",
      "Batch Loss: 0.6219468116760254\n",
      "Batch Loss: 0.6338228583335876\n",
      "Batch Loss: 0.6694183945655823\n",
      "Batch Loss: 0.6516158580780029\n",
      "Batch Loss: 0.6494244337081909\n",
      "Batch Loss: 0.651606559753418\n",
      "Batch Loss: 0.6575422286987305\n",
      "Batch Loss: 0.675344705581665\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6553647518157959\n",
      "Batch Loss: 0.673162579536438\n",
      "Batch Loss: 0.6753492951393127\n",
      "Batch Loss: 0.6753446459770203\n",
      "Batch Loss: 0.6694135665893555\n",
      "Batch Loss: 0.6753492951393127\n",
      "Batch Loss: 0.6516157388687134\n",
      "Batch Loss: 0.6575421690940857\n",
      "Batch Loss: 0.679102897644043\n",
      "Batch Loss: 0.6612957119941711\n",
      "Batch Loss: 0.6672314405441284\n",
      "Batch Loss: 0.6634778380393982\n",
      "Batch Loss: 0.6791074275970459\n",
      "Batch Loss: 0.6456936597824097\n",
      "Batch Loss: 0.6575421690940857\n",
      "Batch Loss: 0.6709941625595093\n",
      "Batch Loss: 0.6516201496124268\n",
      "Batch Loss: 0.6694180965423584\n",
      "Batch Loss: 0.6634823679924011\n",
      "Batch Loss: 0.6575375199317932\n",
      "Batch Loss: 0.669408917427063\n",
      "Batch Loss: 0.6397440433502197\n",
      "Batch Loss: 0.6612910032272339\n",
      "Batch Loss: 0.6753445863723755\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6434851884841919\n",
      "Batch Loss: 0.6694134473800659\n",
      "Batch Loss: 0.681280255317688\n",
      "Batch Loss: 0.6672313213348389\n",
      "Batch Loss: 0.6516199111938477\n",
      "Batch Loss: 0.6634821891784668\n",
      "Batch Loss: 0.6575465202331543\n",
      "Batch Loss: 0.676912784576416\n",
      "Batch Loss: 0.6672312617301941\n",
      "Batch Loss: 0.6516198515892029\n",
      "Batch Loss: 0.6516016721725464\n",
      "Batch Loss: 0.6672189831733704\n",
      "Batch Loss: 0.6575509309768677\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6613045930862427\n",
      "Batch Loss: 0.6909695267677307\n",
      "Batch Loss: 0.6828517317771912\n",
      "Batch Loss: 0.6338080167770386\n",
      "Batch Loss: 0.6575554609298706\n",
      "Batch Loss: 0.681280255317688\n",
      "Batch Loss: 0.6731714010238647\n",
      "Batch Loss: 0.6575464010238647\n",
      "Batch Loss: 0.6494207978248596\n",
      "Batch Loss: 0.6612999439239502\n",
      "Batch Loss: 0.6575464010238647\n",
      "Batch Loss: 0.6634865403175354\n",
      "Batch Loss: 0.6494195461273193\n",
      "Batch Loss: 0.6456704139709473\n",
      "Batch Loss: 0.6575418710708618\n",
      "Batch Loss: 0.6731591820716858\n",
      "Batch Loss: 0.6516106128692627\n",
      "Batch Loss: 0.6278722286224365\n",
      "Batch Loss: 0.6887918710708618\n",
      "Batch Loss: 0.657541811466217\n",
      "Batch Loss: 0.6375703811645508\n",
      "Batch Loss: 0.645679235458374\n",
      "Batch Loss: 0.6456881761550903\n",
      "Batch Loss: 0.6791024804115295\n",
      "Batch Loss: 0.645679235458374\n",
      "Batch Loss: 0.6790860295295715\n",
      "Batch Loss: 0.6516060829162598\n",
      "Batch Loss: 0.657550573348999\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6575373411178589\n",
      "Batch Loss: 0.6160138249397278\n",
      "Batch Loss: 0.6516148447990417\n",
      "Batch Loss: 0.6494370698928833\n",
      "Batch Loss: 0.6219406127929688\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6790948510169983\n",
      "Batch Loss: 0.6672265529632568\n",
      "Batch Loss: 0.6694175004959106\n",
      "Batch Loss: 0.6456746459007263\n",
      "Batch Loss: 0.6709933280944824\n",
      "Batch Loss: 0.6456658840179443\n",
      "Batch Loss: 0.6456745862960815\n",
      "Batch Loss: 0.6397432684898376\n",
      "Batch Loss: 0.6397476196289062\n",
      "Batch Loss: 0.6672277450561523\n",
      "Batch Loss: 0.6694086790084839\n",
      "Batch Loss: 0.6694173812866211\n",
      "Batch Loss: 0.6494324207305908\n",
      "Batch Loss: 0.6731666326522827\n",
      "Batch Loss: 0.6516188979148865\n",
      "Batch Loss: 0.6397301554679871\n",
      "Batch Loss: 0.6575415730476379\n",
      "Batch Loss: 0.6694086790084839\n",
      "Batch Loss: 0.645687460899353\n",
      "Batch Loss: 0.6672308444976807\n",
      "Batch Loss: 0.6753443479537964\n",
      "Batch Loss: 0.7059966325759888\n",
      "Batch Loss: 0.6694215536117554\n",
      "Batch Loss: 0.6575501561164856\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6397429704666138\n",
      "Batch Loss: 0.6634772419929504\n",
      "Batch Loss: 0.6397558450698853\n",
      "Batch Loss: 0.6553593873977661\n",
      "Batch Loss: 0.7065943479537964\n",
      "Batch Loss: 0.6634814739227295\n",
      "Batch Loss: 0.639742910861969\n",
      "Batch Loss: 0.6575499773025513\n",
      "Batch Loss: 0.6516100168228149\n",
      "Batch Loss: 0.6575413942337036\n",
      "Batch Loss: 0.6516057252883911\n",
      "Batch Loss: 0.651614248752594\n",
      "Batch Loss: 0.6753443479537964\n",
      "Batch Loss: 0.6612919569015503\n",
      "Batch Loss: 0.6612919569015503\n",
      "Batch Loss: 0.6456869840621948\n",
      "Batch Loss: 0.6397342681884766\n",
      "Batch Loss: 0.6338070034980774\n",
      "Batch Loss: 0.6753442883491516\n",
      "Batch Loss: 0.6850378513336182\n",
      "Batch Loss: 0.6575413942337036\n",
      "Batch Loss: 0.6634728908538818\n",
      "Batch Loss: 0.6694211959838867\n",
      "Batch Loss: 0.616012454032898\n",
      "Batch Loss: 0.6575497388839722\n",
      "Batch Loss: 0.6516140699386597\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6850377321243286\n",
      "Batch Loss: 0.6516098380088806\n",
      "Batch Loss: 0.6553759574890137\n",
      "Batch Loss: 0.6672389507293701\n",
      "Batch Loss: 0.6828556060791016\n",
      "Batch Loss: 0.6516097784042358\n",
      "Batch Loss: 0.6731662750244141\n",
      "Batch Loss: 0.6850377321243286\n",
      "Batch Loss: 0.6553632616996765\n",
      "Batch Loss: 0.6516138911247253\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6925531029701233\n",
      "Batch Loss: 0.649423360824585\n",
      "Batch Loss: 0.655359148979187\n",
      "Batch Loss: 0.651605486869812\n",
      "Batch Loss: 0.6769198179244995\n",
      "Batch Loss: 0.651605486869812\n",
      "Batch Loss: 0.6731621026992798\n",
      "Batch Loss: 0.6575412154197693\n",
      "Batch Loss: 0.6516095995903015\n",
      "Batch Loss: 0.657545268535614\n",
      "Batch Loss: 0.649431586265564\n",
      "Batch Loss: 0.657545268535614\n",
      "Batch Loss: 0.6575493812561035\n",
      "Batch Loss: 0.6575411558151245\n",
      "Batch Loss: 0.6219391822814941\n",
      "Batch Loss: 0.6672192811965942\n",
      "Batch Loss: 0.6494039297103882\n",
      "Batch Loss: 0.6850334405899048\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.64566969871521\n",
      "Batch Loss: 0.6672345399856567\n",
      "Batch Loss: 0.6850374937057495\n",
      "Batch Loss: 0.6397380828857422\n",
      "Batch Loss: 0.6516135931015015\n",
      "Batch Loss: 0.6413065791130066\n",
      "Batch Loss: 0.6338064074516296\n",
      "Batch Loss: 0.6753441095352173\n",
      "Batch Loss: 0.6338064074516296\n",
      "Batch Loss: 0.6575410962104797\n",
      "Batch Loss: 0.6456695795059204\n",
      "Batch Loss: 0.6634807586669922\n",
      "Batch Loss: 0.6516175270080566\n",
      "Batch Loss: 0.6397379636764526\n",
      "Batch Loss: 0.6456776857376099\n",
      "Batch Loss: 0.6753441095352173\n",
      "Batch Loss: 0.6575450897216797\n",
      "Batch Loss: 0.6575450897216797\n",
      "Batch Loss: 0.6731700301170349\n",
      "Batch Loss: 0.66941237449646\n",
      "Batch Loss: 0.6397379636764526\n",
      "Batch Loss: 0.6650412082672119\n",
      "Batch Loss: 0.66940838098526\n",
      "Batch Loss: 0.6575409173965454\n",
      "Batch Loss: 0.6456695795059204\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456736326217651\n",
      "Batch Loss: 0.6338061094284058\n",
      "Batch Loss: 0.6694164276123047\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6316239833831787\n",
      "Batch Loss: 0.6278703808784485\n",
      "Batch Loss: 0.6575449705123901\n",
      "Batch Loss: 0.651617169380188\n",
      "Batch Loss: 0.6694083213806152\n",
      "Batch Loss: 0.6634766459465027\n",
      "Batch Loss: 0.6694123148918152\n",
      "Batch Loss: 0.6516091823577881\n",
      "Batch Loss: 0.6456694602966309\n",
      "Batch Loss: 0.6516051292419434\n",
      "Batch Loss: 0.6694122552871704\n",
      "Batch Loss: 0.645673394203186\n",
      "Batch Loss: 0.6694122552871704\n",
      "Batch Loss: 0.6397377252578735\n",
      "Batch Loss: 0.6553705930709839\n",
      "Batch Loss: 0.6456773281097412\n",
      "Batch Loss: 0.6516011953353882\n",
      "Batch Loss: 0.6747197508811951\n",
      "Batch Loss: 0.6612904667854309\n",
      "Batch Loss: 0.679097592830658\n",
      "Batch Loss: 0.6516090631484985\n",
      "Batch Loss: 0.6731657981872559\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6494268774986267\n",
      "Batch Loss: 0.6790947318077087\n",
      "Batch Loss: 0.6456772089004517\n",
      "Batch Loss: 0.6909689903259277\n",
      "Batch Loss: 0.6694121956825256\n",
      "Batch Loss: 0.6791054010391235\n",
      "Batch Loss: 0.6516050696372986\n",
      "Batch Loss: 0.651608943939209\n",
      "Batch Loss: 0.6456810235977173\n",
      "Batch Loss: 0.6456771492958069\n",
      "Batch Loss: 0.6456732153892517\n",
      "Batch Loss: 0.6731618642807007\n",
      "Batch Loss: 0.7006582617759705\n",
      "Batch Loss: 0.6575446128845215\n",
      "Batch Loss: 0.6672378182411194\n",
      "Batch Loss: 0.6634725332260132\n",
      "Batch Loss: 0.679105281829834\n",
      "Batch Loss: 0.6337978839874268\n",
      "Batch Loss: 0.6575523614883423\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6634725332260132\n",
      "Batch Loss: 0.6769231557846069\n",
      "Batch Loss: 0.6516088247299194\n",
      "Batch Loss: 0.6575484275817871\n",
      "Batch Loss: 0.6575367450714111\n",
      "Batch Loss: 0.6694120764732361\n",
      "Batch Loss: 0.6516165733337402\n",
      "Batch Loss: 0.6516126990318298\n",
      "Batch Loss: 0.6575406193733215\n",
      "Batch Loss: 0.6909727454185486\n",
      "Batch Loss: 0.6575406193733215\n",
      "Batch Loss: 0.6397411823272705\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6672375798225403\n",
      "Batch Loss: 0.6753477454185486\n",
      "Batch Loss: 0.6694081425666809\n",
      "Batch Loss: 0.6634801030158997\n",
      "Batch Loss: 0.6769153475761414\n",
      "Batch Loss: 0.679101288318634\n",
      "Batch Loss: 0.6516048908233643\n",
      "Batch Loss: 0.6575443744659424\n",
      "Batch Loss: 0.6575443744659424\n",
      "Batch Loss: 0.6731617450714111\n",
      "Batch Loss: 0.6435022354125977\n",
      "Batch Loss: 0.6338090896606445\n",
      "Batch Loss: 0.6553622484207153\n",
      "Batch Loss: 0.6753438711166382\n",
      "Batch Loss: 0.6160019636154175\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6694118976593018\n",
      "Batch Loss: 0.6634837985038757\n",
      "Batch Loss: 0.6456652879714966\n",
      "Batch Loss: 0.6456652879714966\n",
      "Batch Loss: 0.6731617450714111\n",
      "Batch Loss: 0.6812795400619507\n",
      "Batch Loss: 0.6634724140167236\n",
      "Batch Loss: 0.6575366854667664\n",
      "Batch Loss: 0.6613054275512695\n",
      "Batch Loss: 0.6575442552566528\n",
      "Batch Loss: 0.6731552481651306\n",
      "Batch Loss: 0.6375586986541748\n",
      "Batch Loss: 0.679087221622467\n",
      "Batch Loss: 0.649437665939331\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6694118976593018\n",
      "Batch Loss: 0.6553620100021362\n",
      "Batch Loss: 0.6634836196899414\n",
      "Batch Loss: 0.6672334671020508\n",
      "Batch Loss: 0.6791011095046997\n",
      "Batch Loss: 0.6516121625900269\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6516121625900269\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.669411838054657\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6694155335426331\n",
      "Batch Loss: 0.6575441360473633\n",
      "Batch Loss: 0.6397370100021362\n",
      "Batch Loss: 0.6516121029853821\n",
      "Batch Loss: 0.6694117784500122\n",
      "Batch Loss: 0.6672333478927612\n",
      "Batch Loss: 0.6456800699234009\n",
      "Batch Loss: 0.6456800699234009\n",
      "Batch Loss: 0.6456726789474487\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6575477123260498\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6516156792640686\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6338085532188416\n",
      "Batch Loss: 0.6694080233573914\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6731653213500977\n",
      "Batch Loss: 0.6634759902954102\n",
      "Batch Loss: 0.6612975597381592\n",
      "Batch Loss: 0.6731725931167603\n",
      "Batch Loss: 0.6613048315048218\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6634759902954102\n",
      "Batch Loss: 0.6553727388381958\n",
      "Batch Loss: 0.6709631681442261\n",
      "Batch Loss: 0.6634759902954102\n",
      "Batch Loss: 0.6850329637527466\n",
      "Batch Loss: 0.6516045331954956\n",
      "Batch Loss: 0.6338083148002625\n",
      "Batch Loss: 0.6694079637527466\n",
      "Batch Loss: 0.639747679233551\n",
      "Batch Loss: 0.6828545331954956\n",
      "Batch Loss: 0.6850230693817139\n",
      "Batch Loss: 0.6575437784194946\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.670983076095581\n",
      "Batch Loss: 0.6397366523742676\n",
      "Batch Loss: 0.6397439241409302\n",
      "Batch Loss: 0.6672258377075195\n",
      "Batch Loss: 0.673161506652832\n",
      "Batch Loss: 0.6575402021408081\n",
      "Batch Loss: 0.6650509238243103\n",
      "Batch Loss: 0.673162579536438\n",
      "Batch Loss: 0.639751136302948\n",
      "Batch Loss: 0.6694152355194092\n",
      "Batch Loss: 0.6516044735908508\n",
      "Batch Loss: 0.6694115400314331\n",
      "Batch Loss: 0.6516116857528687\n",
      "Batch Loss: 0.6791008710861206\n",
      "Batch Loss: 0.6338080763816833\n",
      "Batch Loss: 0.657536506652832\n",
      "Batch Loss: 0.6575437188148499\n",
      "Batch Loss: 0.6375616192817688\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.682854413986206\n",
      "Batch Loss: 0.6790971755981445\n",
      "Batch Loss: 0.6694151163101196\n",
      "Batch Loss: 0.639729380607605\n",
      "Batch Loss: 0.663475751876831\n",
      "Batch Loss: 0.6731721758842468\n",
      "Batch Loss: 0.6634793877601624\n",
      "Batch Loss: 0.6741567254066467\n",
      "Epoch 6/20, Loss: 0.6598393323071581, Time: 492.63s\n",
      "Batch Loss: 0.6516043543815613\n",
      "Batch Loss: 0.657536506652832\n",
      "Batch Loss: 0.6494221687316895\n",
      "Batch Loss: 0.639736533164978\n",
      "Batch Loss: 0.6456722021102905\n",
      "Batch Loss: 0.639739990234375\n",
      "Batch Loss: 0.6456756591796875\n",
      "Batch Loss: 0.6516113877296448\n",
      "Batch Loss: 0.6709935069084167\n",
      "Batch Loss: 0.6456685662269592\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.6575400233268738\n",
      "Batch Loss: 0.627875566482544\n",
      "Batch Loss: 0.6672433614730835\n",
      "Batch Loss: 0.6575364470481873\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.649429202079773\n",
      "Batch Loss: 0.6338006258010864\n",
      "Batch Loss: 0.6375612020492554\n",
      "Batch Loss: 0.6575399041175842\n",
      "Batch Loss: 0.6456685066223145\n",
      "Batch Loss: 0.6516112089157104\n",
      "Batch Loss: 0.6634721159934998\n",
      "Batch Loss: 0.6516112089157104\n",
      "Batch Loss: 0.6516112089157104\n",
      "Batch Loss: 0.6516146659851074\n",
      "Batch Loss: 0.6553612947463989\n",
      "Batch Loss: 0.6456754803657532\n",
      "Batch Loss: 0.6278682947158813\n",
      "Batch Loss: 0.6791006326675415\n",
      "Batch Loss: 0.6278682947158813\n",
      "Batch Loss: 0.6650539636611938\n",
      "Batch Loss: 0.6672232151031494\n",
      "Batch Loss: 0.667229175567627\n",
      "Batch Loss: 0.6456649303436279\n",
      "Batch Loss: 0.669407844543457\n",
      "Batch Loss: 0.6747338175773621\n",
      "Batch Loss: 0.6575433015823364\n",
      "Batch Loss: 0.6516144871711731\n",
      "Batch Loss: 0.6612968444824219\n",
      "Batch Loss: 0.6672197580337524\n",
      "Batch Loss: 0.6397464871406555\n",
      "Batch Loss: 0.6575398445129395\n",
      "Batch Loss: 0.6553645730018616\n",
      "Batch Loss: 0.6575500965118408\n",
      "Batch Loss: 0.6397532820701599\n",
      "Batch Loss: 0.6575398445129395\n",
      "Batch Loss: 0.6516075134277344\n",
      "Batch Loss: 0.663472056388855\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6634789109230042\n",
      "Batch Loss: 0.6575466394424438\n",
      "Batch Loss: 0.6278715133666992\n",
      "Batch Loss: 0.6494287252426147\n",
      "Batch Loss: 0.696904182434082\n",
      "Batch Loss: 0.6731613278388977\n",
      "Batch Loss: 0.6160101890563965\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575431227684021\n",
      "Batch Loss: 0.651614248752594\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575431227684021\n",
      "Batch Loss: 0.6456682682037354\n",
      "Batch Loss: 0.6634753942489624\n",
      "Batch Loss: 0.6575464606285095\n",
      "Batch Loss: 0.6672289371490479\n",
      "Batch Loss: 0.6456682682037354\n",
      "Batch Loss: 0.6575396656990051\n",
      "Batch Loss: 0.6338069438934326\n",
      "Batch Loss: 0.6709734201431274\n",
      "Batch Loss: 0.6769158244132996\n",
      "Batch Loss: 0.6634753346443176\n",
      "Batch Loss: 0.6850360631942749\n",
      "Batch Loss: 0.6672289371490479\n",
      "Batch Loss: 0.6456682085990906\n",
      "Batch Loss: 0.6709824800491333\n",
      "Batch Loss: 0.6612998843193054\n",
      "Batch Loss: 0.6397324800491333\n",
      "Batch Loss: 0.6456748843193054\n",
      "Batch Loss: 0.6612908244132996\n",
      "Batch Loss: 0.6612932085990906\n",
      "Batch Loss: 0.6338101625442505\n",
      "Batch Loss: 0.6672322750091553\n",
      "Batch Loss: 0.6575429439544678\n",
      "Batch Loss: 0.6753467321395874\n",
      "Batch Loss: 0.6634752750396729\n",
      "Batch Loss: 0.6278777122497559\n",
      "Batch Loss: 0.6516105532646179\n",
      "Batch Loss: 0.6634752750396729\n",
      "Batch Loss: 0.6753467321395874\n",
      "Batch Loss: 0.6694077253341675\n",
      "Batch Loss: 0.6887772083282471\n",
      "Batch Loss: 0.6769148111343384\n",
      "Batch Loss: 0.6456747651100159\n",
      "Batch Loss: 0.6850302815437317\n",
      "Batch Loss: 0.6397390365600586\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6731644868850708\n",
      "Batch Loss: 0.6613030433654785\n",
      "Batch Loss: 0.6456681489944458\n",
      "Batch Loss: 0.6790969371795654\n",
      "Batch Loss: 0.6397356986999512\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6612841486930847\n",
      "Batch Loss: 0.6612963676452637\n",
      "Batch Loss: 0.6850326657295227\n",
      "Batch Loss: 0.6828472018241882\n",
      "Batch Loss: 0.6731555461883545\n",
      "Batch Loss: 0.6575461030006409\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6634784936904907\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6531784534454346\n",
      "Batch Loss: 0.6516004800796509\n",
      "Batch Loss: 0.6634751558303833\n",
      "Batch Loss: 0.639738917350769\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6909626722335815\n",
      "Batch Loss: 0.6753433346748352\n",
      "Batch Loss: 0.6456778645515442\n",
      "Batch Loss: 0.6516070365905762\n",
      "Batch Loss: 0.6612963080406189\n",
      "Batch Loss: 0.6769091486930847\n",
      "Batch Loss: 0.6672286987304688\n",
      "Batch Loss: 0.6694076061248779\n",
      "Batch Loss: 0.6694076061248779\n",
      "Batch Loss: 0.6634817123413086\n",
      "Batch Loss: 0.6694076061248779\n",
      "Batch Loss: 0.6672254800796509\n",
      "Batch Loss: 0.6672287583351135\n",
      "Batch Loss: 0.6397420763969421\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6634783744812012\n",
      "Batch Loss: 0.6494280695915222\n",
      "Batch Loss: 0.6516069173812866\n",
      "Batch Loss: 0.6828504800796509\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6694140434265137\n",
      "Batch Loss: 0.663481593132019\n",
      "Batch Loss: 0.6731556057929993\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6634718775749207\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6456679701805115\n",
      "Batch Loss: 0.6456711888313293\n",
      "Batch Loss: 0.6456711292266846\n",
      "Batch Loss: 0.657545804977417\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6634782552719116\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575393676757812\n",
      "Batch Loss: 0.6694139838218689\n",
      "Batch Loss: 0.6575393676757812\n",
      "Batch Loss: 0.6516132354736328\n",
      "Batch Loss: 0.6672382354736328\n",
      "Batch Loss: 0.6634718179702759\n",
      "Batch Loss: 0.6753496527671814\n",
      "Batch Loss: 0.6612938046455383\n",
      "Batch Loss: 0.6634750366210938\n",
      "Batch Loss: 0.6694075465202332\n",
      "Batch Loss: 0.6575489044189453\n",
      "Batch Loss: 0.6634782552719116\n",
      "Batch Loss: 0.6694074869155884\n",
      "Batch Loss: 0.6753432154655457\n",
      "Batch Loss: 0.6694074869155884\n",
      "Batch Loss: 0.6553667187690735\n",
      "Batch Loss: 0.6397353410720825\n",
      "Batch Loss: 0.663474977016449\n",
      "Batch Loss: 0.6516067385673523\n",
      "Batch Loss: 0.663474977016449\n",
      "Batch Loss: 0.6160019636154175\n",
      "Batch Loss: 0.6494245529174805\n",
      "Batch Loss: 0.661296010017395\n",
      "Batch Loss: 0.6731674671173096\n",
      "Batch Loss: 0.6338058710098267\n",
      "Batch Loss: 0.6278669834136963\n",
      "Batch Loss: 0.6694106459617615\n",
      "Batch Loss: 0.6516097784042358\n",
      "Batch Loss: 0.6694137454032898\n",
      "Batch Loss: 0.6375594139099121\n",
      "Batch Loss: 0.6753431558609009\n",
      "Batch Loss: 0.6219375133514404\n",
      "Batch Loss: 0.6575391888618469\n",
      "Batch Loss: 0.6456708908081055\n",
      "Batch Loss: 0.6694137454032898\n",
      "Batch Loss: 0.639735221862793\n",
      "Batch Loss: 0.6634716987609863\n",
      "Batch Loss: 0.6591168642044067\n",
      "Batch Loss: 0.6694074869155884\n",
      "Batch Loss: 0.6516034603118896\n",
      "Batch Loss: 0.6634749174118042\n",
      "Batch Loss: 0.6769208908081055\n",
      "Batch Loss: 0.6791061162948608\n",
      "Batch Loss: 0.6397382020950317\n",
      "Batch Loss: 0.6575360298156738\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6553601026535034\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6850324273109436\n",
      "Batch Loss: 0.6753431558609009\n",
      "Batch Loss: 0.6753462553024292\n",
      "Batch Loss: 0.6456707715988159\n",
      "Batch Loss: 0.663477897644043\n",
      "Batch Loss: 0.633805513381958\n",
      "Batch Loss: 0.6456738710403442\n",
      "Batch Loss: 0.6553570032119751\n",
      "Batch Loss: 0.6850324273109436\n",
      "Batch Loss: 0.6968923807144165\n",
      "Batch Loss: 0.686607837677002\n",
      "Batch Loss: 0.6516095399856567\n",
      "Batch Loss: 0.663477897644043\n",
      "Batch Loss: 0.6575452089309692\n",
      "Batch Loss: 0.615998387336731\n",
      "Batch Loss: 0.6887807250022888\n",
      "Batch Loss: 0.6634808778762817\n",
      "Batch Loss: 0.6516156196594238\n",
      "Batch Loss: 0.6694104671478271\n",
      "Batch Loss: 0.6769206523895264\n",
      "Batch Loss: 0.6634777784347534\n",
      "Batch Loss: 0.6634716987609863\n",
      "Batch Loss: 0.6731700897216797\n",
      "Batch Loss: 0.6672283411026001\n",
      "Batch Loss: 0.6612956523895264\n",
      "Batch Loss: 0.6753430962562561\n",
      "Batch Loss: 0.6397440433502197\n",
      "Batch Loss: 0.6456706523895264\n",
      "Batch Loss: 0.6694134473800659\n",
      "Batch Loss: 0.6456706523895264\n",
      "Batch Loss: 0.6575419902801514\n",
      "Batch Loss: 0.6516093611717224\n",
      "Batch Loss: 0.6672283411026001\n",
      "Batch Loss: 0.6516093015670776\n",
      "Batch Loss: 0.6516032814979553\n",
      "Batch Loss: 0.6791056990623474\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6634746789932251\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634776592254639\n",
      "Batch Loss: 0.6694103479385376\n",
      "Batch Loss: 0.6612955331802368\n",
      "Batch Loss: 0.6575449705123901\n",
      "Batch Loss: 0.6850353479385376\n",
      "Batch Loss: 0.6553537845611572\n",
      "Batch Loss: 0.6516062021255493\n",
      "Batch Loss: 0.6694103479385376\n",
      "Batch Loss: 0.657538890838623\n",
      "Batch Loss: 0.6397438049316406\n",
      "Batch Loss: 0.6516062021255493\n",
      "Batch Loss: 0.6553688049316406\n",
      "Batch Loss: 0.6553597450256348\n",
      "Batch Loss: 0.645670473575592\n",
      "Batch Loss: 0.639731764793396\n",
      "Batch Loss: 0.6553486585617065\n",
      "Batch Loss: 0.6694103479385376\n",
      "Batch Loss: 0.6612924933433533\n",
      "Batch Loss: 0.6634775400161743\n",
      "Batch Loss: 0.6516091227531433\n",
      "Batch Loss: 0.6694073677062988\n",
      "Batch Loss: 0.6397406458854675\n",
      "Batch Loss: 0.6575418710708618\n",
      "Batch Loss: 0.6397287845611572\n",
      "Batch Loss: 0.645673394203186\n",
      "Batch Loss: 0.657541811466217\n",
      "Batch Loss: 0.6694102883338928\n",
      "Batch Loss: 0.6634745597839355\n",
      "Batch Loss: 0.6516060829162598\n",
      "Batch Loss: 0.65535968542099\n",
      "Batch Loss: 0.651600182056427\n",
      "Batch Loss: 0.6456733345985413\n",
      "Batch Loss: 0.6753430366516113\n",
      "Batch Loss: 0.6812787055969238\n",
      "Batch Loss: 0.6731638312339783\n",
      "Batch Loss: 0.651608943939209\n",
      "Batch Loss: 0.6456674337387085\n",
      "Batch Loss: 0.6575417518615723\n",
      "Batch Loss: 0.6575446724891663\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.6850272417068481\n",
      "Batch Loss: 0.6278631687164307\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.679099440574646\n",
      "Batch Loss: 0.651608943939209\n",
      "Batch Loss: 0.669410228729248\n",
      "Batch Loss: 0.6753429770469666\n",
      "Batch Loss: 0.6337959170341492\n",
      "Batch Loss: 0.6909679174423218\n",
      "Batch Loss: 0.6672251224517822\n",
      "Batch Loss: 0.6769202947616577\n",
      "Batch Loss: 0.6575387716293335\n",
      "Batch Loss: 0.663474440574646\n",
      "Batch Loss: 0.6753458976745605\n",
      "Batch Loss: 0.663474440574646\n",
      "Batch Loss: 0.6456789970397949\n",
      "Batch Loss: 0.6494296193122864\n",
      "Batch Loss: 0.6969037055969238\n",
      "Batch Loss: 0.6434801816940308\n",
      "Batch Loss: 0.7044058442115784\n",
      "Batch Loss: 0.6575416326522827\n",
      "Batch Loss: 0.6731666326522827\n",
      "Batch Loss: 0.6219360828399658\n",
      "Batch Loss: 0.6516058444976807\n",
      "Batch Loss: 0.6316087245941162\n",
      "Batch Loss: 0.6338074207305908\n",
      "Batch Loss: 0.6731607913970947\n",
      "Batch Loss: 0.6672279834747314\n",
      "Batch Loss: 0.6575387120246887\n",
      "Batch Loss: 0.6694129705429077\n",
      "Batch Loss: 0.6516116261482239\n",
      "Batch Loss: 0.6612844467163086\n",
      "Batch Loss: 0.6634743809700012\n",
      "Batch Loss: 0.6694101095199585\n",
      "Batch Loss: 0.6650487184524536\n",
      "Batch Loss: 0.6769171953201294\n",
      "Batch Loss: 0.6612844467163086\n",
      "Batch Loss: 0.6575415134429932\n",
      "Batch Loss: 0.6575443744659424\n",
      "Batch Loss: 0.6553536653518677\n",
      "Batch Loss: 0.6456700563430786\n",
      "Batch Loss: 0.6790915727615356\n",
      "Batch Loss: 0.6575443744659424\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.657538652420044\n",
      "Batch Loss: 0.657538652420044\n",
      "Batch Loss: 0.6612921953201294\n",
      "Batch Loss: 0.6672201156616211\n",
      "Batch Loss: 0.6694128513336182\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.6516057252883911\n",
      "Batch Loss: 0.659115731716156\n",
      "Batch Loss: 0.6575442552566528\n",
      "Batch Loss: 0.6650571227073669\n",
      "Batch Loss: 0.6516057252883911\n",
      "Batch Loss: 0.6456756591796875\n",
      "Batch Loss: 0.6494235992431641\n",
      "Batch Loss: 0.6516057252883911\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.6753429174423218\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456756591796875\n",
      "Batch Loss: 0.6456671953201294\n",
      "Batch Loss: 0.675342857837677\n",
      "Batch Loss: 0.6575385332107544\n",
      "Batch Loss: 0.6337985396385193\n",
      "Batch Loss: 0.6634743213653564\n",
      "Batch Loss: 0.6575385332107544\n",
      "Batch Loss: 0.6456671357154846\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6516028642654419\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.643487811088562\n",
      "Batch Loss: 0.6575469970703125\n",
      "Batch Loss: 0.6434962153434753\n",
      "Batch Loss: 0.6634798049926758\n",
      "Batch Loss: 0.661300539970398\n",
      "Batch Loss: 0.6634770035743713\n",
      "Batch Loss: 0.6650512218475342\n",
      "Batch Loss: 0.6634770035743713\n",
      "Batch Loss: 0.6650484800338745\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6634770035743713\n",
      "Batch Loss: 0.6612948179244995\n",
      "Batch Loss: 0.6516000032424927\n",
      "Batch Loss: 0.6731662750244141\n",
      "Batch Loss: 0.6575412154197693\n",
      "Batch Loss: 0.6672277450561523\n",
      "Batch Loss: 0.6553618907928467\n",
      "Batch Loss: 0.663479745388031\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.6397396326065063\n",
      "Batch Loss: 0.6672277450561523\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6397340893745422\n",
      "Batch Loss: 0.6575411558151245\n",
      "Batch Loss: 0.6753427982330322\n",
      "Batch Loss: 0.6575384736061096\n",
      "Batch Loss: 0.6375546455383301\n",
      "Batch Loss: 0.6672332286834717\n",
      "Batch Loss: 0.6456697583198547\n",
      "Batch Loss: 0.6338011026382446\n",
      "Batch Loss: 0.6575411558151245\n",
      "Batch Loss: 0.6753427982330322\n",
      "Batch Loss: 0.6516081690788269\n",
      "Batch Loss: 0.6494233012199402\n",
      "Batch Loss: 0.682842493057251\n",
      "Batch Loss: 0.6769169569015503\n",
      "Batch Loss: 0.6812784671783447\n",
      "Batch Loss: 0.6731661558151245\n",
      "Batch Loss: 0.6887856721878052\n",
      "Batch Loss: 0.6850273609161377\n",
      "Batch Loss: 0.6456724405288696\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6516108512878418\n",
      "Batch Loss: 0.6634740829467773\n",
      "Batch Loss: 0.6672303676605225\n",
      "Batch Loss: 0.663476824760437\n",
      "Batch Loss: 0.6575437784194946\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6850320100784302\n",
      "Batch Loss: 0.6456696391105652\n",
      "Batch Loss: 0.6731606125831604\n",
      "Batch Loss: 0.6753427386283875\n",
      "Batch Loss: 0.669407069683075\n",
      "Batch Loss: 0.6397366523742676\n",
      "Batch Loss: 0.6516026258468628\n",
      "Batch Loss: 0.6494313478469849\n",
      "Batch Loss: 0.657541036605835\n",
      "Batch Loss: 0.6672248840332031\n",
      "Batch Loss: 0.6575356721878052\n",
      "Batch Loss: 0.6790990233421326\n",
      "Batch Loss: 0.657541036605835\n",
      "Batch Loss: 0.6731632947921753\n",
      "Batch Loss: 0.6553642749786377\n",
      "Batch Loss: 0.651602566242218\n",
      "Batch Loss: 0.6516052484512329\n",
      "Batch Loss: 0.6375417709350586\n",
      "Batch Loss: 0.651602566242218\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6397445797920227\n",
      "Batch Loss: 0.6575436592102051\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6769149303436279\n",
      "Batch Loss: 0.6850320100784302\n",
      "Batch Loss: 0.6753454208374023\n",
      "Batch Loss: 0.6456748843193054\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6731606125831604\n",
      "Batch Loss: 0.6338061094284058\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6694096922874451\n",
      "Batch Loss: 0.6909676790237427\n",
      "Batch Loss: 0.6575382947921753\n",
      "Batch Loss: 0.6575409173965454\n",
      "Batch Loss: 0.6397390365600586\n",
      "Batch Loss: 0.663479208946228\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.6731560230255127\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6634739637374878\n",
      "Batch Loss: 0.6947239637374878\n",
      "Batch Loss: 0.6516077518463135\n",
      "Batch Loss: 0.6516077518463135\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6397363543510437\n",
      "Batch Loss: 0.6575382351875305\n",
      "Batch Loss: 0.6850320100784302\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.657543420791626\n",
      "Batch Loss: 0.6753426790237427\n",
      "Batch Loss: 0.6887855529785156\n",
      "Batch Loss: 0.6434873342514038\n",
      "Batch Loss: 0.6672255992889404\n",
      "Batch Loss: 0.679098904132843\n",
      "Batch Loss: 0.6753426790237427\n",
      "Batch Loss: 0.6672275066375732\n",
      "Batch Loss: 0.6575407981872559\n",
      "Batch Loss: 0.6337953209877014\n",
      "Batch Loss: 0.639738917350769\n",
      "Batch Loss: 0.6828524470329285\n",
      "Batch Loss: 0.6731560230255127\n",
      "Batch Loss: 0.6731631755828857\n",
      "Batch Loss: 0.6850274801254272\n",
      "Batch Loss: 0.6634790897369385\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6672274470329285\n",
      "Batch Loss: 0.6812809705734253\n",
      "Batch Loss: 0.6278699636459351\n",
      "Batch Loss: 0.6790891885757446\n",
      "Batch Loss: 0.6634738445281982\n",
      "Batch Loss: 0.6634764671325684\n",
      "Batch Loss: 0.6278673410415649\n",
      "Batch Loss: 0.6515998244285583\n",
      "Batch Loss: 0.6516023874282837\n",
      "Batch Loss: 0.6634764671325684\n",
      "Batch Loss: 0.6397361755371094\n",
      "Batch Loss: 0.6694095134735107\n",
      "Batch Loss: 0.6672325730323792\n",
      "Batch Loss: 0.6753426790237427\n",
      "Batch Loss: 0.6634789705276489\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6731605529785156\n",
      "Batch Loss: 0.6694120764732361\n",
      "Batch Loss: 0.6516023874282837\n",
      "Batch Loss: 0.6575380563735962\n",
      "Batch Loss: 0.6516075134277344\n",
      "Batch Loss: 0.6278698444366455\n",
      "Batch Loss: 0.6872140169143677\n",
      "Batch Loss: 0.657545804977417\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.651604950428009\n",
      "Batch Loss: 0.6612942218780518\n",
      "Batch Loss: 0.6612915992736816\n",
      "Batch Loss: 0.6338080167770386\n",
      "Batch Loss: 0.6575406193733215\n",
      "Batch Loss: 0.6278620362281799\n",
      "Batch Loss: 0.679101288318634\n",
      "Batch Loss: 0.6456717252731323\n",
      "Batch Loss: 0.6553533673286438\n",
      "Batch Loss: 0.6968938112258911\n",
      "Batch Loss: 0.6672350168228149\n",
      "Batch Loss: 0.6456665992736816\n",
      "Batch Loss: 0.6650553941726685\n",
      "Batch Loss: 0.6434844732284546\n",
      "Batch Loss: 0.6397461891174316\n",
      "Batch Loss: 0.6575379967689514\n",
      "Batch Loss: 0.6790987253189087\n",
      "Batch Loss: 0.6456665992736816\n",
      "Batch Loss: 0.6694119572639465\n",
      "Batch Loss: 0.655353307723999\n",
      "Batch Loss: 0.6575354337692261\n",
      "Batch Loss: 0.6672272682189941\n",
      "Batch Loss: 0.6397308707237244\n",
      "Batch Loss: 0.6790987253189087\n",
      "Batch Loss: 0.6338027119636536\n",
      "Batch Loss: 0.6887760162353516\n",
      "Batch Loss: 0.6516022682189941\n",
      "Batch Loss: 0.6634761691093445\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515997052192688\n",
      "Batch Loss: 0.6731654405593872\n",
      "Batch Loss: 0.6731629371643066\n",
      "Batch Loss: 0.6790868043899536\n",
      "Batch Loss: 0.6553583145141602\n",
      "Batch Loss: 0.645671546459198\n",
      "Batch Loss: 0.6634762287139893\n",
      "Batch Loss: 0.6634711623191833\n",
      "Batch Loss: 0.6575430035591125\n",
      "Batch Loss: 0.6397383213043213\n",
      "Batch Loss: 0.6553583145141602\n",
      "Batch Loss: 0.6694068312644958\n",
      "Batch Loss: 0.6256822347640991\n",
      "Batch Loss: 0.6575404405593872\n",
      "Batch Loss: 0.6397358179092407\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6397407650947571\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6375561356544495\n",
      "Batch Loss: 0.645673930644989\n",
      "Batch Loss: 0.6753425598144531\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6338074803352356\n",
      "Batch Loss: 0.6575379371643066\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6553656458854675\n",
      "Batch Loss: 0.6731561422348022\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6337975263595581\n",
      "Batch Loss: 0.6612914800643921\n",
      "Batch Loss: 0.6397331953048706\n",
      "Batch Loss: 0.6694117784500122\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6634759902954102\n",
      "Batch Loss: 0.6731635332107544\n",
      "Batch Loss: 0.6790894269943237\n",
      "Batch Loss: 0.6456688642501831\n",
      "Batch Loss: 0.6575378179550171\n",
      "Batch Loss: 0.6494225263595581\n",
      "Batch Loss: 0.6575378179550171\n",
      "Batch Loss: 0.6456737518310547\n",
      "Batch Loss: 0.6575378179550171\n",
      "Batch Loss: 0.6575452089309692\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6397331357002258\n",
      "Batch Loss: 0.6694092750549316\n",
      "Batch Loss: 0.6612962484359741\n",
      "Batch Loss: 0.6612962484359741\n",
      "Batch Loss: 0.6516045331954956\n",
      "Batch Loss: 0.6634759306907654\n",
      "Batch Loss: 0.6575353741645813\n",
      "Batch Loss: 0.6634711027145386\n",
      "Batch Loss: 0.6575426459312439\n",
      "Batch Loss: 0.6397404074668884\n",
      "Batch Loss: 0.6516020894050598\n",
      "Batch Loss: 0.6456687450408936\n",
      "Batch Loss: 0.6790984869003296\n",
      "Batch Loss: 0.6494247913360596\n",
      "Batch Loss: 0.6494199633598328\n",
      "Batch Loss: 0.6614927053451538\n",
      "Epoch 7/20, Loss: 0.6600037661632173, Time: 492.13s\n",
      "Batch Loss: 0.6575377583503723\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6516068577766418\n",
      "Batch Loss: 0.6634734869003296\n",
      "Batch Loss: 0.6456711292266846\n",
      "Batch Loss: 0.6812781691551208\n",
      "Batch Loss: 0.6612937450408936\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575401425361633\n",
      "Batch Loss: 0.6397305727005005\n",
      "Batch Loss: 0.592259407043457\n",
      "Batch Loss: 0.651604413986206\n",
      "Batch Loss: 0.6456711292266846\n",
      "Batch Loss: 0.6828472018241882\n",
      "Batch Loss: 0.6634711027145386\n",
      "Batch Loss: 0.6456687450408936\n",
      "Batch Loss: 0.6494133472442627\n",
      "Batch Loss: 0.6731610298156738\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753448247909546\n",
      "Batch Loss: 0.6753424406051636\n",
      "Batch Loss: 0.6575376987457275\n",
      "Batch Loss: 0.6812781095504761\n",
      "Batch Loss: 0.633797287940979\n",
      "Batch Loss: 0.6634781360626221\n",
      "Batch Loss: 0.66347336769104\n",
      "Batch Loss: 0.6575400829315186\n",
      "Batch Loss: 0.6397353410720825\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6672292947769165\n",
      "Batch Loss: 0.6553555727005005\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6575400233268738\n",
      "Batch Loss: 0.6575424671173096\n",
      "Batch Loss: 0.6434935927391052\n",
      "Batch Loss: 0.66347336769104\n",
      "Batch Loss: 0.6353805065155029\n",
      "Batch Loss: 0.6456709504127502\n",
      "Batch Loss: 0.6397328972816467\n",
      "Batch Loss: 0.6672269105911255\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6516090631484985\n",
      "Batch Loss: 0.655362606048584\n",
      "Batch Loss: 0.65754234790802\n",
      "Batch Loss: 0.673164963722229\n",
      "Batch Loss: 0.6219351291656494\n",
      "Batch Loss: 0.6456708908081055\n",
      "Batch Loss: 0.670985221862793\n",
      "Batch Loss: 0.6634756326675415\n",
      "Batch Loss: 0.6672292351722717\n",
      "Batch Loss: 0.6753423810005188\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6812781095504761\n",
      "Batch Loss: 0.6850316524505615\n",
      "Batch Loss: 0.6612935066223145\n",
      "Batch Loss: 0.651606559753418\n",
      "Batch Loss: 0.6672182083129883\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694066524505615\n",
      "Batch Loss: 0.6397420167922974\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6694089770317078\n",
      "Batch Loss: 0.6397373676300049\n",
      "Batch Loss: 0.6397373676300049\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6634756326675415\n",
      "Batch Loss: 0.6456707715988159\n",
      "Batch Loss: 0.663477897644043\n",
      "Batch Loss: 0.6278682351112366\n",
      "Batch Loss: 0.6812780499458313\n",
      "Batch Loss: 0.6575398445129395\n",
      "Batch Loss: 0.675342321395874\n",
      "Batch Loss: 0.6337946653366089\n",
      "Batch Loss: 0.6397418975830078\n",
      "Batch Loss: 0.6731648445129395\n",
      "Batch Loss: 0.6397327184677124\n",
      "Batch Loss: 0.6672291159629822\n",
      "Batch Loss: 0.6672267913818359\n",
      "Batch Loss: 0.6397349834442139\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6337969303131104\n",
      "Batch Loss: 0.6694066524505615\n",
      "Batch Loss: 0.6672290563583374\n",
      "Batch Loss: 0.6575421094894409\n",
      "Batch Loss: 0.6278657913208008\n",
      "Batch Loss: 0.6516017913818359\n",
      "Batch Loss: 0.6575420498847961\n",
      "Batch Loss: 0.6790958642959595\n",
      "Batch Loss: 0.675346851348877\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6434884071350098\n",
      "Batch Loss: 0.6516040563583374\n",
      "Batch Loss: 0.6516017913818359\n",
      "Batch Loss: 0.6753445863723755\n",
      "Batch Loss: 0.6672289967536926\n",
      "Batch Loss: 0.6278656721115112\n",
      "Batch Loss: 0.6575374603271484\n",
      "Batch Loss: 0.6731539964675903\n",
      "Batch Loss: 0.6650362014770508\n",
      "Batch Loss: 0.6553598642349243\n",
      "Batch Loss: 0.6612955331802368\n",
      "Batch Loss: 0.6909695863723755\n",
      "Batch Loss: 0.6694066524505615\n",
      "Batch Loss: 0.6456660032272339\n",
      "Batch Loss: 0.6634753942489624\n",
      "Batch Loss: 0.670987069606781\n",
      "Batch Loss: 0.6219276189804077\n",
      "Batch Loss: 0.6812779903411865\n",
      "Batch Loss: 0.6612910032272339\n",
      "Batch Loss: 0.6316152811050415\n",
      "Batch Loss: 0.6338013410568237\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6337945461273193\n",
      "Batch Loss: 0.6397370100021362\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694087982177734\n",
      "Batch Loss: 0.6338034868240356\n",
      "Batch Loss: 0.6672311425209045\n",
      "Batch Loss: 0.6397392153739929\n",
      "Batch Loss: 0.6753422617912292\n",
      "Batch Loss: 0.6909672617912292\n",
      "Batch Loss: 0.6925410032272339\n",
      "Batch Loss: 0.6434866189956665\n",
      "Batch Loss: 0.6575418710708618\n",
      "Batch Loss: 0.6968947649002075\n",
      "Batch Loss: 0.6984744071960449\n",
      "Batch Loss: 0.6634731292724609\n",
      "Batch Loss: 0.6612909436225891\n",
      "Batch Loss: 0.685023307800293\n",
      "Batch Loss: 0.6672288775444031\n",
      "Batch Loss: 0.675342321395874\n",
      "Batch Loss: 0.6634730696678162\n",
      "Batch Loss: 0.6434860229492188\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.6337922811508179\n",
      "Batch Loss: 0.6672288775444031\n",
      "Batch Loss: 0.6753422617912292\n",
      "Batch Loss: 0.6553574204444885\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6516060829162598\n",
      "Batch Loss: 0.6456703543663025\n",
      "Batch Loss: 0.685031533241272\n",
      "Batch Loss: 0.6575417518615723\n",
      "Batch Loss: 0.6575395464897156\n",
      "Batch Loss: 0.6753422617912292\n",
      "Batch Loss: 0.6456702947616577\n",
      "Batch Loss: 0.6397346258163452\n",
      "Batch Loss: 0.6456681489944458\n",
      "Batch Loss: 0.6516038179397583\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6575394868850708\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6434925198554993\n",
      "Batch Loss: 0.6694087386131287\n",
      "Batch Loss: 0.645668089389801\n",
      "Batch Loss: 0.6575416326522827\n",
      "Batch Loss: 0.6516081094741821\n",
      "Batch Loss: 0.6575394868850708\n",
      "Batch Loss: 0.6575372815132141\n",
      "Batch Loss: 0.6634751558303833\n",
      "Batch Loss: 0.6516081094741821\n",
      "Batch Loss: 0.6753444075584412\n",
      "Batch Loss: 0.6634751558303833\n",
      "Batch Loss: 0.6397344470024109\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.651610255241394\n",
      "Batch Loss: 0.657539427280426\n",
      "Batch Loss: 0.6612930297851562\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6516080498695374\n",
      "Batch Loss: 0.6753422021865845\n",
      "Batch Loss: 0.6672286987304688\n",
      "Batch Loss: 0.6634751558303833\n",
      "Batch Loss: 0.6575437188148499\n",
      "Batch Loss: 0.6694086790084839\n",
      "Batch Loss: 0.6694108247756958\n",
      "Batch Loss: 0.6337922215461731\n",
      "Batch Loss: 0.6575350761413574\n",
      "Batch Loss: 0.6731643676757812\n",
      "Batch Loss: 0.639736533164978\n",
      "Batch Loss: 0.6456722021102905\n",
      "Batch Loss: 0.6278607845306396\n",
      "Batch Loss: 0.6634771823883057\n",
      "Batch Loss: 0.6769157648086548\n",
      "Batch Loss: 0.6612907648086548\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.6553535461425781\n",
      "Batch Loss: 0.6397321820259094\n",
      "Batch Loss: 0.6397385597229004\n",
      "Batch Loss: 0.6731563806533813\n",
      "Batch Loss: 0.6634728908538818\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634771823883057\n",
      "Batch Loss: 0.6850335597991943\n",
      "Batch Loss: 0.6731600761413574\n",
      "Batch Loss: 0.6456679105758667\n",
      "Batch Loss: 0.6634750366210938\n",
      "Batch Loss: 0.643487811088562\n",
      "Batch Loss: 0.6456699967384338\n",
      "Batch Loss: 0.6634728908538818\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6219334602355957\n",
      "Batch Loss: 0.6456699371337891\n",
      "Batch Loss: 0.6516014337539673\n",
      "Batch Loss: 0.6634770631790161\n",
      "Batch Loss: 0.6694085597991943\n",
      "Batch Loss: 0.6575392484664917\n",
      "Batch Loss: 0.6516077518463135\n",
      "Batch Loss: 0.6612949371337891\n",
      "Batch Loss: 0.6516056060791016\n",
      "Batch Loss: 0.6553549766540527\n",
      "Batch Loss: 0.6575412750244141\n",
      "Batch Loss: 0.6828514337539673\n",
      "Batch Loss: 0.6790957450866699\n",
      "Batch Loss: 0.6337984800338745\n",
      "Batch Loss: 0.6672306060791016\n",
      "Batch Loss: 0.6456719636917114\n",
      "Batch Loss: 0.6672248840332031\n",
      "Batch Loss: 0.6456719636917114\n",
      "Batch Loss: 0.6575412750244141\n",
      "Batch Loss: 0.6575371026992798\n",
      "Batch Loss: 0.6672264337539673\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575391292572021\n",
      "Batch Loss: 0.6397361755371094\n",
      "Batch Loss: 0.6575391888618469\n",
      "Batch Loss: 0.6575371026992798\n",
      "Batch Loss: 0.6790978312492371\n",
      "Batch Loss: 0.6753421425819397\n",
      "Batch Loss: 0.6634727716445923\n",
      "Batch Loss: 0.6494254469871521\n",
      "Batch Loss: 0.6790977716445923\n",
      "Batch Loss: 0.6575391292572021\n",
      "Batch Loss: 0.6731621026992798\n",
      "Batch Loss: 0.6516034007072449\n",
      "Batch Loss: 0.6219269037246704\n",
      "Batch Loss: 0.6575371026992798\n",
      "Batch Loss: 0.6672263145446777\n",
      "Batch Loss: 0.6397340893745422\n",
      "Batch Loss: 0.6397340297698975\n",
      "Batch Loss: 0.6575411558151245\n",
      "Batch Loss: 0.6672304272651672\n",
      "Batch Loss: 0.6397401690483093\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6612988114356995\n",
      "Batch Loss: 0.6753420829772949\n",
      "Batch Loss: 0.6553575396537781\n",
      "Batch Loss: 0.6672283411026001\n",
      "Batch Loss: 0.6456737518310547\n",
      "Batch Loss: 0.6612987518310547\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6516013145446777\n",
      "Batch Loss: 0.6553609371185303\n",
      "Batch Loss: 0.6612967252731323\n",
      "Batch Loss: 0.6456656455993652\n",
      "Batch Loss: 0.6753461360931396\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6850258111953735\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6278665065765381\n",
      "Batch Loss: 0.6790921688079834\n",
      "Batch Loss: 0.6790996789932251\n",
      "Batch Loss: 0.6278665065765381\n",
      "Batch Loss: 0.6753461360931396\n",
      "Batch Loss: 0.6694063544273376\n",
      "Batch Loss: 0.657541036605835\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.6516072750091553\n",
      "Batch Loss: 0.6575409770011902\n",
      "Batch Loss: 0.6790956258773804\n",
      "Batch Loss: 0.6672261953353882\n",
      "Batch Loss: 0.6731619834899902\n",
      "Batch Loss: 0.6575409770011902\n",
      "Batch Loss: 0.6338001489639282\n",
      "Batch Loss: 0.6731619834899902\n",
      "Batch Loss: 0.6575409173965454\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6397337913513184\n",
      "Batch Loss: 0.6753440499305725\n",
      "Batch Loss: 0.6456674933433533\n",
      "Batch Loss: 0.6790956258773804\n",
      "Batch Loss: 0.6494250297546387\n",
      "Batch Loss: 0.657538890838623\n",
      "Batch Loss: 0.6516011953353882\n",
      "Batch Loss: 0.6694062948226929\n",
      "Batch Loss: 0.6397337913513184\n",
      "Batch Loss: 0.6612944602966309\n",
      "Batch Loss: 0.6634726524353027\n",
      "Batch Loss: 0.6731618642807007\n",
      "Batch Loss: 0.639731764793396\n",
      "Batch Loss: 0.679097592830658\n",
      "Batch Loss: 0.6516031622886658\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6731598973274231\n",
      "Batch Loss: 0.6694082617759705\n",
      "Batch Loss: 0.6375575065612793\n",
      "Batch Loss: 0.6790921688079834\n",
      "Batch Loss: 0.639731764793396\n",
      "Batch Loss: 0.6494249701499939\n",
      "Batch Loss: 0.6456694006919861\n",
      "Batch Loss: 0.6612983345985413\n",
      "Batch Loss: 0.6812777519226074\n",
      "Batch Loss: 0.651603102684021\n",
      "Batch Loss: 0.6753439903259277\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6612943410873413\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.669410228729248\n",
      "Batch Loss: 0.6812796592712402\n",
      "Batch Loss: 0.6731545925140381\n",
      "Batch Loss: 0.6612851023674011\n",
      "Batch Loss: 0.685035228729248\n",
      "Batch Loss: 0.6494228839874268\n",
      "Batch Loss: 0.6575407385826111\n",
      "Batch Loss: 0.6516050100326538\n",
      "Batch Loss: 0.676917314529419\n",
      "Batch Loss: 0.6731565594673157\n",
      "Batch Loss: 0.6575368642807007\n",
      "Batch Loss: 0.6612943410873413\n",
      "Batch Loss: 0.6612889766693115\n",
      "Batch Loss: 0.6634705662727356\n",
      "Batch Loss: 0.6553566455841064\n",
      "Batch Loss: 0.6731657385826111\n",
      "Batch Loss: 0.6575368046760559\n",
      "Batch Loss: 0.6397316455841064\n",
      "Batch Loss: 0.6494214534759521\n",
      "Batch Loss: 0.6397296786308289\n",
      "Batch Loss: 0.6575406789779663\n",
      "Batch Loss: 0.6634725332260132\n",
      "Batch Loss: 0.663474440574646\n",
      "Batch Loss: 0.663474440574646\n",
      "Batch Loss: 0.6694082021713257\n",
      "Batch Loss: 0.6731618046760559\n",
      "Batch Loss: 0.645667314529419\n",
      "Batch Loss: 0.6694082021713257\n",
      "Batch Loss: 0.6650458574295044\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6397315263748169\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6397296190261841\n",
      "Batch Loss: 0.6731584668159485\n",
      "Batch Loss: 0.6337977647781372\n",
      "Batch Loss: 0.6553565263748169\n",
      "Batch Loss: 0.6516029834747314\n",
      "Batch Loss: 0.6219301819801331\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575406193733215\n",
      "Batch Loss: 0.6456634402275085\n",
      "Batch Loss: 0.6278601288795471\n",
      "Batch Loss: 0.6575367450714111\n",
      "Batch Loss: 0.6397391557693481\n",
      "Batch Loss: 0.6375551223754883\n",
      "Batch Loss: 0.645669162273407\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6516048908233643\n",
      "Batch Loss: 0.6672297716140747\n",
      "Batch Loss: 0.6337957978248596\n",
      "Batch Loss: 0.6278657913208008\n",
      "Batch Loss: 0.6694062352180481\n",
      "Batch Loss: 0.673163652420044\n",
      "Batch Loss: 0.6494207978248596\n",
      "Batch Loss: 0.657538652420044\n",
      "Batch Loss: 0.6694118976593018\n",
      "Batch Loss: 0.657540500164032\n",
      "Batch Loss: 0.6456671953201294\n",
      "Batch Loss: 0.6575366854667664\n",
      "Batch Loss: 0.6575385928153992\n",
      "Batch Loss: 0.6672278642654419\n",
      "Batch Loss: 0.6790955066680908\n",
      "Batch Loss: 0.6278619170188904\n",
      "Batch Loss: 0.6434869170188904\n",
      "Batch Loss: 0.6634743213653564\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575367450714111\n",
      "Batch Loss: 0.6731598377227783\n",
      "Batch Loss: 0.6634724140167236\n",
      "Batch Loss: 0.6790955066680908\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6456708908081055\n",
      "Batch Loss: 0.6844261884689331\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6516028642654419\n",
      "Batch Loss: 0.6634723544120789\n",
      "Batch Loss: 0.6219298839569092\n",
      "Batch Loss: 0.6672278642654419\n",
      "Batch Loss: 0.6731616258621216\n",
      "Batch Loss: 0.6494174599647522\n",
      "Batch Loss: 0.6397294998168945\n",
      "Batch Loss: 0.6634723544120789\n",
      "Batch Loss: 0.6553544998168945\n",
      "Batch Loss: 0.6516046524047852\n",
      "Batch Loss: 0.6494225263595581\n",
      "Batch Loss: 0.6575403809547424\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6650443077087402\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6575403213500977\n",
      "Batch Loss: 0.6397314071655273\n",
      "Batch Loss: 0.6397294998168945\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6575384736061096\n",
      "Batch Loss: 0.6575347781181335\n",
      "Batch Loss: 0.6494193077087402\n",
      "Batch Loss: 0.6828527450561523\n",
      "Batch Loss: 0.6397331953048706\n",
      "Batch Loss: 0.6812794208526611\n",
      "Batch Loss: 0.6753437519073486\n",
      "Batch Loss: 0.6456688642501831\n",
      "Batch Loss: 0.6575403213500977\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6709744930267334\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6694080233573914\n",
      "Batch Loss: 0.663470447063446\n",
      "Batch Loss: 0.6575421094894409\n",
      "Batch Loss: 0.6456706523895264\n",
      "Batch Loss: 0.6575402021408081\n",
      "Batch Loss: 0.6634722948074341\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6516045331954956\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.663470447063446\n",
      "Batch Loss: 0.6575402021408081\n",
      "Batch Loss: 0.6553494930267334\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.639733076095581\n",
      "Batch Loss: 0.6612901091575623\n",
      "Batch Loss: 0.6456723809242249\n",
      "Batch Loss: 0.6731633543968201\n",
      "Batch Loss: 0.6456687450408936\n",
      "Batch Loss: 0.6634722948074341\n",
      "Batch Loss: 0.6790972352027893\n",
      "Batch Loss: 0.6694079637527466\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6337973475456238\n",
      "Batch Loss: 0.6575382947921753\n",
      "Batch Loss: 0.682845950126648\n",
      "Batch Loss: 0.6672276258468628\n",
      "Batch Loss: 0.6850311756134033\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6694115400314331\n",
      "Batch Loss: 0.6731566190719604\n",
      "Batch Loss: 0.6634740233421326\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6456651091575623\n",
      "Batch Loss: 0.657536506652832\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6790953874588013\n",
      "Batch Loss: 0.6790972352027893\n",
      "Batch Loss: 0.6337972283363342\n",
      "Batch Loss: 0.6278651356697083\n",
      "Batch Loss: 0.6731566190719604\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6694061160087585\n",
      "Batch Loss: 0.6516043543815613\n",
      "Batch Loss: 0.6456668376922607\n",
      "Batch Loss: 0.6709811687469482\n",
      "Batch Loss: 0.673161506652832\n",
      "Batch Loss: 0.643486499786377\n",
      "Batch Loss: 0.6909686326980591\n",
      "Batch Loss: 0.6516097187995911\n",
      "Batch Loss: 0.655354380607605\n",
      "Batch Loss: 0.6694061160087585\n",
      "Batch Loss: 0.6553597450256348\n",
      "Batch Loss: 0.6634739637374878\n",
      "Batch Loss: 0.6850311160087585\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6575382947921753\n",
      "Batch Loss: 0.6575382947921753\n",
      "Batch Loss: 0.673161506652832\n",
      "Batch Loss: 0.6694079041481018\n",
      "Batch Loss: 0.6850262880325317\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6516025066375732\n",
      "Batch Loss: 0.6634739637374878\n",
      "Batch Loss: 0.6456685662269592\n",
      "Batch Loss: 0.6694096326828003\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.66722571849823\n",
      "Batch Loss: 0.6397310495376587\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.6516025066375732\n",
      "Batch Loss: 0.6337988972663879\n",
      "Batch Loss: 0.679098904132843\n",
      "Batch Loss: 0.6516059637069702\n",
      "Batch Loss: 0.6516025066375732\n",
      "Batch Loss: 0.6337970495223999\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6397345066070557\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6553595066070557\n",
      "Batch Loss: 0.645666778087616\n",
      "Batch Loss: 0.6316149234771729\n",
      "Batch Loss: 0.6634721159934998\n",
      "Batch Loss: 0.6634721159934998\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.6672244071960449\n",
      "Batch Loss: 0.669407844543457\n",
      "Batch Loss: 0.669407844543457\n",
      "Batch Loss: 0.6316149234771729\n",
      "Batch Loss: 0.669407844543457\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6456649899482727\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6790971159934998\n",
      "Batch Loss: 0.6397344470024109\n",
      "Batch Loss: 0.6887799501419067\n",
      "Batch Loss: 0.6575363874435425\n",
      "Batch Loss: 0.685032844543457\n",
      "Batch Loss: 0.6434845924377441\n",
      "Batch Loss: 0.6612904667854309\n",
      "Batch Loss: 0.6887816786766052\n",
      "Batch Loss: 0.6337952613830566\n",
      "Batch Loss: 0.6575398445129395\n",
      "Batch Loss: 0.6753435134887695\n",
      "Batch Loss: 0.6753417253494263\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.675341784954071\n",
      "Batch Loss: 0.6575380563735962\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6672273874282837\n",
      "Batch Loss: 0.6709809303283691\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575380563735962\n",
      "Batch Loss: 0.6575380563735962\n",
      "Batch Loss: 0.6634737849235535\n",
      "Batch Loss: 0.6850310564041138\n",
      "Batch Loss: 0.6553559303283691\n",
      "Batch Loss: 0.6694095134735107\n",
      "Batch Loss: 0.6516023874282837\n",
      "Batch Loss: 0.6753451824188232\n",
      "Batch Loss: 0.6494219303131104\n",
      "Batch Loss: 0.6456665992736816\n",
      "Batch Loss: 0.6694077849388123\n",
      "Batch Loss: 0.6634754538536072\n",
      "Batch Loss: 0.6575397253036499\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.6456682682037354\n",
      "Batch Loss: 0.6790987253189087\n",
      "Batch Loss: 0.6575363278388977\n",
      "Batch Loss: 0.6456683278083801\n",
      "Batch Loss: 0.6731630563735962\n",
      "Batch Loss: 0.6575397253036499\n",
      "Batch Loss: 0.6516023278236389\n",
      "Batch Loss: 0.6634737253189087\n",
      "Batch Loss: 0.6397308707237244\n",
      "Batch Loss: 0.6769182682037354\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.6100641489028931\n",
      "Batch Loss: 0.6694077253341675\n",
      "Batch Loss: 0.6909667253494263\n",
      "Batch Loss: 0.67534339427948\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6790986657142639\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6612882018089294\n",
      "Batch Loss: 0.6709774732589722\n",
      "Batch Loss: 0.6634719967842102\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6456665396690369\n",
      "Batch Loss: 0.6516039371490479\n",
      "Batch Loss: 0.67534339427948\n",
      "Batch Loss: 0.6337951421737671\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6634736657142639\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6575362682342529\n",
      "Batch Loss: 0.6753417253494263\n",
      "Batch Loss: 0.6672272086143494\n",
      "Batch Loss: 0.6397308111190796\n",
      "Batch Loss: 0.6753417253494263\n",
      "Batch Loss: 0.6790969371795654\n",
      "Batch Loss: 0.6494266986846924\n",
      "Batch Loss: 0.6361715197563171\n",
      "Epoch 8/20, Loss: 0.6594498193101265, Time: 492.28s\n",
      "Batch Loss: 0.6397307515144348\n",
      "Batch Loss: 0.6456714868545532\n",
      "Batch Loss: 0.6256805658340454\n",
      "Batch Loss: 0.6338016986846924\n",
      "Batch Loss: 0.6694076657295227\n",
      "Batch Loss: 0.6612914800643921\n",
      "Batch Loss: 0.6731645464897156\n",
      "Batch Loss: 0.6516021490097046\n",
      "Batch Loss: 0.6575345396995544\n",
      "Batch Loss: 0.690963864326477\n",
      "Batch Loss: 0.6575378775596619\n",
      "Batch Loss: 0.6337983012199402\n",
      "Batch Loss: 0.6731628775596619\n",
      "Batch Loss: 0.6790952682495117\n",
      "Batch Loss: 0.6575362682342529\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.645668089389801\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6790952682495117\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6516004800796509\n",
      "Batch Loss: 0.6456680297851562\n",
      "Batch Loss: 0.6397339105606079\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6850265860557556\n",
      "Batch Loss: 0.6850309371948242\n",
      "Batch Loss: 0.6612881422042847\n",
      "Batch Loss: 0.6516020894050598\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6456696391105652\n",
      "Batch Loss: 0.6634718775749207\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6516053080558777\n",
      "Batch Loss: 0.6694092154502869\n",
      "Batch Loss: 0.6278624534606934\n",
      "Batch Loss: 0.6790968775749207\n",
      "Batch Loss: 0.669405996799469\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6575393676757812\n",
      "Batch Loss: 0.6397306323051453\n",
      "Batch Loss: 0.6456679105758667\n",
      "Batch Loss: 0.6278656721115112\n",
      "Batch Loss: 0.6828488111495972\n",
      "Batch Loss: 0.6612945795059204\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6575393676757812\n",
      "Batch Loss: 0.6575393676757812\n",
      "Batch Loss: 0.6694075465202332\n",
      "Batch Loss: 0.6634734272956848\n",
      "Batch Loss: 0.6731626987457275\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6634718179702759\n",
      "Batch Loss: 0.6634750366210938\n",
      "Batch Loss: 0.6634718179702759\n",
      "Batch Loss: 0.6672242283821106\n",
      "Batch Loss: 0.6516003608703613\n",
      "Batch Loss: 0.6516051292419434\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.6397289037704468\n",
      "Batch Loss: 0.655360221862793\n",
      "Batch Loss: 0.6731594800949097\n",
      "Batch Loss: 0.6516019701957703\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6337963342666626\n",
      "Batch Loss: 0.6516019105911255\n",
      "Batch Loss: 0.6887844800949097\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6494213342666626\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6553570032119751\n",
      "Batch Loss: 0.6219264268875122\n",
      "Batch Loss: 0.6850298047065735\n",
      "Batch Loss: 0.6456661820411682\n",
      "Batch Loss: 0.6612911820411682\n",
      "Batch Loss: 0.6516019105911255\n",
      "Batch Loss: 0.6516003012657166\n",
      "Batch Loss: 0.6278620958328247\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.6278605461120605\n",
      "Batch Loss: 0.6397304534912109\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6612895727157593\n",
      "Batch Loss: 0.6694074273109436\n",
      "Batch Loss: 0.6672284007072449\n",
      "Batch Loss: 0.657537579536438\n",
      "Batch Loss: 0.6672283411026001\n",
      "Batch Loss: 0.639736533164978\n",
      "Batch Loss: 0.6575374603271484\n",
      "Batch Loss: 0.6516033411026001\n",
      "Batch Loss: 0.6790951490402222\n",
      "Batch Loss: 0.7044083476066589\n",
      "Batch Loss: 0.6694073677062988\n",
      "Batch Loss: 0.6434813737869263\n",
      "Batch Loss: 0.639728844165802\n",
      "Batch Loss: 0.6516002416610718\n",
      "Batch Loss: 0.6434813737869263\n",
      "Batch Loss: 0.6753430962562561\n",
      "Batch Loss: 0.6434839963912964\n",
      "Batch Loss: 0.6634716987609863\n",
      "Batch Loss: 0.6516047716140747\n",
      "Batch Loss: 0.6397303342819214\n",
      "Batch Loss: 0.6337916851043701\n",
      "Batch Loss: 0.6516032218933105\n",
      "Batch Loss: 0.657535970211029\n",
      "Batch Loss: 0.6219232082366943\n",
      "Batch Loss: 0.6790981888771057\n",
      "Batch Loss: 0.661292552947998\n",
      "Batch Loss: 0.6456645727157593\n",
      "Batch Loss: 0.6494226455688477\n",
      "Batch Loss: 0.6828502416610718\n",
      "Batch Loss: 0.661285400390625\n",
      "Batch Loss: 0.6337931156158447\n",
      "Batch Loss: 0.6397318243980408\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6634731292724609\n",
      "Batch Loss: 0.6612924933433533\n",
      "Batch Loss: 0.6672252416610718\n",
      "Batch Loss: 0.655356764793396\n",
      "Batch Loss: 0.645667552947998\n",
      "Batch Loss: 0.6516032218933105\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.657538890838623\n",
      "Batch Loss: 0.6338005065917969\n",
      "Batch Loss: 0.6434868574142456\n",
      "Batch Loss: 0.6375481486320496\n",
      "Batch Loss: 0.6575374007225037\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6553497314453125\n",
      "Batch Loss: 0.6516016721725464\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6337930560112\n",
      "Batch Loss: 0.6516031622886658\n",
      "Batch Loss: 0.6575403213500977\n",
      "Batch Loss: 0.667221188545227\n",
      "Batch Loss: 0.6672266721725464\n",
      "Batch Loss: 0.6456704139709473\n",
      "Batch Loss: 0.682850182056427\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6969022154808044\n",
      "Batch Loss: 0.6456688642501831\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.6694072484970093\n",
      "Batch Loss: 0.6575387716293335\n",
      "Batch Loss: 0.6516016721725464\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6672266125679016\n",
      "Batch Loss: 0.6612894535064697\n",
      "Batch Loss: 0.6456673741340637\n",
      "Batch Loss: 0.6575373411178589\n",
      "Batch Loss: 0.6612894535064697\n",
      "Batch Loss: 0.6925394535064697\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6634700894355774\n",
      "Batch Loss: 0.6397302150726318\n",
      "Batch Loss: 0.6494198441505432\n",
      "Batch Loss: 0.6731608510017395\n",
      "Batch Loss: 0.6575402021408081\n",
      "Batch Loss: 0.6256794929504395\n",
      "Batch Loss: 0.6634700894355774\n",
      "Batch Loss: 0.6516029834747314\n",
      "Batch Loss: 0.6694072484970093\n",
      "Batch Loss: 0.6456687450408936\n",
      "Batch Loss: 0.6397316455841064\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6456701755523682\n",
      "Batch Loss: 0.6516001224517822\n",
      "Batch Loss: 0.6219229698181152\n",
      "Batch Loss: 0.6516001224517822\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6219229698181152\n",
      "Batch Loss: 0.6397300958633423\n",
      "Batch Loss: 0.657538652420044\n",
      "Batch Loss: 0.6337957978248596\n",
      "Batch Loss: 0.6397315263748169\n",
      "Batch Loss: 0.645664393901825\n",
      "Batch Loss: 0.663471519947052\n",
      "Batch Loss: 0.6612922549247742\n",
      "Batch Loss: 0.6575357913970947\n",
      "Batch Loss: 0.657538652420044\n",
      "Batch Loss: 0.6575357913970947\n",
      "Batch Loss: 0.6337957978248596\n",
      "Batch Loss: 0.6672251224517822\n",
      "Batch Loss: 0.6397343873977661\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6375522017478943\n",
      "Batch Loss: 0.6612908244132996\n",
      "Batch Loss: 0.6397329568862915\n",
      "Batch Loss: 0.6753429174423218\n",
      "Batch Loss: 0.6672254800796509\n",
      "Batch Loss: 0.6612893342971802\n",
      "Batch Loss: 0.645668625831604\n",
      "Batch Loss: 0.6516042947769165\n",
      "Batch Loss: 0.6397328972816467\n",
      "Batch Loss: 0.6219257712364197\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6753414869308472\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397314071655273\n",
      "Batch Loss: 0.6516056656837463\n",
      "Batch Loss: 0.65753573179245\n",
      "Batch Loss: 0.6731593608856201\n",
      "Batch Loss: 0.6397299766540527\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6337971091270447\n",
      "Batch Loss: 0.6650443077087402\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.6694085597991943\n",
      "Batch Loss: 0.6672250032424927\n",
      "Batch Loss: 0.6634742021560669\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6731607913970947\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.670974850654602\n",
      "Batch Loss: 0.6516000032424927\n",
      "Batch Loss: 0.6612893342971802\n",
      "Batch Loss: 0.6456670761108398\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575371026992798\n",
      "Batch Loss: 0.6694057583808899\n",
      "Batch Loss: 0.6456683874130249\n",
      "Batch Loss: 0.6516013741493225\n",
      "Batch Loss: 0.6812771558761597\n",
      "Batch Loss: 0.6650432348251343\n",
      "Batch Loss: 0.6634727716445923\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.6575384736061096\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.6790926456451416\n",
      "Batch Loss: 0.6812771558761597\n",
      "Batch Loss: 0.627859890460968\n",
      "Batch Loss: 0.6397326588630676\n",
      "Batch Loss: 0.639729917049408\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6650428175926208\n",
      "Batch Loss: 0.6769105195999146\n",
      "Batch Loss: 0.6850321292877197\n",
      "Batch Loss: 0.6516013145446777\n",
      "Batch Loss: 0.6516000032424927\n",
      "Batch Loss: 0.657537043094635\n",
      "Batch Loss: 0.6575356721878052\n",
      "Batch Loss: 0.6278639435768127\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6634727716445923\n",
      "Batch Loss: 0.6753427982330322\n",
      "Batch Loss: 0.6397271752357483\n",
      "Batch Loss: 0.6456669569015503\n",
      "Batch Loss: 0.6397325992584229\n",
      "Batch Loss: 0.6909626722335815\n",
      "Batch Loss: 0.6887869834899902\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456723809242249\n",
      "Batch Loss: 0.6575383543968201\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6672248840332031\n",
      "Batch Loss: 0.66940838098526\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6575356125831604\n",
      "Batch Loss: 0.655356228351593\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6887856721878052\n",
      "Batch Loss: 0.6672263145446777\n",
      "Batch Loss: 0.6316160559654236\n",
      "Batch Loss: 0.6516026258468628\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.645661473274231\n",
      "Batch Loss: 0.6397311687469482\n",
      "Batch Loss: 0.6694070100784302\n",
      "Batch Loss: 0.6553561687469482\n",
      "Batch Loss: 0.6753413677215576\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.6887832880020142\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6278610825538635\n",
      "Batch Loss: 0.6516026258468628\n",
      "Batch Loss: 0.6456655263900757\n",
      "Batch Loss: 0.6731569766998291\n",
      "Batch Loss: 0.6159909963607788\n",
      "Batch Loss: 0.6397337913513184\n",
      "Batch Loss: 0.6790913343429565\n",
      "Batch Loss: 0.6694083213806152\n",
      "Batch Loss: 0.6731619834899902\n",
      "Batch Loss: 0.6397297382354736\n",
      "Batch Loss: 0.6790949702262878\n",
      "Batch Loss: 0.6516011953353882\n",
      "Batch Loss: 0.6694083213806152\n",
      "Batch Loss: 0.6397311091423035\n",
      "Batch Loss: 0.6337940692901611\n",
      "Batch Loss: 0.6397311091423035\n",
      "Batch Loss: 0.6812770366668701\n",
      "Batch Loss: 0.6634699702262878\n",
      "Batch Loss: 0.6731605529785156\n",
      "Batch Loss: 0.6456654667854309\n",
      "Batch Loss: 0.6553547382354736\n",
      "Batch Loss: 0.6634726524353027\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6812784075737\n",
      "Batch Loss: 0.6672275066375732\n",
      "Batch Loss: 0.6516038179397583\n",
      "Batch Loss: 0.6219265460968018\n",
      "Batch Loss: 0.6769118905067444\n",
      "Batch Loss: 0.6753413677215576\n",
      "Batch Loss: 0.6375502347946167\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6553560495376587\n",
      "Batch Loss: 0.6769128441810608\n",
      "Batch Loss: 0.6515998244285583\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.6575381755828857\n",
      "Batch Loss: 0.6872127652168274\n",
      "Batch Loss: 0.6553524732589722\n",
      "Batch Loss: 0.6634738445281982\n",
      "Batch Loss: 0.6612904071807861\n",
      "Batch Loss: 0.6553586721420288\n",
      "Batch Loss: 0.6397297382354736\n",
      "Batch Loss: 0.6731618642807007\n",
      "Batch Loss: 0.6731592416763306\n",
      "Batch Loss: 0.6753426790237427\n",
      "Batch Loss: 0.6694056391716003\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6753426194190979\n",
      "Batch Loss: 0.6790949106216431\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.6553546786308289\n",
      "Batch Loss: 0.6456666588783264\n",
      "Batch Loss: 0.6337965726852417\n",
      "Batch Loss: 0.6397309303283691\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6812770366668701\n",
      "Batch Loss: 0.6812770366668701\n",
      "Batch Loss: 0.6575380563735962\n",
      "Batch Loss: 0.6397322416305542\n",
      "Batch Loss: 0.6769140958786011\n",
      "Batch Loss: 0.6397296190261841\n",
      "Batch Loss: 0.6516010761260986\n",
      "Batch Loss: 0.6278607845306396\n",
      "Batch Loss: 0.6650439500808716\n",
      "Batch Loss: 0.6612903475761414\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6672247648239136\n",
      "Batch Loss: 0.6516010761260986\n",
      "Batch Loss: 0.6753413081169128\n",
      "Batch Loss: 0.6790987253189087\n",
      "Batch Loss: 0.6753426194190979\n",
      "Batch Loss: 0.6575354337692261\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6515985131263733\n",
      "Batch Loss: 0.6456665992736816\n",
      "Batch Loss: 0.6672285795211792\n",
      "Batch Loss: 0.6516035795211792\n",
      "Batch Loss: 0.615994393825531\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6634724736213684\n",
      "Batch Loss: 0.6828497648239136\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6672199964523315\n",
      "Batch Loss: 0.6634711623191833\n",
      "Batch Loss: 0.6516010165214539\n",
      "Batch Loss: 0.6812770366668701\n",
      "Batch Loss: 0.6850318908691406\n",
      "Batch Loss: 0.6278606653213501\n",
      "Batch Loss: 0.6634724140167236\n",
      "Batch Loss: 0.6456639766693115\n",
      "Batch Loss: 0.639728307723999\n",
      "Batch Loss: 0.659109354019165\n",
      "Batch Loss: 0.655353307723999\n",
      "Batch Loss: 0.6397308111190796\n",
      "Batch Loss: 0.6434844136238098\n",
      "Batch Loss: 0.6694081425666809\n",
      "Batch Loss: 0.6575366854667664\n",
      "Batch Loss: 0.6516009569168091\n",
      "Batch Loss: 0.6634711027145386\n",
      "Batch Loss: 0.6828476190567017\n",
      "Batch Loss: 0.6516009569168091\n",
      "Batch Loss: 0.6790914535522461\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6456677317619324\n",
      "Batch Loss: 0.6494163274765015\n",
      "Batch Loss: 0.6812770366668701\n",
      "Batch Loss: 0.6531761288642883\n",
      "Batch Loss: 0.6672259569168091\n",
      "Batch Loss: 0.6672213077545166\n",
      "Batch Loss: 0.6634736061096191\n",
      "Batch Loss: 0.6731616258621216\n",
      "Batch Loss: 0.6612893342971802\n",
      "Batch Loss: 0.6672259569168091\n",
      "Batch Loss: 0.6494178771972656\n",
      "Batch Loss: 0.633793830871582\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6516022086143494\n",
      "Batch Loss: 0.6575378775596619\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6672258973121643\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6790927648544312\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6575366258621216\n",
      "Batch Loss: 0.6612902283668518\n",
      "Batch Loss: 0.6612914204597473\n",
      "Batch Loss: 0.6553557515144348\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6634711027145386\n",
      "Batch Loss: 0.6672234535217285\n",
      "Batch Loss: 0.6456664800643921\n",
      "Batch Loss: 0.688784122467041\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6769118905067444\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6634698510169983\n",
      "Batch Loss: 0.6790961027145386\n",
      "Batch Loss: 0.6612913608551025\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6634710431098938\n",
      "Batch Loss: 0.6516008973121643\n",
      "Batch Loss: 0.6337913274765015\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6516020894050598\n",
      "Batch Loss: 0.6731640100479126\n",
      "Batch Loss: 0.6337974071502686\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6397318840026855\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.651602029800415\n",
      "Batch Loss: 0.6672258377075195\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6612889170646667\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.651602029800415\n",
      "Batch Loss: 0.6731558442115784\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6634710431098938\n",
      "Batch Loss: 0.657536506652832\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6634734869003296\n",
      "Batch Loss: 0.6634710431098938\n",
      "Batch Loss: 0.6694055199623108\n",
      "Batch Loss: 0.6634722948074341\n",
      "Batch Loss: 0.6575365662574768\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6694067120552063\n",
      "Batch Loss: 0.6753412485122681\n",
      "Batch Loss: 0.6790927648544312\n",
      "Batch Loss: 0.6672257781028748\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6278567910194397\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6612900495529175\n",
      "Batch Loss: 0.6337960958480835\n",
      "Batch Loss: 0.6694067120552063\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6337972283363342\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6812769174575806\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694055199623108\n",
      "Batch Loss: 0.6456650495529175\n",
      "Batch Loss: 0.639729380607605\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.661291241645813\n",
      "Batch Loss: 0.6337972283363342\n",
      "Batch Loss: 0.6456698179244995\n",
      "Batch Loss: 0.6337948441505432\n",
      "Batch Loss: 0.6397293210029602\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.6515995860099792\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6494177579879761\n",
      "Batch Loss: 0.6575364470481873\n",
      "Batch Loss: 0.6575364470481873\n",
      "Batch Loss: 0.6553534865379333\n",
      "Batch Loss: 0.6456650495529175\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6634721755981445\n",
      "Batch Loss: 0.645667314529419\n",
      "Batch Loss: 0.6850317120552063\n",
      "Batch Loss: 0.6553499698638916\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.6434840559959412\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6634721755981445\n",
      "Batch Loss: 0.645661473274231\n",
      "Batch Loss: 0.6672269105911255\n",
      "Batch Loss: 0.688784122467041\n",
      "Batch Loss: 0.6337912082672119\n",
      "Batch Loss: 0.657537579536438\n",
      "Batch Loss: 0.6575363874435425\n",
      "Batch Loss: 0.6634733080863953\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6397315859794617\n",
      "Batch Loss: 0.6456685066223145\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456661820411682\n",
      "Batch Loss: 0.639726996421814\n",
      "Batch Loss: 0.6872126460075378\n",
      "Batch Loss: 0.6516029834747314\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.661288857460022\n",
      "Batch Loss: 0.6634709239006042\n",
      "Batch Loss: 0.645667314529419\n",
      "Batch Loss: 0.6672245264053345\n",
      "Batch Loss: 0.6553542613983154\n",
      "Batch Loss: 0.673159122467041\n",
      "Batch Loss: 0.6494185924530029\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6516017913818359\n",
      "Batch Loss: 0.673159122467041\n",
      "Batch Loss: 0.6494185328483582\n",
      "Batch Loss: 0.6575363874435425\n",
      "Batch Loss: 0.679097056388855\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6769118309020996\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.6575363874435425\n",
      "Batch Loss: 0.6731559634208679\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6219221353530884\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6575375199317932\n",
      "Batch Loss: 0.685030460357666\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6731570959091187\n",
      "Batch Loss: 0.6694077253341675\n",
      "Batch Loss: 0.6634709239006042\n",
      "Batch Loss: 0.6337969303131104\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6516028642654419\n",
      "Batch Loss: 0.688784122467041\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6515994668006897\n",
      "Batch Loss: 0.6516017317771912\n",
      "Batch Loss: 0.6575374603271484\n",
      "Batch Loss: 0.6337946057319641\n",
      "Batch Loss: 0.6672214269638062\n",
      "Batch Loss: 0.6753411889076233\n",
      "Batch Loss: 0.6337957382202148\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6456648707389832\n",
      "Batch Loss: 0.6397302746772766\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.6159863471984863\n",
      "Batch Loss: 0.675342321395874\n",
      "Batch Loss: 0.6634719967842102\n",
      "Batch Loss: 0.6516017317771912\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6850262880325317\n",
      "Batch Loss: 0.6672244668006897\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6397291421890259\n",
      "Batch Loss: 0.6551610827445984\n",
      "Epoch 9/20, Loss: 0.658796954887312, Time: 488.18s\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6456660032272339\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6725478768348694\n",
      "Batch Loss: 0.6575362682342529\n",
      "Batch Loss: 0.6278599500656128\n",
      "Batch Loss: 0.6672266721725464\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6575351357460022\n",
      "Batch Loss: 0.6516027450561523\n",
      "Batch Loss: 0.6397313475608826\n",
      "Batch Loss: 0.6456659436225891\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6516016721725464\n",
      "Batch Loss: 0.6456659436225891\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6575351357460022\n",
      "Batch Loss: 0.685030460357666\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6634730696678162\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6553562879562378\n",
      "Batch Loss: 0.6278588175773621\n",
      "Batch Loss: 0.6790958642959595\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.643484890460968\n",
      "Batch Loss: 0.6769148111343384\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6634730100631714\n",
      "Batch Loss: 0.6694076657295227\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6456636786460876\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6516026854515076\n",
      "Batch Loss: 0.6337955594062805\n",
      "Batch Loss: 0.6769147515296936\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6731600761413574\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6516026258468628\n",
      "Batch Loss: 0.6456648111343384\n",
      "Batch Loss: 0.6456647515296936\n",
      "Batch Loss: 0.6887861490249634\n",
      "Batch Loss: 0.6731600761413574\n",
      "Batch Loss: 0.6753411293029785\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6769139766693115\n",
      "Batch Loss: 0.6456648111343384\n",
      "Batch Loss: 0.6909661293029785\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6612886786460876\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.6731600761413574\n",
      "Batch Loss: 0.6812768578529358\n",
      "Batch Loss: 0.6753422021865845\n",
      "Batch Loss: 0.6694064736366272\n",
      "Batch Loss: 0.6516015529632568\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.6575372219085693\n",
      "Batch Loss: 0.6516026258468628\n",
      "Batch Loss: 0.6634718775749207\n",
      "Batch Loss: 0.6516014933586121\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672243475914001\n",
      "Batch Loss: 0.6694076061248779\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.681276798248291\n",
      "Batch Loss: 0.6634728908538818\n",
      "Batch Loss: 0.6753411293029785\n",
      "Batch Loss: 0.6634707450866699\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672232747077942\n",
      "Batch Loss: 0.6731593012809753\n",
      "Batch Loss: 0.6612886190414429\n",
      "Batch Loss: 0.6612907648086548\n",
      "Batch Loss: 0.6887840032577515\n",
      "Batch Loss: 0.6672214269638062\n",
      "Batch Loss: 0.6634718179702759\n",
      "Batch Loss: 0.6575350761413574\n",
      "Batch Loss: 0.6531740427017212\n",
      "Batch Loss: 0.6694064736366272\n",
      "Batch Loss: 0.6516014933586121\n",
      "Batch Loss: 0.6575371623039246\n",
      "Batch Loss: 0.6337922215461731\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6456646919250488\n",
      "Batch Loss: 0.6553529500961304\n",
      "Batch Loss: 0.6731611490249634\n",
      "Batch Loss: 0.6984742879867554\n",
      "Batch Loss: 0.6575360894203186\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6516014337539673\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6375479102134705\n",
      "Batch Loss: 0.6337953209877014\n",
      "Batch Loss: 0.6634707450866699\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6575350761413574\n",
      "Batch Loss: 0.6672242879867554\n",
      "Batch Loss: 0.681277871131897\n",
      "Batch Loss: 0.6397310495376587\n",
      "Batch Loss: 0.6575360894203186\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.682845413684845\n",
      "Batch Loss: 0.6694074869155884\n",
      "Batch Loss: 0.6634718179702759\n",
      "Batch Loss: 0.6337963342666626\n",
      "Batch Loss: 0.6790956854820251\n",
      "Batch Loss: 0.681276798248291\n",
      "Batch Loss: 0.6337942481040955\n",
      "Batch Loss: 0.6753411293029785\n",
      "Batch Loss: 0.6397299766540527\n",
      "Batch Loss: 0.6672273874282837\n",
      "Batch Loss: 0.6397289037704468\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6575350165367126\n",
      "Batch Loss: 0.6456667184829712\n",
      "Batch Loss: 0.6575360298156738\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6553570032119751\n",
      "Batch Loss: 0.6278605461120605\n",
      "Batch Loss: 0.6397330164909363\n",
      "Batch Loss: 0.6672253012657166\n",
      "Batch Loss: 0.6612906455993652\n",
      "Batch Loss: 0.6553528308868408\n",
      "Batch Loss: 0.6516013145446777\n",
      "Batch Loss: 0.6612906455993652\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6456635594367981\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6337931156158447\n",
      "Batch Loss: 0.6731561422348022\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6575369834899902\n",
      "Batch Loss: 0.6337952017784119\n",
      "Batch Loss: 0.6397278308868408\n",
      "Batch Loss: 0.6790966987609863\n",
      "Batch Loss: 0.686603844165802\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6634727716445923\n",
      "Batch Loss: 0.6456634998321533\n",
      "Batch Loss: 0.6634716987609863\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6612884998321533\n",
      "Batch Loss: 0.6515992283821106\n",
      "Batch Loss: 0.6731619834899902\n",
      "Batch Loss: 0.6553548574447632\n",
      "Batch Loss: 0.6456645727157593\n",
      "Batch Loss: 0.6494181156158447\n",
      "Batch Loss: 0.6731588840484619\n",
      "Batch Loss: 0.6515992283821106\n",
      "Batch Loss: 0.6828482151031494\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6553530693054199\n",
      "Batch Loss: 0.6828492283821106\n",
      "Batch Loss: 0.6456645131111145\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6694063544273376\n",
      "Batch Loss: 0.6672242283821106\n",
      "Batch Loss: 0.6575379371643066\n",
      "Batch Loss: 0.6828474998474121\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6397287845611572\n",
      "Batch Loss: 0.6694073677062988\n",
      "Batch Loss: 0.6575379371643066\n",
      "Batch Loss: 0.6790966391563416\n",
      "Batch Loss: 0.6515992283821106\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6159889698028564\n",
      "Batch Loss: 0.6516011953353882\n",
      "Batch Loss: 0.6397278308868408\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6731572151184082\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6456674337387085\n",
      "Batch Loss: 0.6753410696983337\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6790946125984192\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397297382354736\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.667225182056427\n",
      "Batch Loss: 0.6337960362434387\n",
      "Batch Loss: 0.6494190692901611\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6731609106063843\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.639727771282196\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.6790928840637207\n",
      "Batch Loss: 0.6397307515144348\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6575359106063843\n",
      "Batch Loss: 0.6337950229644775\n",
      "Batch Loss: 0.667225182056427\n",
      "Batch Loss: 0.6337920427322388\n",
      "Batch Loss: 0.6434832811355591\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6397297382354736\n",
      "Batch Loss: 0.6375524997711182\n",
      "Batch Loss: 0.6612887382507324\n",
      "Batch Loss: 0.6553537845611572\n",
      "Batch Loss: 0.6494170427322388\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6575357913970947\n",
      "Batch Loss: 0.6753419637680054\n",
      "Batch Loss: 0.6672251224517822\n",
      "Batch Loss: 0.6575358510017395\n",
      "Batch Loss: 0.6634725332260132\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.6694062948226929\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.6672232151031494\n",
      "Batch Loss: 0.6575377583503723\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.6612887382507324\n",
      "Batch Loss: 0.6575357913970947\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6850303411483765\n",
      "Batch Loss: 0.6553536653518677\n",
      "Batch Loss: 0.667224109172821\n",
      "Batch Loss: 0.6456663608551025\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6790946125984192\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.663471519947052\n",
      "Batch Loss: 0.679096519947052\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6731598377227783\n",
      "Batch Loss: 0.6516000628471375\n",
      "Batch Loss: 0.6731607913970947\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6516029834747314\n",
      "Batch Loss: 0.6850312948226929\n",
      "Batch Loss: 0.663471519947052\n",
      "Batch Loss: 0.6575367450714111\n",
      "Batch Loss: 0.645666241645813\n",
      "Batch Loss: 0.6256779432296753\n",
      "Batch Loss: 0.6516010165214539\n",
      "Batch Loss: 0.6694052815437317\n",
      "Batch Loss: 0.6516000628471375\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6553500890731812\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6397286653518677\n",
      "Batch Loss: 0.6516001224517822\n",
      "Batch Loss: 0.6634696125984192\n",
      "Batch Loss: 0.651599109172821\n",
      "Batch Loss: 0.59818434715271\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6553536057472229\n",
      "Batch Loss: 0.6850267648696899\n",
      "Batch Loss: 0.633791983127594\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.651599109172821\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.65753573179245\n",
      "Batch Loss: 0.6456643342971802\n",
      "Batch Loss: 0.6278572082519531\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6612902879714966\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6337919235229492\n",
      "Batch Loss: 0.6790920495986938\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.6790946125984192\n",
      "Batch Loss: 0.6731616258621216\n",
      "Batch Loss: 0.6672215461730957\n",
      "Batch Loss: 0.6828500032424927\n",
      "Batch Loss: 0.6337910294532776\n",
      "Batch Loss: 0.6278599500656128\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6516000032424927\n",
      "Batch Loss: 0.6591089963912964\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.6456661224365234\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6672250032424927\n",
      "Batch Loss: 0.6731606721878052\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.6672250032424927\n",
      "Batch Loss: 0.6456670761108398\n",
      "Batch Loss: 0.6672234535217285\n",
      "Batch Loss: 0.6753409504890442\n",
      "Batch Loss: 0.6516009569168091\n",
      "Batch Loss: 0.6731588244438171\n",
      "Batch Loss: 0.6694071292877197\n",
      "Batch Loss: 0.661288321018219\n",
      "Batch Loss: 0.6790964007377625\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6731597781181335\n",
      "Batch Loss: 0.64348304271698\n",
      "Batch Loss: 0.6812766790390015\n",
      "Batch Loss: 0.6612858772277832\n",
      "Batch Loss: 0.661288321018219\n",
      "Batch Loss: 0.6397294998168945\n",
      "Batch Loss: 0.6850302815437317\n",
      "Batch Loss: 0.6850302815437317\n",
      "Batch Loss: 0.645665168762207\n",
      "Batch Loss: 0.6575375199317932\n",
      "Batch Loss: 0.645663321018219\n",
      "Batch Loss: 0.6731597781181335\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6672242879867554\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6494178771972656\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6456660628318787\n",
      "Batch Loss: 0.6575356721878052\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6753418445587158\n",
      "Batch Loss: 0.6731597185134888\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6731597185134888\n",
      "Batch Loss: 0.6591070890426636\n",
      "Batch Loss: 0.6456660032272339\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6612882614135742\n",
      "Batch Loss: 0.6790945529937744\n",
      "Batch Loss: 0.6397284865379333\n",
      "Batch Loss: 0.6278598308563232\n",
      "Batch Loss: 0.6731606721878052\n",
      "Batch Loss: 0.6456642150878906\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.657536506652832\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6694061160087585\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6731606125831604\n",
      "Batch Loss: 0.645663321018219\n",
      "Batch Loss: 0.6812766790390015\n",
      "Batch Loss: 0.6456651091575623\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6694061160087585\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672249436378479\n",
      "Batch Loss: 0.6850302219390869\n",
      "Batch Loss: 0.6694061160087585\n",
      "Batch Loss: 0.6731605529785156\n",
      "Batch Loss: 0.6553534865379333\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6397311687469482\n",
      "Batch Loss: 0.621924877166748\n",
      "Batch Loss: 0.6694070100784302\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6672239899635315\n",
      "Batch Loss: 0.6812766194343567\n",
      "Batch Loss: 0.6553534865379333\n",
      "Batch Loss: 0.6753418445587158\n",
      "Batch Loss: 0.6515989899635315\n",
      "Batch Loss: 0.6531689167022705\n",
      "Batch Loss: 0.6634712815284729\n",
      "Batch Loss: 0.6553552150726318\n",
      "Batch Loss: 0.6731614470481873\n",
      "Batch Loss: 0.6634712815284729\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6850302219390869\n",
      "Batch Loss: 0.6337935924530029\n",
      "Batch Loss: 0.6591037511825562\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.657534658908844\n",
      "Batch Loss: 0.6612882614135742\n",
      "Batch Loss: 0.6634712219238281\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6456623673439026\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.6516015529632568\n",
      "Batch Loss: 0.6709818840026855\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6790953874588013\n",
      "Batch Loss: 0.6456658840179443\n",
      "Batch Loss: 0.6337927579879761\n",
      "Batch Loss: 0.6456640958786011\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6634721159934998\n",
      "Batch Loss: 0.6337918043136597\n",
      "Batch Loss: 0.6731605529785156\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.6397284269332886\n",
      "Batch Loss: 0.6634712815284729\n",
      "Batch Loss: 0.6515997648239136\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.66722571849823\n",
      "Batch Loss: 0.6812775135040283\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.6375479698181152\n",
      "Batch Loss: 0.6731604933738708\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456640958786011\n",
      "Batch Loss: 0.6790930032730103\n",
      "Batch Loss: 0.6850310564041138\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6731604933738708\n",
      "Batch Loss: 0.6553550958633423\n",
      "Batch Loss: 0.673159658908844\n",
      "Batch Loss: 0.6591063737869263\n",
      "Batch Loss: 0.6516006588935852\n",
      "Batch Loss: 0.6397283673286438\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6591063737869263\n",
      "Batch Loss: 0.6828465461730957\n",
      "Batch Loss: 0.6769123077392578\n",
      "Batch Loss: 0.6612890958786011\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.663472056388855\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.657534658908844\n",
      "Batch Loss: 0.6753417253494263\n",
      "Batch Loss: 0.6731604933738708\n",
      "Batch Loss: 0.6575354933738708\n",
      "Batch Loss: 0.6731595993041992\n",
      "Batch Loss: 0.6612899303436279\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6731573343276978\n",
      "Batch Loss: 0.6634711623191833\n",
      "Batch Loss: 0.6337943077087402\n",
      "Batch Loss: 0.6731595993041992\n",
      "Batch Loss: 0.6731587648391724\n",
      "Batch Loss: 0.6806644797325134\n",
      "Batch Loss: 0.690963625907898\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6456648707389832\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6337926387786865\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.639728307723999\n",
      "Batch Loss: 0.6456657648086548\n",
      "Batch Loss: 0.6516013741493225\n",
      "Batch Loss: 0.6812774538993835\n",
      "Batch Loss: 0.6672247648239136\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6672238707542419\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.670978307723999\n",
      "Batch Loss: 0.6850279569625854\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6850310564041138\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6694068312644958\n",
      "Batch Loss: 0.6456648111343384\n",
      "Batch Loss: 0.6790952682495117\n",
      "Batch Loss: 0.6694068908691406\n",
      "Batch Loss: 0.6456648111343384\n",
      "Batch Loss: 0.6553549766540527\n",
      "Batch Loss: 0.6575353741645813\n",
      "Batch Loss: 0.655353307723999\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6456648111343384\n",
      "Batch Loss: 0.6516004800796509\n",
      "Batch Loss: 0.6753408312797546\n",
      "Batch Loss: 0.6575354337692261\n",
      "Batch Loss: 0.6434835195541382\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6397315263748169\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.6753416657447815\n",
      "Batch Loss: 0.649417519569397\n",
      "Batch Loss: 0.6159862279891968\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6575353741645813\n",
      "Batch Loss: 0.6769131422042847\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6947194337844849\n",
      "Batch Loss: 0.6516004800796509\n",
      "Batch Loss: 0.6456639766693115\n",
      "Batch Loss: 0.6553502082824707\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6575353741645813\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6456639766693115\n",
      "Batch Loss: 0.6790952682495117\n",
      "Batch Loss: 0.6753408312797546\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6575353741645813\n",
      "Batch Loss: 0.6812773942947388\n",
      "Batch Loss: 0.6553502082824707\n",
      "Batch Loss: 0.6516004204750061\n",
      "Batch Loss: 0.651601254940033\n",
      "Batch Loss: 0.6278567910194397\n",
      "Batch Loss: 0.6337933540344238\n",
      "Batch Loss: 0.665042519569397\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.6434811949729919\n",
      "Batch Loss: 0.6219258904457092\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6753416061401367\n",
      "Batch Loss: 0.6753408312797546\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6434849500656128\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6397297978401184\n",
      "Batch Loss: 0.6397313475608826\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6456655263900757\n",
      "Batch Loss: 0.6337932348251343\n",
      "Batch Loss: 0.7006551027297974\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6553523540496826\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6672238111495972\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6397289633750916\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6397281885147095\n",
      "Batch Loss: 0.6516003608703613\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6353648900985718\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.6397273540496826\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6397289037704468\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6850309371948242\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6424974799156189\n",
      "Epoch 10/20, Loss: 0.6604094105572423, Time: 483.76s\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.645664632320404\n",
      "Batch Loss: 0.6634702086448669\n",
      "Batch Loss: 0.6456654071807861\n",
      "Batch Loss: 0.6731566190719604\n",
      "Batch Loss: 0.6769130825996399\n",
      "Batch Loss: 0.6612880825996399\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6278590559959412\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6100527048110962\n",
      "Batch Loss: 0.6434832811355591\n",
      "Batch Loss: 0.6731602549552917\n",
      "Batch Loss: 0.6731594800949097\n",
      "Batch Loss: 0.6634702086448669\n",
      "Batch Loss: 0.6812772750854492\n",
      "Batch Loss: 0.6515987515449524\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.6694066524505615\n",
      "Batch Loss: 0.6516003012657166\n",
      "Batch Loss: 0.6575368046760559\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6790951490402222\n",
      "Batch Loss: 0.6494174003601074\n",
      "Batch Loss: 0.663470983505249\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6672245264053345\n",
      "Batch Loss: 0.6553530693054199\n",
      "Batch Loss: 0.6337953805923462\n",
      "Batch Loss: 0.6494181156158447\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6694066524505615\n",
      "Batch Loss: 0.6790944337844849\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.6375482082366943\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6337900757789612\n",
      "Batch Loss: 0.6694058775901794\n",
      "Batch Loss: 0.633793830871582\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6337953805923462\n",
      "Batch Loss: 0.6434816718101501\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6634709239006042\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.6456645131111145\n",
      "Batch Loss: 0.6672252416610718\n",
      "Batch Loss: 0.6397280693054199\n",
      "Batch Loss: 0.6753415465354919\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6397287845611572\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.673160195350647\n",
      "Batch Loss: 0.6278581619262695\n",
      "Batch Loss: 0.6553522944450378\n",
      "Batch Loss: 0.6731594204902649\n",
      "Batch Loss: 0.6456637382507324\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.667225182056427\n",
      "Batch Loss: 0.6790943741798401\n",
      "Batch Loss: 0.6828486919403076\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.5981810092926025\n",
      "Batch Loss: 0.6397302746772766\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6672236919403076\n",
      "Batch Loss: 0.661290168762207\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6634708642959595\n",
      "Batch Loss: 0.6516008973121643\n",
      "Batch Loss: 0.6337922811508179\n",
      "Batch Loss: 0.6575351357460022\n",
      "Batch Loss: 0.6731601357460022\n",
      "Batch Loss: 0.6516023874282837\n",
      "Batch Loss: 0.6634715795516968\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6553537249565125\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6753414869308472\n",
      "Batch Loss: 0.6828486323356628\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.669406533241272\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6337944865226746\n",
      "Batch Loss: 0.6612874269485474\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.645665168762207\n",
      "Batch Loss: 0.6887836456298828\n",
      "Batch Loss: 0.6850300431251526\n",
      "Batch Loss: 0.6672244071960449\n",
      "Batch Loss: 0.6672229170799255\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6397294402122498\n",
      "Batch Loss: 0.6731573939323425\n",
      "Batch Loss: 0.6731588840484619\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6650429368019104\n",
      "Batch Loss: 0.6456629633903503\n",
      "Batch Loss: 0.6516008377075195\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6397279500961304\n",
      "Batch Loss: 0.6709786653518677\n",
      "Batch Loss: 0.6753407716751099\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6612879633903503\n",
      "Batch Loss: 0.6575350761413574\n",
      "Batch Loss: 0.6456643342971802\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6456651091575623\n",
      "Batch Loss: 0.6397286653518677\n",
      "Batch Loss: 0.6753407716751099\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6397300958633423\n",
      "Batch Loss: 0.6812765002250671\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6753422021865845\n",
      "Batch Loss: 0.6219215393066406\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.6337936520576477\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6850301027297974\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6516000628471375\n",
      "Batch Loss: 0.6634707450866699\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6672250628471375\n",
      "Batch Loss: 0.6753414869308472\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6456629633903503\n",
      "Batch Loss: 0.6515993475914001\n",
      "Batch Loss: 0.7006550431251526\n",
      "Batch Loss: 0.7006538510322571\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6515993475914001\n",
      "Batch Loss: 0.6753407716751099\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6887816786766052\n",
      "Batch Loss: 0.6397278904914856\n",
      "Batch Loss: 0.6516000032424927\n",
      "Batch Loss: 0.6278564929962158\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6753421425819397\n",
      "Batch Loss: 0.6694064736366272\n",
      "Batch Loss: 0.6434814929962158\n",
      "Batch Loss: 0.6634707450866699\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6731600165367126\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6947193145751953\n",
      "Batch Loss: 0.6634714603424072\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6397278904914856\n",
      "Batch Loss: 0.6694064140319824\n",
      "Batch Loss: 0.6494171619415283\n",
      "Batch Loss: 0.6753414273262024\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.65160071849823\n",
      "Batch Loss: 0.655349612236023\n",
      "Batch Loss: 0.6672242879867554\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.6553535461425781\n",
      "Batch Loss: 0.6634714007377625\n",
      "Batch Loss: 0.6397285461425781\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6397271752357483\n",
      "Batch Loss: 0.6456636190414429\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6769142150878906\n",
      "Batch Loss: 0.6456636190414429\n",
      "Batch Loss: 0.6731593012809753\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6731593012809753\n",
      "Batch Loss: 0.6634699702262878\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6634714007377625\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6278564929962158\n",
      "Batch Loss: 0.6672242879867554\n",
      "Batch Loss: 0.6515999436378479\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6515999436378479\n",
      "Batch Loss: 0.673158586025238\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6515992879867554\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6553535461425781\n",
      "Batch Loss: 0.6672235727310181\n",
      "Batch Loss: 0.6812771558761597\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.680664598941803\n",
      "Batch Loss: 0.6612884998321533\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.6694064140319824\n",
      "Batch Loss: 0.6694064140319824\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6672238111495972\n",
      "Batch Loss: 0.6397271156311035\n",
      "Batch Loss: 0.6397278308868408\n",
      "Batch Loss: 0.6709753274917603\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6672242879867554\n",
      "Batch Loss: 0.6516005992889404\n",
      "Batch Loss: 0.6731599569320679\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6515992283821106\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.6731606125831604\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6515992283821106\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6494177579879761\n",
      "Batch Loss: 0.6731593012809753\n",
      "Batch Loss: 0.6634719371795654\n",
      "Batch Loss: 0.6197412610054016\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6634699702262878\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.6694062948226929\n",
      "Batch Loss: 0.6553534269332886\n",
      "Batch Loss: 0.6753413677215576\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6337940692901611\n",
      "Batch Loss: 0.6553534269332886\n",
      "Batch Loss: 0.6494157314300537\n",
      "Batch Loss: 0.6634699702262878\n",
      "Batch Loss: 0.6634713411331177\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.6397284269332886\n",
      "Batch Loss: 0.6790956258773804\n",
      "Batch Loss: 0.6753407120704651\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.633791446685791\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6337920427322388\n",
      "Batch Loss: 0.6456634998321533\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6887842416763306\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6397271156311035\n",
      "Batch Loss: 0.7065907120704651\n",
      "Batch Loss: 0.6278563141822815\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6850312948226929\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6397284269332886\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6634705662727356\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6850288510322571\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6694056391716003\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575361490249634\n",
      "Batch Loss: 0.6515997648239136\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6612890958786011\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6456647515296936\n",
      "Batch Loss: 0.6278582811355591\n",
      "Batch Loss: 0.6456647515296936\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6634705662727356\n",
      "Batch Loss: 0.6397283673286438\n",
      "Batch Loss: 0.6709771156311035\n",
      "Batch Loss: 0.6575355529785156\n",
      "Batch Loss: 0.6790942549705505\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6591058373451233\n",
      "Batch Loss: 0.6456640958786011\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6575354933738708\n",
      "Batch Loss: 0.6612847447395325\n",
      "Batch Loss: 0.6494163274765015\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6790955066680908\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.6456634402275085\n",
      "Batch Loss: 0.6634705662727356\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6456640958786011\n",
      "Batch Loss: 0.6812763810157776\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6456634402275085\n",
      "Batch Loss: 0.6337920427322388\n",
      "Batch Loss: 0.6790949106216431\n",
      "Batch Loss: 0.6516003608703613\n",
      "Batch Loss: 0.6790949106216431\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6731598377227783\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6790932416915894\n",
      "Batch Loss: 0.6575348377227783\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6278607249259949\n",
      "Batch Loss: 0.6694062352180481\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6337932348251343\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6575367450714111\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.670978307723999\n",
      "Batch Loss: 0.6812763810157776\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6612883806228638\n",
      "Batch Loss: 0.6850299835205078\n",
      "Batch Loss: 0.6694062352180481\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6612860560417175\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6672234535217285\n",
      "Batch Loss: 0.6812763810157776\n",
      "Batch Loss: 0.639728307723999\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.621921181678772\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397276520729065\n",
      "Batch Loss: 0.6278568506240845\n",
      "Batch Loss: 0.639728307723999\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6278568506240845\n",
      "Batch Loss: 0.6634711623191833\n",
      "Batch Loss: 0.673156201839447\n",
      "Batch Loss: 0.639728307723999\n",
      "Batch Loss: 0.6516009569168091\n",
      "Batch Loss: 0.6397289037704468\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6494163274765015\n",
      "Batch Loss: 0.6828503608703613\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6434818506240845\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6790948510169983\n",
      "Batch Loss: 0.6887847781181335\n",
      "Batch Loss: 0.6397295594215393\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6769133806228638\n",
      "Batch Loss: 0.62785804271698\n",
      "Batch Loss: 0.6278555989265442\n",
      "Batch Loss: 0.6337944269180298\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6672240495681763\n",
      "Batch Loss: 0.649417519569397\n",
      "Batch Loss: 0.651599645614624\n",
      "Batch Loss: 0.6612889766693115\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.663470447063446\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.657535970211029\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.6397275924682617\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6219216585159302\n",
      "Batch Loss: 0.6634711027145386\n",
      "Batch Loss: 0.6219222545623779\n",
      "Batch Loss: 0.6591062545776367\n",
      "Batch Loss: 0.6694061756134033\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6812763810157776\n",
      "Batch Loss: 0.6672239899635315\n",
      "Batch Loss: 0.6925360560417175\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6694067716598511\n",
      "Batch Loss: 0.6790942549705505\n",
      "Batch Loss: 0.6694055795669556\n",
      "Batch Loss: 0.645663321018219\n",
      "Batch Loss: 0.6100503206253052\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6753406524658203\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6337919235229492\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6397275924682617\n",
      "Batch Loss: 0.6515989899635315\n",
      "Batch Loss: 0.6672239899635315\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6397287845611572\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456644535064697\n",
      "Batch Loss: 0.639726996421814\n",
      "Batch Loss: 0.6909646391868591\n",
      "Batch Loss: 0.6731603145599365\n",
      "Batch Loss: 0.6753406524658203\n",
      "Batch Loss: 0.6494162678718567\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6650419235229492\n",
      "Batch Loss: 0.6731568574905396\n",
      "Batch Loss: 0.6397281289100647\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.673159122467041\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6515989899635315\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6219216585159302\n",
      "Batch Loss: 0.6694055199623108\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6694055199623108\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6575363874435425\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6337918043136597\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6515995264053345\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6278561353683472\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6516001224517822\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6434805393218994\n",
      "Batch Loss: 0.6397269368171692\n",
      "Batch Loss: 0.6553519368171692\n",
      "Batch Loss: 0.6434828639030457\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6456637978553772\n",
      "Batch Loss: 0.6709769368171692\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6337912082672119\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.7237855195999146\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6909656524658203\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6672239303588867\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6731590628623962\n",
      "Batch Loss: 0.6337924003601074\n",
      "Batch Loss: 0.6634709239006042\n",
      "Batch Loss: 0.6731584668159485\n",
      "Batch Loss: 0.6850298643112183\n",
      "Batch Loss: 0.6397275328636169\n",
      "Batch Loss: 0.6612882614135742\n",
      "Batch Loss: 0.6434816718101501\n",
      "Batch Loss: 0.6612876653671265\n",
      "Batch Loss: 0.6575334668159485\n",
      "Batch Loss: 0.6397280693054199\n",
      "Batch Loss: 0.6769120693206787\n",
      "Batch Loss: 0.6397280693054199\n",
      "Batch Loss: 0.6731595993041992\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6650424003601074\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.6434833407402039\n",
      "Batch Loss: 0.6397280693054199\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6456649303436279\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6650392413139343\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6694060564041138\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.669404923915863\n",
      "Batch Loss: 0.6397286057472229\n",
      "Batch Loss: 0.6612876057624817\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.682848334312439\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6337928771972656\n",
      "Batch Loss: 0.6812769174575806\n",
      "Batch Loss: 0.6515988707542419\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6709780097007751\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.6553535461425781\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6612861156463623\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6531693935394287\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6790932416915894\n",
      "Batch Loss: 0.6575356721878052\n",
      "Batch Loss: 0.6553513407707214\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.6488295793533325\n",
      "Epoch 11/20, Loss: 0.6594448839234818, Time: 492.24s\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6397280097007751\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6456642746925354\n",
      "Batch Loss: 0.6575351357460022\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6456637382507324\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6650417447090149\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6872119903564453\n",
      "Batch Loss: 0.6672238707542419\n",
      "Batch Loss: 0.6731575131416321\n",
      "Batch Loss: 0.6434832215309143\n",
      "Batch Loss: 0.6397290825843811\n",
      "Batch Loss: 0.6553524136543274\n",
      "Batch Loss: 0.6515994071960449\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6219214200973511\n",
      "Batch Loss: 0.6456636786460876\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6790947318077087\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6575356721878052\n",
      "Batch Loss: 0.6397285461425781\n",
      "Batch Loss: 0.6375453472137451\n",
      "Batch Loss: 0.6456636786460876\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6850309371948242\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6731569766998291\n",
      "Batch Loss: 0.655350387096405\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6456636190414429\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6515988707542419\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6278554201126099\n",
      "Batch Loss: 0.6828453540802002\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6753411293029785\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6397279500961304\n",
      "Batch Loss: 0.6100504398345947\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6456636190414429\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.679094672203064\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6575350165367126\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.6694064736366272\n",
      "Batch Loss: 0.6731595396995544\n",
      "Batch Loss: 0.6553534269332886\n",
      "Batch Loss: 0.6575345396995544\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6672238111495972\n",
      "Batch Loss: 0.6925361156463623\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6925366520881653\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6612886190414429\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.6612850427627563\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6694059371948242\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.694719672203064\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.62785804271698\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6397278904914856\n",
      "Batch Loss: 0.6628594994544983\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6553534269332886\n",
      "Batch Loss: 0.6456630825996399\n",
      "Batch Loss: 0.6219223737716675\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6612890958786011\n",
      "Batch Loss: 0.6375452280044556\n",
      "Batch Loss: 0.6397278308868408\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6456630825996399\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.62785804271698\n",
      "Batch Loss: 0.6612885594367981\n",
      "Batch Loss: 0.6731569766998291\n",
      "Batch Loss: 0.6575339436531067\n",
      "Batch Loss: 0.656923770904541\n",
      "Batch Loss: 0.6850279569625854\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6337916254997253\n",
      "Batch Loss: 0.6456640958786011\n",
      "Batch Loss: 0.6790932416915894\n",
      "Batch Loss: 0.6850298643112183\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.679094135761261\n",
      "Batch Loss: 0.6456635594367981\n",
      "Batch Loss: 0.6672237515449524\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6634706854820251\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6612880229949951\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6575349569320679\n",
      "Batch Loss: 0.6612890362739563\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6515997648239136\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6672218441963196\n",
      "Batch Loss: 0.6575339436531067\n",
      "Batch Loss: 0.6872119903564453\n",
      "Batch Loss: 0.6672233939170837\n",
      "Batch Loss: 0.6375457048416138\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6753410696983337\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6850308775901794\n",
      "Batch Loss: 0.6515997648239136\n",
      "Batch Loss: 0.6731589436531067\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6828477382659912\n",
      "Batch Loss: 0.6672218441963196\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6337925791740417\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6434789896011353\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.6612875461578369\n",
      "Batch Loss: 0.7006548643112183\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6456634998321533\n",
      "Batch Loss: 0.6694063544273376\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6709772944450378\n",
      "Batch Loss: 0.6612861156463623\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.6337915658950806\n",
      "Batch Loss: 0.6634706258773804\n",
      "Batch Loss: 0.6494171023368835\n",
      "Batch Loss: 0.6850303411483765\n",
      "Batch Loss: 0.6828468441963196\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.7162798643112183\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6672218441963196\n",
      "Batch Loss: 0.6256747245788574\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6694062948226929\n",
      "Batch Loss: 0.6731593608856201\n",
      "Batch Loss: 0.6494171023368835\n",
      "Batch Loss: 0.637545645236969\n",
      "Batch Loss: 0.6397292613983154\n",
      "Batch Loss: 0.6397272348403931\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.6531716585159302\n",
      "Batch Loss: 0.6850303411483765\n",
      "Batch Loss: 0.6887838840484619\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6278563141822815\n",
      "Batch Loss: 0.6434800028800964\n",
      "Batch Loss: 0.6397272348403931\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694058179855347\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6731588840484619\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.633792519569397\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6456634402275085\n",
      "Batch Loss: 0.6872119903564453\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6634705662727356\n",
      "Batch Loss: 0.675341010093689\n",
      "Batch Loss: 0.6731588840484619\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6634700894355774\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6553527116775513\n",
      "Batch Loss: 0.6828481554985046\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6850279569625854\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6790945529937744\n",
      "Batch Loss: 0.6866022348403931\n",
      "Batch Loss: 0.6828469038009644\n",
      "Batch Loss: 0.6575348973274231\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6278572678565979\n",
      "Batch Loss: 0.6672231554985046\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6612889170646667\n",
      "Batch Loss: 0.6812767386436462\n",
      "Batch Loss: 0.6337934732437134\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6397272348403931\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.633792519569397\n",
      "Batch Loss: 0.633792519569397\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6494179964065552\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6337910294532776\n",
      "Batch Loss: 0.6256750822067261\n",
      "Batch Loss: 0.6709767580032349\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6812762022018433\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6672236323356628\n",
      "Batch Loss: 0.6413000822067261\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6694057583808899\n",
      "Batch Loss: 0.6434804201126099\n",
      "Batch Loss: 0.6219205856323242\n",
      "Batch Loss: 0.6672236323356628\n",
      "Batch Loss: 0.6575353145599365\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.7044084072113037\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6694052815437317\n",
      "Batch Loss: 0.6790923476219177\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6515986323356628\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6515995860099792\n",
      "Batch Loss: 0.6494161486625671\n",
      "Batch Loss: 0.6909655332565308\n",
      "Batch Loss: 0.645663857460022\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6397276520729065\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6650409698486328\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6850302815437317\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6769129037857056\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6694052815437317\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6337928771972656\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6375459432601929\n",
      "Batch Loss: 0.686600923538208\n",
      "Batch Loss: 0.6790950298309326\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6812762022018433\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6634699702262878\n",
      "Batch Loss: 0.6278557777404785\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6672235727310181\n",
      "Batch Loss: 0.6397280693054199\n",
      "Batch Loss: 0.6456637382507324\n",
      "Batch Loss: 0.657535195350647\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.7103428840637207\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.645663321018219\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.645663321018219\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6753409504890442\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6456637382507324\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6337919235229492\n",
      "Batch Loss: 0.6397285461425781\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6278557777404785\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6397271156311035\n",
      "Batch Loss: 0.6456628441810608\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6575343012809753\n",
      "Batch Loss: 0.6515998840332031\n",
      "Batch Loss: 0.6278566122055054\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6553521156311035\n",
      "Batch Loss: 0.6612878441810608\n",
      "Batch Loss: 0.663470447063446\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6790944933891296\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6591061949729919\n",
      "Batch Loss: 0.6397284269332886\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6397275924682617\n",
      "Batch Loss: 0.6694056987762451\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6397279500961304\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6456628441810608\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6812762022018433\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6456628441810608\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.6316105723381042\n",
      "Batch Loss: 0.6575347185134888\n",
      "Batch Loss: 0.6634703874588013\n",
      "Batch Loss: 0.657534658908844\n",
      "Batch Loss: 0.6159838438034058\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6337931156158447\n",
      "Batch Loss: 0.6337913870811462\n",
      "Batch Loss: 0.6397284269332886\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.676912784576416\n",
      "Batch Loss: 0.6612861752510071\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6337926387786865\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.639728844165802\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6790949106216431\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6397275328636169\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6219213008880615\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.6850290298461914\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.6694056391716003\n",
      "Batch Loss: 0.6672230362892151\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.6515989303588867\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.610050618648529\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.657534658908844\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6769108772277832\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6515993475914001\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.690965473651886\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6769112348556519\n",
      "Batch Loss: 0.6337918043136597\n",
      "Batch Loss: 0.6887833476066589\n",
      "Batch Loss: 0.6278560757637024\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6397270560264587\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6515993475914001\n",
      "Batch Loss: 0.6790944337844849\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6634703278541565\n",
      "Batch Loss: 0.6553524732589722\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6553520560264587\n",
      "Batch Loss: 0.6041144728660583\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6553524732589722\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.67315673828125\n",
      "Batch Loss: 0.6612877249717712\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6731572151184082\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6672230362892151\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6612885594367981\n",
      "Batch Loss: 0.6687957048416138\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6456627249717712\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6672219038009644\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6947194337844849\n",
      "Batch Loss: 0.6278555989265442\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6634698510169983\n",
      "Batch Loss: 0.6769127249717712\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6731600165367126\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6850286722183228\n",
      "Batch Loss: 0.6337913274765015\n",
      "Batch Loss: 0.6337917447090149\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6634702682495117\n",
      "Batch Loss: 0.6375457048416138\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.633790910243988\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6672230362892151\n",
      "Batch Loss: 0.6434810161590576\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6494159698486328\n",
      "Batch Loss: 0.6494166851043701\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6397278308868408\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6337929368019104\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6612881422042847\n",
      "Batch Loss: 0.6678219437599182\n",
      "Epoch 12/20, Loss: 0.6596388576787486, Time: 493.86s\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6812761425971985\n",
      "Batch Loss: 0.6397274136543274\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6612881422042847\n",
      "Batch Loss: 0.6969000697135925\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6434803009033203\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6553515791893005\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.7103428840637207\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456630825996399\n",
      "Batch Loss: 0.6278559565544128\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6100492477416992\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6850301027297974\n",
      "Batch Loss: 0.6337912678718567\n",
      "Batch Loss: 0.673159122467041\n",
      "Batch Loss: 0.6434805393218994\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6650413870811462\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6553515791893005\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6753408312797546\n",
      "Batch Loss: 0.6753408312797546\n",
      "Batch Loss: 0.6337912678718567\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6612876653671265\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6434801816940308\n",
      "Batch Loss: 0.627855122089386\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6456634998321533\n",
      "Batch Loss: 0.6256741881370544\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6731590628623962\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6434805393218994\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6828476190567017\n",
      "Batch Loss: 0.6909639835357666\n",
      "Batch Loss: 0.6872118711471558\n",
      "Batch Loss: 0.6553505063056946\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6790947914123535\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6219210028648376\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.682848334312439\n",
      "Batch Loss: 0.6709773540496826\n",
      "Batch Loss: 0.625673770904541\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6753412485122681\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6634701490402222\n",
      "Batch Loss: 0.6515991687774658\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6887832880020142\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.6515987515449524\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6612870097160339\n",
      "Batch Loss: 0.6397269368171692\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6434812545776367\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6397273540496826\n",
      "Batch Loss: 0.6731590628623962\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6731594800949097\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6850296854972839\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6575340628623962\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6278558969497681\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6850301027297974\n",
      "Batch Loss: 0.669405460357666\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6397277116775513\n",
      "Batch Loss: 0.6634697914123535\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6397277116775513\n",
      "Batch Loss: 0.6790943741798401\n",
      "Batch Loss: 0.6553522944450378\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.6634705066680908\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6434812545776367\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6612876653671265\n",
      "Batch Loss: 0.6337923407554626\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6984719038009644\n",
      "Batch Loss: 0.6887836456298828\n",
      "Batch Loss: 0.6575347781181335\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6494147777557373\n",
      "Batch Loss: 0.6456637382507324\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6337915658950806\n",
      "Batch Loss: 0.6709768772125244\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6672240495681763\n",
      "Batch Loss: 0.6612887382507324\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6612875461578369\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6337922811508179\n",
      "Batch Loss: 0.6256740689277649\n",
      "Batch Loss: 0.6850301027297974\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6947189569473267\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6456629633903503\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.667223334312439\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.653170108795166\n",
      "Batch Loss: 0.6397279500961304\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6316108703613281\n",
      "Batch Loss: 0.6709775924682617\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6812761425971985\n",
      "Batch Loss: 0.6159858703613281\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6531684994697571\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6219204664230347\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.7000447511672974\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6337915062904358\n",
      "Batch Loss: 0.6434804201126099\n",
      "Batch Loss: 0.6694054007530212\n",
      "Batch Loss: 0.6812760829925537\n",
      "Batch Loss: 0.6515989899635315\n",
      "Batch Loss: 0.6828472018241882\n",
      "Batch Loss: 0.6397275328636169\n",
      "Batch Loss: 0.6494165062904358\n",
      "Batch Loss: 0.633792519569397\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6709745526313782\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6709765195846558\n",
      "Batch Loss: 0.6650411486625671\n",
      "Batch Loss: 0.6397275924682617\n",
      "Batch Loss: 0.6575343608856201\n",
      "Batch Loss: 0.6456636190414429\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6909654140472412\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6278554201126099\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6672239303588867\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.6672232151031494\n",
      "Batch Loss: 0.6672232747077942\n",
      "Batch Loss: 0.6769115924835205\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6278564929962158\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6553521752357483\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.633791446685791\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6397271752357483\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6375447511672974\n",
      "Batch Loss: 0.6812764406204224\n",
      "Batch Loss: 0.6553521752357483\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.6709768176078796\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6278550624847412\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.673158586025238\n",
      "Batch Loss: 0.6397271752357483\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6672228574752808\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6769112348556519\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.6753410696983337\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6850284337997437\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6909653544425964\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.665041446685791\n",
      "Batch Loss: 0.6731588840484619\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6672228574752808\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6969010829925537\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6672228574752808\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6434807181358337\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6397274732589722\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.633791446685791\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6828478574752808\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6612878441810608\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6672219634056091\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6634696125984192\n",
      "Batch Loss: 0.6456632018089294\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6812760829925537\n",
      "Batch Loss: 0.6278560161590576\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6634696125984192\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6515988707542419\n",
      "Batch Loss: 0.6828482151031494\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6612874269485474\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.6256738901138306\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6812764406204224\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6456634998321533\n",
      "Batch Loss: 0.6769115924835205\n",
      "Batch Loss: 0.6634699106216431\n",
      "Batch Loss: 0.663469672203064\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.673158586025238\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6812764406204224\n",
      "Batch Loss: 0.6672219634056091\n",
      "Batch Loss: 0.6753407120704651\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6694053411483765\n",
      "Batch Loss: 0.6337910890579224\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6219203472137451\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6753407120704651\n",
      "Batch Loss: 0.6731592416763306\n",
      "Batch Loss: 0.6790942549705505\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6531703472137451\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6672234535217285\n",
      "Batch Loss: 0.6553527116775513\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6397267580032349\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.7044067978858948\n",
      "Batch Loss: 0.6575342416763306\n",
      "Batch Loss: 0.6337916851043701\n",
      "Batch Loss: 0.6753407120704651\n",
      "Batch Loss: 0.6634696125984192\n",
      "Batch Loss: 0.673158586025238\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6494157314300537\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6553521156311035\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6337916851043701\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6731592416763306\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6672231554985046\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6337910294532776\n",
      "Batch Loss: 0.6709752678871155\n",
      "Batch Loss: 0.6790945529937744\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6812763810157776\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.661287784576416\n",
      "Batch Loss: 0.6790934205055237\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6753406524658203\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6219199299812317\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6515988111495972\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6828478574752808\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6456630825996399\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6694052815437317\n",
      "Batch Loss: 0.6456630229949951\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.6397267580032349\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6397276520729065\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6337909698486328\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6790927648544312\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6731573939323425\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6434804201126099\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6219196319580078\n",
      "Batch Loss: 0.6694052815437317\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6456633806228638\n",
      "Batch Loss: 0.6790927648544312\n",
      "Batch Loss: 0.6731582283973694\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6694049835205078\n",
      "Batch Loss: 0.6515987515449524\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6753406524658203\n",
      "Batch Loss: 0.6753406524658203\n",
      "Batch Loss: 0.6553516983985901\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6612877249717712\n",
      "Batch Loss: 0.6812760829925537\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6828474998474121\n",
      "Batch Loss: 0.6337919235229492\n",
      "Batch Loss: 0.6672234535217285\n",
      "Batch Loss: 0.6456627249717712\n",
      "Batch Loss: 0.6278564929962158\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6515983939170837\n",
      "Batch Loss: 0.6575344204902649\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.6515984535217285\n",
      "Batch Loss: 0.655351996421814\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6337909698486328\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.685029923915863\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6434800624847412\n",
      "Batch Loss: 0.6456627249717712\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6515990495681763\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.6434808969497681\n",
      "Batch Loss: 0.6515986919403076\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.6531692743301392\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.6278564929962158\n",
      "Batch Loss: 0.639726996421814\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6731587648391724\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6731585264205933\n",
      "Batch Loss: 0.669404923915863\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6553528308868408\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6397269368171692\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.655159056186676\n",
      "Epoch 13/20, Loss: 0.6594331496404706, Time: 496.53s\n",
      "Batch Loss: 0.6397275328636169\n",
      "Batch Loss: 0.639726996421814\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.669404923915863\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.6887835264205933\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6731576919555664\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.69847172498703\n",
      "Batch Loss: 0.6397272348403931\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6434805393218994\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6337918043136597\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6494159698486328\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6850285530090332\n",
      "Batch Loss: 0.621920108795166\n",
      "Batch Loss: 0.6494162678718567\n",
      "Batch Loss: 0.6456632614135742\n",
      "Batch Loss: 0.6515983939170837\n",
      "Batch Loss: 0.6375440359115601\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6337918043136597\n",
      "Batch Loss: 0.6790944933891296\n",
      "Batch Loss: 0.6278554797172546\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6709764003753662\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6278555393218994\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6612862944602966\n",
      "Batch Loss: 0.6850296258926392\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6850298643112183\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6612871289253235\n",
      "Batch Loss: 0.6434799432754517\n",
      "Batch Loss: 0.621920645236969\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.649415910243988\n",
      "Batch Loss: 0.6575345993041992\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6812763214111328\n",
      "Batch Loss: 0.6731584668159485\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6100492477416992\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456629037857056\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6887826919555664\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.665040910243988\n",
      "Batch Loss: 0.6612879037857056\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6731590032577515\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6256733536720276\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6753405928611755\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6790934205055237\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.647234320640564\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6634700298309326\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6219199895858765\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6769126057624817\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6672230362892151\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6575334668159485\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6790944337844849\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6694051623344421\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6278557181358337\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.6634697318077087\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6731584668159485\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6812760233879089\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6337911486625671\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6494159698486328\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6812760233879089\n",
      "Batch Loss: 0.6397277116775513\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6434807181358337\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6456631422042847\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6337911486625671\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6909655332565308\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6278549432754517\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6316088438034058\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6397268772125244\n",
      "Batch Loss: 0.6515985727310181\n",
      "Batch Loss: 0.6753408908843994\n",
      "Batch Loss: 0.6591041684150696\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6337913870811462\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6850295662879944\n",
      "Batch Loss: 0.6887831687927246\n",
      "Batch Loss: 0.6337916851043701\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.679094135761261\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6909652948379517\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6828477382659912\n",
      "Batch Loss: 0.6731587052345276\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6434817314147949\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575344800949097\n",
      "Batch Loss: 0.6553518176078796\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6850296258926392\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6672232151031494\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6219202280044556\n",
      "Batch Loss: 0.6575339436531067\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6790943741798401\n",
      "Batch Loss: 0.6850301027297974\n",
      "Batch Loss: 0.7006545662879944\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6672237515449524\n",
      "Batch Loss: 0.6494160890579224\n",
      "Batch Loss: 0.6397270560264587\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672232151031494\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6337905526161194\n",
      "Batch Loss: 0.6909652948379517\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6575341820716858\n",
      "Batch Loss: 0.6434797048568726\n",
      "Batch Loss: 0.6397273540496826\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6159844398498535\n",
      "Batch Loss: 0.665040135383606\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6553506255149841\n",
      "Batch Loss: 0.6591049432754517\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6456627249717712\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6434805989265442\n",
      "Batch Loss: 0.6731575131416321\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6553518176078796\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6612869501113892\n",
      "Batch Loss: 0.6494165658950806\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6672220230102539\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.679094135761261\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6747305989265442\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6337910890579224\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6909652948379517\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6612869501113892\n",
      "Batch Loss: 0.6434811353683472\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6612862944602966\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6753407716751099\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.700654149055481\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.657534122467041\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6612874865531921\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6219196319580078\n",
      "Batch Loss: 0.6634693741798401\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6909655332565308\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6337913274765015\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6612876653671265\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6494160294532776\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6494160294532776\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6337907910346985\n",
      "Batch Loss: 0.6866006255149841\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6850295662879944\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6909652948379517\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.661287248134613\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6828476786613464\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6612874269485474\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6434800624847412\n",
      "Batch Loss: 0.6634695529937744\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6612876653671265\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6434798836708069\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6553516983985901\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6434805393218994\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6375452876091003\n",
      "Batch Loss: 0.6494165062904358\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6575338840484619\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6612869501113892\n",
      "Batch Loss: 0.6790943145751953\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6434807181358337\n",
      "Batch Loss: 0.6850299835205078\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6694052219390869\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6672230958938599\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6278557181358337\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6278555393218994\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6159840822219849\n",
      "Batch Loss: 0.6078658103942871\n",
      "Batch Loss: 0.6612869501113892\n",
      "Batch Loss: 0.6769121885299683\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6397266983985901\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6456626057624817\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6650409698486328\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6575340628623962\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6672220230102539\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6278558969497681\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6753405332565308\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.7044083476066589\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6515985131263733\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6278552412986755\n",
      "Batch Loss: 0.6828476190567017\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.645662784576416\n",
      "Batch Loss: 0.6731575131416321\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6316088438034058\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6887835264205933\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.655351459980011\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6969003677368164\n",
      "Batch Loss: 0.6278554201126099\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6709764003753662\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6159842610359192\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6553521156311035\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6828478574752808\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.627855658531189\n",
      "Batch Loss: 0.6612875461578369\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6672228574752808\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6672228574752808\n",
      "Batch Loss: 0.6515982747077942\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6456623673439026\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456623673439026\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6337912082672119\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6614905595779419\n",
      "Epoch 14/20, Loss: 0.6596697090835701, Time: 492.41s\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6753407120704651\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.633790910243988\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6887827515602112\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.6634694933891296\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6494157314300537\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6850287318229675\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6219197511672974\n",
      "Batch Loss: 0.6456623673439026\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6553515195846558\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6887827515602112\n",
      "Batch Loss: 0.6672220230102539\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6790942549705505\n",
      "Batch Loss: 0.6650402545928955\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6397272348403931\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6456627249717712\n",
      "Batch Loss: 0.675340473651886\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6337910890579224\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6828476190567017\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6434794068336487\n",
      "Batch Loss: 0.6434803605079651\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6790932416915894\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6434797644615173\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6553504467010498\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6337910890579224\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6612871289253235\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6731587648391724\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.631608784198761\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6850292086601257\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6278555989265442\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6731587052345276\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6219198703765869\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.655351996421814\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6456624865531921\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6397267580032349\n",
      "Batch Loss: 0.6515983939170837\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6672220230102539\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.6790932416915894\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6397265791893005\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634694337844849\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.639726996421814\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6515982151031494\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6553514003753662\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.651598334312439\n",
      "Batch Loss: 0.6694051027297974\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.6100484132766724\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.7065900564193726\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6159837245941162\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6515981554985046\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6731586456298828\n",
      "Batch Loss: 0.669404923915863\n",
      "Batch Loss: 0.6456626653671265\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6828479766845703\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.643480122089386\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6434803009033203\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6709756851196289\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6375442743301392\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337906718254089\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6731575727462769\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6909645199775696\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397271156311035\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6887832880020142\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6553516983985901\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6575334668159485\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6278549432754517\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6872116327285767\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6553506851196289\n",
      "Batch Loss: 0.6650409698486328\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.6947191953659058\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6397266983985901\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6672220230102539\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6769118309020996\n",
      "Batch Loss: 0.6672229766845703\n",
      "Batch Loss: 0.688782811164856\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.6278550624847412\n",
      "Batch Loss: 0.6278549432754517\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456625461578369\n",
      "Batch Loss: 0.6650406122207642\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6850297451019287\n",
      "Batch Loss: 0.7000442147254944\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6278554797172546\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.661287248134613\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6612870097160339\n",
      "Batch Loss: 0.6887824535369873\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6434810161590576\n",
      "Batch Loss: 0.6731584668159485\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6434797644615173\n",
      "Batch Loss: 0.6575338244438171\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6769113540649414\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6375445127487183\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6947188377380371\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6575334668159485\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.7006546854972839\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6731582283973694\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6494157314300537\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6494159698486328\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6790933609008789\n",
      "Batch Loss: 0.6509872674942017\n",
      "Batch Loss: 0.6553506851196289\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6159836649894714\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6925363540649414\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694050431251526\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6850288510322571\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.655351459980011\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.665040135383606\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6591044664382935\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6850290298461914\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6575340032577515\n",
      "Batch Loss: 0.6278555393218994\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6553518772125244\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634693145751953\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6397268176078796\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6591050624847412\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6887831091880798\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6337910890579224\n",
      "Batch Loss: 0.6553516387939453\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6925368309020996\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6337905526161194\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6709762811660767\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6672219038009644\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6575337648391724\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6731584072113037\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6650402545928955\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6672220826148987\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6612863540649414\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6828474998474121\n",
      "Batch Loss: 0.6947184801101685\n",
      "Batch Loss: 0.6612874269485474\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6612873077392578\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575337052345276\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6872116327285767\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6531692743301392\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6397265791893005\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6488276124000549\n",
      "Epoch 15/20, Loss: 0.6603506982529936, Time: 483.34s\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6219191551208496\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6219202280044556\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6828474998474121\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6687939763069153\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6494160294532776\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6731582283973694\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6709762811660767\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6375443339347839\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6612863540649414\n",
      "Batch Loss: 0.6650404334068298\n",
      "Batch Loss: 0.6612871289253235\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.686600923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6278550028800964\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6612863540649414\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634692549705505\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6591050028800964\n",
      "Batch Loss: 0.688782811164856\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6672226786613464\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6650402545928955\n",
      "Batch Loss: 0.6397266983985901\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6553514003753662\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6731583476066589\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6515979766845703\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.604112446308136\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6812760829925537\n",
      "Batch Loss: 0.6456623077392578\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6515980958938599\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6612871289253235\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6828474998474121\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.6769115328788757\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6219192743301392\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6434803009033203\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.7006543278694153\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6709756851196289\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6672219634056091\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.6434802412986755\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.667222797870636\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.669404923915863\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6531698703765869\n",
      "Batch Loss: 0.645662248134613\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6887830495834351\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6337909698486328\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6790941953659058\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575336456298828\n",
      "Batch Loss: 0.6850290894508362\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6947185397148132\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6769117712974548\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6969009041786194\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6769115328788757\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6219192147254944\n",
      "Batch Loss: 0.6337906718254089\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6375445127487183\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6612861156463623\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6219193935394287\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6434798240661621\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6515980362892151\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6278547644615173\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6812760233879089\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6553513407707214\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6850290894508362\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6947180032730103\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6731576919555664\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.688782811164856\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6947187781333923\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6591042280197144\n",
      "Batch Loss: 0.6553513407707214\n",
      "Batch Loss: 0.6553517580032349\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6494148969650269\n",
      "Batch Loss: 0.6434803009033203\n",
      "Batch Loss: 0.6219191551208496\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.639726459980011\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6219193339347839\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6634691953659058\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6456620097160339\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6947187185287476\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.657533586025238\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6375443935394287\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6812760233879089\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6494155526161194\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6278551816940308\n",
      "Batch Loss: 0.6456624269485474\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6790935397148132\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6219192743301392\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.670975923538208\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.659104585647583\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.6219193935394287\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.688782811164856\n",
      "Batch Loss: 0.6709762811660767\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6612871885299683\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6494154334068298\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6694048643112183\n",
      "Batch Loss: 0.6790940165519714\n",
      "Batch Loss: 0.6375441551208496\n",
      "Batch Loss: 0.6494158506393433\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6790940165519714\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6494157314300537\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6969007253646851\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6672227382659912\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6790940165519714\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6612870097160339\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6434800624847412\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6850295662879944\n",
      "Batch Loss: 0.6812760233879089\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6434803605079651\n",
      "Batch Loss: 0.6375442743301392\n",
      "Batch Loss: 0.6709761619567871\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6872116327285767\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515978574752808\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6456621289253235\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6650403141975403\n",
      "Batch Loss: 0.645661473274231\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6159831881523132\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6828471422195435\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6866008043289185\n",
      "Batch Loss: 0.663469135761261\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6278548836708069\n",
      "Batch Loss: 0.6591046452522278\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6790938973426819\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6687936782836914\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6337905526161194\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6790940761566162\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6909652948379517\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.6709762811660767\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6375445127487183\n",
      "Batch Loss: 0.6947185397148132\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6553514003753662\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6397266387939453\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6678216457366943\n",
      "Epoch 16/20, Loss: 0.6597719781431322, Time: 473.76s\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6887830495834351\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6769118309020996\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.651597797870636\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6397265195846558\n",
      "Batch Loss: 0.6753404140472412\n",
      "Batch Loss: 0.6434799432754517\n",
      "Batch Loss: 0.6515976786613464\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.700654149055481\n",
      "Batch Loss: 0.6515979170799255\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6709758043289185\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6694048047065735\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6575335264205933\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6731582880020142\n",
      "Batch Loss: 0.6278553009033203\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6790934205055237\n",
      "Batch Loss: 0.6731576919555664\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6709758043289185\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6434798240661621\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.685029149055481\n",
      "Batch Loss: 0.6591049432754517\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6434799432754517\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6219193339347839\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6041120290756226\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.7103433609008789\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6634690761566162\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.643480122089386\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6375440955162048\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6694046854972839\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6397263407707214\n",
      "Batch Loss: 0.6694047451019287\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6375440359115601\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6434798240661621\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6575333476066589\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6434798240661621\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6531684994697571\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6872115731239319\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.631608247756958\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6591045260429382\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6850295662879944\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6456621885299683\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6278548836708069\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6337908506393433\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6909651160240173\n",
      "Batch Loss: 0.6790940165519714\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6709758043289185\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6434797048568726\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6375443935394287\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6909648180007935\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6278547644615173\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.655351459980011\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6887829899787903\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6872115731239319\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6909651160240173\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6887831091880798\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6709759831428528\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6790940165519714\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6947183609008789\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6515977382659912\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6769115328788757\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6591046452522278\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.685029149055481\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456620693206787\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6531691551208496\n",
      "Batch Loss: 0.6747293472290039\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6375440359115601\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6909648776054382\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.7022257447242737\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6337907314300537\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6709763407707214\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6709762811660767\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6219191551208496\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6612868905067444\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6753403544425964\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.633790135383606\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6650404334068298\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575334072113037\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6612870693206787\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6434799432754517\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6494156718254089\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6278545260429382\n",
      "Batch Loss: 0.6553512811660767\n",
      "Batch Loss: 0.6375440955162048\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6278546452522278\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6790934205055237\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6278550028800964\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6612863540649414\n",
      "Batch Loss: 0.6612869501113892\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6591044664382935\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6375441551208496\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6219189763069153\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6375435590744019\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6612863540649414\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6887827515602112\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.641297459602356\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6654942035675049\n",
      "Epoch 17/20, Loss: 0.6603095290400469, Time: 474.43s\n",
      "Batch Loss: 0.6887828707695007\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6909652352333069\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6553512215614319\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6591048836708069\n",
      "Batch Loss: 0.6434795260429382\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6850296258926392\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753402948379517\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.604111909866333\n",
      "Batch Loss: 0.6316083669662476\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6969006061553955\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6316084265708923\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6375441551208496\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6256726980209351\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6850296258926392\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6909651160240173\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.7044079899787903\n",
      "Batch Loss: 0.6909652352333069\n",
      "Batch Loss: 0.6769116520881653\n",
      "Batch Loss: 0.6769115328788757\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6812759637832642\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6909651160240173\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6672225594520569\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6375440955162048\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6753402352333069\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.686600923538208\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6828473210334778\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6828472018241882\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6337905526161194\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6316084861755371\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6887830495834351\n",
      "Batch Loss: 0.637543797492981\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6041120886802673\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6337903141975403\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6634690165519714\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6219190359115601\n",
      "Batch Loss: 0.6397261023521423\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6790939569473267\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6159831881523132\n",
      "Batch Loss: 0.6219189167022705\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6278548240661621\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6397264003753662\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731582283973694\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6634689569473267\n",
      "Batch Loss: 0.6709756255149841\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6925365328788757\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.692536473274231\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6909651756286621\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6494156122207642\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.668793797492981\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6159836053848267\n",
      "Batch Loss: 0.694718599319458\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6515975594520569\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6397262811660767\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6769115328788757\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.7044077515602112\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6337906122207642\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6159833669662476\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6909651160240173\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456619501113892\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6591043472290039\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6575332283973694\n",
      "Batch Loss: 0.6812759041786194\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515976190567017\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6947187185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6887829303741455\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6628583669662476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6828471422195435\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6434794068336487\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6397262215614319\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.7006543278694153\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.6434797048568726\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6887831091880798\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.670975923538208\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6375440359115601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6828473210334778\n",
      "Batch Loss: 0.615983247756958\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6424959897994995\n",
      "Epoch 18/20, Loss: 0.65996634278688, Time: 478.15s\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6731581091880798\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6694046258926392\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6375439167022705\n",
      "Batch Loss: 0.6219190955162048\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.610047459602356\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6672226190567017\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.637543797492981\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.7006543874740601\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6575332880020142\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6219186782836914\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6634688973426819\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.659104585647583\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6434797048568726\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6612868309020996\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6337904930114746\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.685029149055481\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6650403738021851\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6947187185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456618905067444\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6494154334068298\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6159835457801819\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.688782811164856\n",
      "Batch Loss: 0.694718599319458\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6850294470787048\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6769117116928101\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6553511023521423\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6769115924835205\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6790938377380371\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6709758639335632\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6278545260429382\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6769115924835205\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6947184205055237\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6591044068336487\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6219189167022705\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.7162792086601257\n",
      "Batch Loss: 0.6494154930114746\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6375436782836914\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6612864136695862\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6887826919555664\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.690964937210083\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6278546452522278\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6434795260429382\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6844189167022705\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6769116520881653\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.615983247756958\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6553511619567871\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.665040135383606\n",
      "Batch Loss: 0.6634688377380371\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6612867712974548\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6375436782836914\n",
      "Batch Loss: 0.6709758639335632\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6909651756286621\n",
      "Batch Loss: 0.6694045662879944\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.7006542682647705\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337903141975403\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6850293278694153\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.621918797492981\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.673157811164856\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6709758043289185\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.659104585647583\n",
      "Batch Loss: 0.6219189763069153\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6887830495834351\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6397261619567871\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515974998474121\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6947187185287476\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6219188570976257\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6672221422195435\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6790935397148132\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6628583073616028\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6769114136695862\n",
      "Batch Loss: 0.6375439167022705\n",
      "Batch Loss: 0.6553510427474976\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6790935397148132\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6494153738021851\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6850295066833496\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6278547048568726\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6278545260429382\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6872115135192871\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6612867116928101\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6424959897994995\n",
      "Epoch 19/20, Loss: 0.6600628216518883, Time: 478.68s\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6456617712974548\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6434796452522278\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6412972211837769\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6159831285476685\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.621918797492981\n",
      "Batch Loss: 0.6731581687927246\n",
      "Batch Loss: 0.6337900757789612\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6790934801101685\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6790937781333923\n",
      "Batch Loss: 0.6591046452522278\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6672223806381226\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.7006543278694153\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6316083073616028\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6159831881523132\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6672222018241882\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.633790135383606\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6456618309020996\n",
      "Batch Loss: 0.676911473274231\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6412973999977112\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6828473210334778\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6909649968147278\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.637543797492981\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6337904334068298\n",
      "Batch Loss: 0.665040135383606\n",
      "Batch Loss: 0.6494150161743164\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6672224402427673\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6219189167022705\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6947185397148132\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337903141975403\n",
      "Batch Loss: 0.6769116520881653\n",
      "Batch Loss: 0.6337903738021851\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6494150161743164\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.694718599319458\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6947186589241028\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6494152545928955\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575331687927246\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6672224998474121\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.661286473274231\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6612866520881653\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6969007849693298\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694045066833496\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6828471422195435\n",
      "Batch Loss: 0.6947187185287476\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6769114136695862\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6278545260429382\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6925364136695862\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6316081285476685\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.643479585647583\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.649415135383606\n",
      "Batch Loss: 0.6316081285476685\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6969007849693298\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6375439167022705\n",
      "Batch Loss: 0.6219188570976257\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6515972018241882\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6553507447242737\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6278546452522278\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6769115924835205\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.627854585647583\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6219189167022705\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.694718599319458\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6397260427474976\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6672223210334778\n",
      "Batch Loss: 0.6575331091880798\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6337900757789612\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.682847261428833\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6219189167022705\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6278544664382935\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753401756286621\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6337902545928955\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.670975923538208\n",
      "Batch Loss: 0.6553508639335632\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6375439167022705\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6872114539146423\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6925367116928101\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.6219188570976257\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6456616520881653\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6650400757789612\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6278546452522278\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.655350923538208\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6909650564193726\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6434794664382935\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6694043278694153\n",
      "Batch Loss: 0.7006542682647705\n",
      "Batch Loss: 0.6494151949882507\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6197367310523987\n",
      "Batch Loss: 0.679093599319458\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6397259831428528\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.670975923538208\n",
      "Batch Loss: 0.663468599319458\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6812757849693298\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6931471824645996\n",
      "Batch Loss: 0.6790937185287476\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6850292682647705\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6434795260429382\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6866008043289185\n",
      "Batch Loss: 0.625672459602356\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6337901949882507\n",
      "Batch Loss: 0.6159831881523132\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.665040135383606\n",
      "Batch Loss: 0.6850293874740601\n",
      "Batch Loss: 0.6456615328788757\n",
      "Batch Loss: 0.6812757253646851\n",
      "Batch Loss: 0.6397258639335632\n",
      "Batch Loss: 0.637543797492981\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6316081881523132\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6219188570976257\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6456617116928101\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6731579899787903\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6694044470787048\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6634687185287476\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753400564193726\n",
      "Batch Loss: 0.6731580495834351\n",
      "Batch Loss: 0.6731579303741455\n",
      "Batch Loss: 0.667222261428833\n",
      "Batch Loss: 0.6591044664382935\n",
      "Batch Loss: 0.6553509831428528\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6515974402427673\n",
      "Batch Loss: 0.6494153141975403\n",
      "Batch Loss: 0.6612865328788757\n",
      "Batch Loss: 0.6456615924835205\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6694043874740601\n",
      "Batch Loss: 0.6575329303741455\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6812758445739746\n",
      "Batch Loss: 0.6634686589241028\n",
      "Batch Loss: 0.639725923538208\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.6278544664382935\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6515973210334778\n",
      "Batch Loss: 0.6634687781333923\n",
      "Batch Loss: 0.6828473806381226\n",
      "Batch Loss: 0.6575330495834351\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6612865924835205\n",
      "Batch Loss: 0.6515973806381226\n",
      "Batch Loss: 0.6790936589241028\n",
      "Batch Loss: 0.6397258043289185\n",
      "Batch Loss: 0.6575329899787903\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.651597261428833\n",
      "Batch Loss: 0.6753401160240173\n",
      "Batch Loss: 0.6553508043289185\n",
      "Batch Loss: 0.6551586389541626\n",
      "Epoch 20/20, Loss: 0.6592377069256818, Time: 471.29s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import optim\n",
    "lr=0.001\n",
    "epochs=20\n",
    "model = BERTLSTMnn(bert=b2, seq_len=512, n_layers=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    tl=0\n",
    "    train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output.squeeze(1), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Batch Loss: {loss.item()}\")\n",
    "        tl += loss.item()\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {tl/len(train_loader)}, Time: {elapsed:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85400df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test, batch_size=64, shuffle=False)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X)\n",
    "        predicted = (output.squeeze(1) > 0.5).float()\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e166c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'bert_lstm_model_21_6.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
