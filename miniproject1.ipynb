{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de0bc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3.tar.gz (23.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1.tar.gz (57.2 MB)\n",
      "     ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/57.2 MB ? eta -:--:--\n",
      "      --------------------------------------- 1.0/57.2 MB 2.6 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 3.4/57.2 MB 5.8 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 6.6/57.2 MB 8.4 MB/s eta 0:00:07\n",
      "     ------- ------------------------------- 11.3/57.2 MB 11.8 MB/s eta 0:00:04\n",
      "     ------------ -------------------------- 17.8/57.2 MB 15.0 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 24.6/57.2 MB 17.8 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 28.8/57.2 MB 19.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 29.4/57.2 MB 17.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 30.4/57.2 MB 15.1 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 31.2/57.2 MB 14.4 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 32.0/57.2 MB 13.8 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 32.5/57.2 MB 12.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 33.0/57.2 MB 12.0 MB/s eta 0:00:03\n",
      "     ----------------------- --------------- 34.1/57.2 MB 11.2 MB/s eta 0:00:03\n",
      "     ----------------------- --------------- 34.9/57.2 MB 10.7 MB/s eta 0:00:03\n",
      "     ------------------------ -------------- 35.9/57.2 MB 10.5 MB/s eta 0:00:03\n",
      "     --------------------------- ----------- 40.9/57.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------------------- ------- 46.7/57.2 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 53.0/57.2 MB 13.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  57.1/57.2 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 57.2/57.2 MB 13.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [46 lines of output]\n",
      "      + meson setup C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f\\.mesonpy-jmb3gcg1 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f\\.mesonpy-jmb3gcg1\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.8.1\n",
      "      Source dir: C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f\n",
      "      Build dir: C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f\\.mesonpy-jmb3gcg1\n",
      "      Build type: native build\n",
      "      Project name: scipy\n",
      "      Project version: 1.13.1\n",
      "      C compiler for the host machine: cc (gcc 15.1.0 \"cc (Rev5, Built by MSYS2 project) 15.1.0\")\n",
      "      C linker for the host machine: cc ld.bfd 2.44\n",
      "      C++ compiler for the host machine: c++ (gcc 15.1.0 \"c++ (Rev5, Built by MSYS2 project) 15.1.0\")\n",
      "      C++ linker for the host machine: c++ ld.bfd 2.44\n",
      "      Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "      Host machine cpu family: x86_64\n",
      "      Host machine cpu: x86_64\n",
      "      Program python found: YES (C:\\Users\\Johan\\miniconda3\\envs\\speakeasy\\python.exe)\n",
      "      Run-time dependency python found: YES 3.13\n",
      "      Program cython found: YES (C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-build-env-9p1lgp5b\\overlay\\Scripts\\cython.EXE)\n",
      "      Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "      Compiler for C supports arguments -Wno-unused-function: YES\n",
      "      Compiler for C supports arguments -Wno-conversion: YES\n",
      "      Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "      Library m found: YES\n",
      "      \n",
      "      ..\\meson.build:78:0: ERROR: Unknown compiler(s): [['ifort'], ['gfortran'], ['flang-new'], ['flang'], ['pgfortran'], ['g95']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `ifort --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `ifort --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `ifort -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\Johan\\AppData\\Local\\Temp\\pip-install-sqovqqrt\\scipy_8ced74e0f925496f9d416f21a400212f\\.mesonpy-jmb3gcg1\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f087a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03a9713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "# Load the pre-trained Word2Vec model\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "# Example words\n",
    "words = [\"king\", \"queen\"]\n",
    "# Get the vector for each word\n",
    "vectors = [model[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb63c518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510957\n"
     ]
    }
   ],
   "source": [
    "a=np.dot(vectors[0], vectors[1])  # Compute the dot product\n",
    "# Compute the cosine similarity\n",
    "print(a/(np.linalg.norm(vectors[0]) * np.linalg.norm(vectors[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f227f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus= pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "887da25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    million americans roll sleeves omicrontargeted...\n",
       "1    american airlines flyer charged banned life pu...\n",
       "2                  funniest tweets cats dogs week sept\n",
       "3                    funniest tweets parents week sept\n",
       "4    woman called cops black birdwatcher loses laws...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#cleaning the text data of punctuation, make everything lowercase, removing stopwords\n",
    "filtered=corpus['headline'].str.lower().str.replace('[^a-z ]', '', regex=True)\n",
    "filtered = filtered.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c870be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors=[]\n",
    "for sentence in filtered:\n",
    "    words = sentence.split()\n",
    "    vectors = [model[word] for word in words if word in model]\n",
    "    if vectors:\n",
    "        sentence_vector = np.mean(vectors, axis=0)\n",
    "        sentence_vectors.append(sentence_vector)\n",
    "    else:\n",
    "        sentence_vectors.append(np.zeros(model.vector_size))  # Handle empty sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2eb0e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02609689,  0.0816476 ,  0.12443324, -0.06874303, -0.02518354,\n",
       "       -0.00381034, -0.00080218, -0.17884691,  0.13344029,  0.16322981,\n",
       "        0.1086077 , -0.19949777, -0.04643467,  0.05913435,  0.01211984,\n",
       "       -0.08632115,  0.020595  ,  0.02985491,  0.0411584 ,  0.01653181,\n",
       "        0.04657855, -0.03735352, -0.02765764,  0.00843157, -0.07263619,\n",
       "       -0.05360631, -0.08433314,  0.00263323,  0.15037973, -0.1233575 ,\n",
       "       -0.00977434,  0.02690561,  0.05687604, -0.01420593, -0.02626256,\n",
       "       -0.08790807,  0.06533595,  0.04438128, -0.09943499,  0.1926967 ,\n",
       "       -0.04513114, -0.0836683 ,  0.06937081,  0.04549735, -0.01101576,\n",
       "       -0.08265904, -0.10972377,  0.03749302, -0.06777518,  0.05221122,\n",
       "        0.04017857, -0.07247489,  0.01252093, -0.03948103, -0.02784947,\n",
       "       -0.10801478, -0.03712681, -0.05824498,  0.00401524, -0.02008929,\n",
       "        0.01405552,  0.2094029 , -0.10889816, -0.02481515, -0.03007398,\n",
       "        0.00983102,  0.04385376,  0.05056327, -0.06953593,  0.02228655,\n",
       "        0.05693708,  0.13922991, -0.03485543,  0.11505999, -0.21913365,\n",
       "        0.04365757,  0.12104797, -0.02634975,  0.12782505,  0.02990723,\n",
       "        0.15744019, -0.00527736,  0.11669922,  0.09633092, -0.10972377,\n",
       "        0.06501988,  0.05770438,  0.01920428,  0.12782505,  0.06173488,\n",
       "       -0.02582659, -0.03065709, -0.04045759, -0.09923445, -0.16322544,\n",
       "       -0.01030622,  0.09901647,  0.04542759,  0.12462507, -0.02751814,\n",
       "       -0.10107422, -0.15248325,  0.15987723, -0.06798118,  0.09699358,\n",
       "       -0.23688616,  0.03894043, -0.02467128, -0.03113665, -0.08253697,\n",
       "       -0.06204659,  0.08325195,  0.01057652, -0.09556361, -0.0284075 ,\n",
       "        0.00167411, -0.02784947, -0.02887835, -0.015625  ,  0.1875    ,\n",
       "       -0.03505162,  0.04847935, -0.07073103, -0.0793457 ,  0.00226702,\n",
       "       -0.04625157,  0.01862444, -0.16409738,  0.12357003,  0.13500977,\n",
       "       -0.00181362, -0.09026228, -0.11033412,  0.07125419, -0.10362025,\n",
       "        0.00967843,  0.06486293,  0.02137974, -0.07273646,  0.15544783,\n",
       "       -0.0197743 , -0.06026786, -0.06532506,  0.02553885,  0.01606097,\n",
       "        0.04119001, -0.13766043,  0.0373012 ,  0.01196289, -0.11045619,\n",
       "        0.12037005, -0.01080104, -0.10121373,  0.05976214,  0.07538714,\n",
       "        0.01994106, -0.04951695, -0.13031878, -0.05889893, -0.01688058,\n",
       "        0.0199149 ,  0.06998117, -0.01488713,  0.01997593, -0.0466483 ,\n",
       "       -0.07087053,  0.05559431, -0.03740583,  0.12934658, -0.11739676,\n",
       "       -0.03887939,  0.06704276, -0.08865792, -0.04458182, -0.15140207,\n",
       "       -0.03989955,  0.15209961, -0.06586565, -0.19782366, -0.00951277,\n",
       "       -0.01206752,  0.0578962 , -0.06192452, -0.05202375,  0.01353237,\n",
       "        0.02347238,  0.01450893,  0.11123221,  0.1773856 ,  0.04675947,\n",
       "        0.0194615 , -0.11844308, -0.00859833,  0.05366298, -0.03863525,\n",
       "        0.10445731,  0.00962612, -0.18223354, -0.09507533,  0.01152693,\n",
       "       -0.02075304,  0.0551191 , -0.17820522, -0.00981576,  0.01721191,\n",
       "       -0.05011858,  0.03565107,  0.08222485,  0.02127511, -0.14743479,\n",
       "       -0.07857841, -0.03398786, -0.15108816,  0.07972936, -0.09570312,\n",
       "       -0.00263323, -0.02675084,  0.14871652, -0.14449637,  0.05136544,\n",
       "       -0.03999547, -0.10152762,  0.08381871,  0.01185826,  0.04663086,\n",
       "       -0.01900809,  0.03210449,  0.14630999, -0.06361607,  0.0453404 ,\n",
       "        0.0693294 , -0.05254255, -0.01974051,  0.02314104,  0.00567191,\n",
       "        0.0388358 ,  0.16896275, -0.04427665,  0.10414778,  0.07933699,\n",
       "        0.15115793, -0.03536551, -0.08765738, -0.15455845,  0.00209263,\n",
       "        0.05589512, -0.04729353,  0.06424386,  0.03696987, -0.06996373,\n",
       "        0.03703962,  0.0869315 ,  0.1524571 ,  0.04854911,  0.1242327 ,\n",
       "       -0.08527483, -0.01021903, -0.02975028,  0.05827985, -0.07972936,\n",
       "        0.01494489, -0.10586984, -0.11732701,  0.01635742,  0.16397531,\n",
       "        0.13040598, -0.07013594, -0.05353655, -0.05205427,  0.00404576,\n",
       "        0.02015904, -0.05705915, -0.01484026,  0.05189187,  0.03544399,\n",
       "       -0.01670619, -0.0632673 , -0.04223633,  0.0476423 , -0.0965053 ,\n",
       "        0.09041923,  0.01896667,  0.04544067,  0.03255353,  0.02582659,\n",
       "        0.06117466, -0.0876988 , -0.05536761,  0.02361189,  0.19655064,\n",
       "       -0.09381975, -0.08159529, -0.01150949,  0.05210659, -0.01681083,\n",
       "       -0.01270403, -0.04264614, -0.03943307, -0.01341466,  0.00628226],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6639fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d0d5134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sentence vector: film franchises made installments\n"
     ]
    }
   ],
   "source": [
    "selected_sentence= np.random.randint(0, len(sentence_vectors))\n",
    "print(\"Selected sentence vector:\", filtered[selected_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6222c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the selected sentence vector with the corpus\n",
    "#ignore the selected sentence itself\n",
    "threshold=0.6\n",
    "similarities = []\n",
    "for i, vector in enumerate(sentence_vectors):\n",
    "    if i != selected_sentence:\n",
    "        similarity = np.dot(sentence_vectors[selected_sentence], vector) / (\n",
    "            np.linalg.norm(sentence_vectors[selected_sentence]) * np.linalg.norm(vector)+0.01)\n",
    "        if similarity > threshold:\n",
    "            similarities.append((i, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "191c03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sentence: 9 Film Franchises That Made It To 9 Installments\n",
      "Index: 193197, Similarity: 0.6310, Headline: How Might the Next Batman Movie Franchise Try to Set Itself Apart from Previous Incarnations?\n",
      "Index: 166311, Similarity: 0.6257, Headline: Mark Hamill On The 'Star Wars' Franchise At CapeTown Film Fest\n",
      "Index: 63517, Similarity: 0.6136, Headline: Tetris Is Being Made Into A Movie Trilogy Because The World Is In Shambles\n",
      "Index: 95803, Similarity: 0.6128, Headline: This Group Of Bears Is Coming Back For The Final Installment Of Their Film Trilogy\n"
     ]
    }
   ],
   "source": [
    "#print similarities\n",
    "print(f\"Selected sentence: {corpus['headline'][selected_sentence]}\")\n",
    "similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "for i, sim in similarities[:10]:\n",
    "    print(f\"Index: {i}, Similarity: {sim:.4f}, Headline: {corpus['headline'][i]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b86dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
